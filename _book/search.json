[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Statistics with R",
    "section": "",
    "text": "Welcome!\nYou’ve discovered the work-in-progress revision for “Learning Statistics with R”.\nI’m so sorry.\nPerhaps I should explain. Back in the grimdark pre-Snapchat era of humanity (i.e. early 2011), I started teaching an introductory statistics class for psychology students offered at the University of Adelaide, using the R statistical package as the primary tool. I wrote my own lecture notes for the class, which have now expanded to the point of effectively being a book. The book is freely available, and released under a creative commons licence (CC BY-SA 4.0). Somehow the book turned out to be rather popular and there are now several variations of the original LSR book:\n\nMy original book was written in LaTeX, which makes it a little inaccessible. Emily Kothe kindly created a bookdown adaptation of LSR, which I’m now reworking in quarto\nMatt Crump has incorporated some LSR content in Answering Questions with Data\nMy own R programming notes R for Psychological Science adapt some LSR content\nDavid Foxcroft has adapted LSR to create Learning Statistics with Jamovi\nTom Faulkenberry has adapted David Foxcroft’s version to create Learning Statistics with JASP\nJean-Marc Meunier has translated Learning Statistics with Jamovi into French\nEthan Weed has started work on a Learning Statistics with Python adaptation (this is a work in progress!)\nRóbert Fodor is working on Learning Statistics with Cogstat\n\nI have suggested that someone write a Learning Statistics with an Abacus adaptation but so far there has been little interest."
  },
  {
    "objectID": "chapters/preface.html",
    "href": "chapters/preface.html",
    "title": "Preface",
    "section": "",
    "text": "Changes since the previous edition:\n\nnotation uses snake case\nchapter on research design removed\nchapter introducing R split into multiple chapters"
  },
  {
    "objectID": "chapters/introduction.html#sec-whywhywhy",
    "href": "chapters/introduction.html#sec-whywhywhy",
    "title": "1  Why statistics? Why R?",
    "section": "1.1 On the psychology of statistics",
    "text": "1.1 On the psychology of statistics\nIn fact, come to think of it, this sounds a lot like a psychological question. And since I used to work in a psychology department, it seems like a good idea to dig a little deeper here. Is it really plausible to think that this “common sense” approach is very trustworthy? Verbal arguments have to be constructed in language, and all languages have biases – some things are harder to say than others, and not necessarily because they’re false (e.g., quantum electrodynamics is a good theory, but hard to explain in words). Human intuitions aren’t built to solve scientific problems, they’re built to handle day to day inferences. Most fundamentally, reasoning sensibly requires people to engage in “induction”, making wise guesses and going beyond the immediate evidence of the senses to make generalisations about the world. It’s more or less impossible to do this without being influenced by other sources. Heck, as the next section shows, we can’t even solve “deductive” problems (ones where no guessing is required) without being influenced by our pre-existing biases.\n\n1.1.1 The curse of belief bias\nPeople are pretty smart. Our minds are quite amazing things, and we seem to be capable of the most incredible feats of thought and reason. That doesn’t make us perfect though. And among the many things that psychologists have shown over the years is that we really do find it hard to be neutral, to evaluate evidence impartially and without being swayed by pre-existing biases. A good example of this is the “belief bias” effect in logical reasoning: if you ask people to decide whether a particular argument is logically valid (i.e., conclusion would be true if the premises were true), we tend to be influenced by the believability of the conclusion, even when we shouldn’t. For instance, here’s a valid argument where the conclusion is believable:\n\nNo cigarettes are inexpensive (Premise 1)\nSome addictive things are inexpensive (Premise 2)\nTherefore, some addictive things are not cigarettes (Conclusion)\n\nAnd here’s a valid argument where the conclusion is not believable:\n\nNo addictive things are inexpensive (Premise 1)\nSome cigarettes are inexpensive (Premise 2)\nTherefore, some cigarettes are not addictive (Conclusion)\n\nThe logical structure of argument #2 is identical to the structure of argument #1, and they’re both valid. However, in the second argument, there are good reasons to think that premise 1 is incorrect, and as a result it’s probably the case that the conclusion is also incorrect. But that’s entirely irrelevant to the topic at hand: an argument is deductively valid if the conclusion is a logical consequence of the premises. That is, a valid argument doesn’t have to involve true statements.\nOn the other hand, here’s an invalid argument that has a believable conclusion:\n\nNo addictive things are inexpensive (Premise 1)\nSome cigarettes are inexpensive (Premise 2)\nTherefore, some addictive things are not cigarettes (Conclusion)\n\nAnd finally, an invalid argument with an unbelievable conclusion:\n\nNo cigarettes are inexpensive (Premise 1)\nSome addictive things are inexpensive (Premise 2)\nTherefore, some cigarettes are not addictive (Conclusion)\n\nNow, suppose that people really are perfectly able to set aside their pre-existing biases about what is true and what isn’t, and purely evaluate an argument on its logical merits. We’d expect 100% of people to say that the valid arguments are valid, and 0% of people to say that the invalid arguments are valid. So if you ran an experiment looking at this, you’d expect to see data like this:\n\n\n\n\nConclusion feels true\nConclusion feels false\n\n\n\n\nArgument is valid\n100% say “valid”\n100% say “valid”\n\n\nArgument is invalid\n0% say “valid”\n0% say “valid”\n\n\n\nIf the psychological data looked like this – or even a good approximation to this – we might feel safe in just trusting our gut instincts. That is, it’d be perfectly okay just to let scientists evaluate data based on their common sense, and not bother with all this murky statistics stuff. However, you guys have taken psych classes, and by now you probably know where this is going…\nIn a classic study, Evans, Barston, and Pollard (1983) ran an experiment looking at exactly this. What they found is that when pre-existing biases (i.e., beliefs) were in agreement with the structure of the data, everything went the way you’d hope:\n\n\n\n\nConclusion feels true\nConclusion feels false\n\n\n\n\nArgument is valid\n92% say “valid”\n\n\n\nArgument is invalid\n\n8% say “valid”\n\n\n\nNot perfect, but that’s pretty good. But look what happens when our intuitive feelings about the truth of the conclusion run against the logical structure of the argument:\n\n\n\n\nConclusion feels true\nConclusion feels false\n\n\n\n\nArgument is valid\n92% say “valid”\n46% say “valid”\n\n\nArgument is invalid\n92% say “valid”\n8% say “valid”\n\n\n\nOh dear, that’s not as good. Apparently, when people are presented with a strong argument that contradicts our pre-existing beliefs, we find it pretty hard to even perceive it to be a strong argument (people only did so 46% of the time). Even worse, when people are presented with a weak argument that agrees with our pre-existing biases, almost no-one can see that the argument is weak (people got that one wrong 92% of the time!)2\nData like these suggest that we ought to be cautious about trusting our intuitions too much. If you were a professional evaluator of evidence, and someone came along and offered you a magic tool that improves your chances of making the right decision, you’d probably jump at it, right? Of course you would. Thankfully, we actually do have a tool that can do this. But it’s not magic, it’s statistics. So that’s the first reason why scientists love statistics. It’s just too easy for us to believe what we want to believe; so if we want to follow the data instead, we’re going to need a bit of help to keep our personal biases under control. That’s what statistics does: when done properly, it helps keep us honest."
  },
  {
    "objectID": "chapters/introduction.html#the-cautionary-tale-of-simpsons-paradox",
    "href": "chapters/introduction.html#the-cautionary-tale-of-simpsons-paradox",
    "title": "1  Why statistics? Why R?",
    "section": "1.2 The cautionary tale of Simpson’s paradox",
    "text": "1.2 The cautionary tale of Simpson’s paradox\nThe following is a true story (I think…). In 1973, the University of California, Berkeley had some worries about the admissions of students into their postgraduate courses. Specifically, the thing that caused the problem was that the gender breakdown of their admissions, which looked like this…\n\n\n\n\nNumber of applicants\nPercent admitted\n\n\n\n\nMales\n8442\n46%\n\n\nFemales\n4321\n35%\n\n\n\n…and they were worried about being sued.3 Given that there were nearly 13,000 applicants, a difference of 9% in admission rates between males and females is just way too big to be a coincidence.4 Pretty compelling data, right?\nWell, maybe. Maybe not.\nWhen people started looking more carefully at the admissions data (Bickel, Hammel, and O’Connell 1975) they told a rather different story. Specifically, when they looked at it on a department by department basis, it turned out that most of the departments actually had a slightly higher success rate for female applicants than for male applicants. The table below shows the admission figures for the six largest departments:\n\n\n\nAdmission figures for the six largest departments by gender\n\n\n\n\n\n\n\n\n\nDepartment\nMale Applicants\nMale Percent Admitted\nFemale Applicants\nFemale Percent admitted\n\n\n\n\nA\n825\n62%\n108\n82%\n\n\nB\n560\n63%\n25\n68%\n\n\nC\n325\n37%\n593\n34%\n\n\nD\n417\n33%\n375\n35%\n\n\nE\n191\n28%\n393\n24%\n\n\nF\n272\n6%\n341\n7%\n\n\n\n\n\nRemarkably, most departments had a higher rate of admissions for females than for males! Yet the overall rate of admission across the university for females was lower than for males. How can this be? How can both of these statements be true at the same time?\nHere’s what’s going on. Firstly, notice that the departments are not equal to one another in terms of their admission percentages: some departments (e.g., engineering, chemistry) tended to admit a high percentage of the qualified applicants, whereas others (e.g., English) tended to reject most of the candidates, even if they were high quality. So, among the six departments shown above, notice that department A is the most generous, followed by B, C, D, E and F in that order. Next, notice that males and females tended to apply to different departments. If we rank the departments in terms of the total number of male applicants, we get A&gt;B&gt;D&gt;C&gt;F&gt;E (the “easy” departments are in bold). On the whole, males tended to apply to the departments that had high admission rates. Now compare this to how the female applicants distributed themselves. Ranking the departments in terms of the total number of female applicants produces a quite different ordering C&gt;E&gt;D&gt;F&gt;A&gt;B. In other words, what these data seem to be suggesting is that the female applicants tended to apply to “harder” departments. And in fact, if we look at all Figure @ref(fig:berkeley) we see that this trend is systematic, and quite striking. This effect is known as Simpson’s paradox. It’s not common, but it does happen in real life, and most people are very surprised by it when they first encounter it, and many people refuse to even believe that it’s real. It is very real. And while there are lots of very subtle statistical lessons buried in there, I want to use it to make a much more important point …doing research is hard, and there are lots of subtle, counterintuitive traps lying in wait for the unwary. That’s reason #2 why scientists love statistics, and why we teach research methods. Because science is hard, and the truth is sometimes cunningly hidden in the nooks and crannies of complicated data.\n\n\n\n\n\nThe Berkeley 1973 college admissions data. This figure plots the admission rate for the 85 departments that had at least one female applicant, as a function of the percentage of applicants that were female. The plot is a redrawing of Figure 1 from Bickel, Hammel, and O’Connell (1975). Circles plot departments with more than 40 applicants; the area of the circle is proportional to the total number of applicants. The crosses plot department with fewer than 40 applicants.\n\n\n\n\nBefore leaving this topic entirely, I want to point out something else really critical that is often overlooked in a research methods class. Statistics only solves part of the problem. Remember that we started all this with the concern that Berkeley’s admissions processes might be unfairly biased against female applicants. When we looked at the “aggregated” data, it did seem like the university was discriminating against women, but when we “disaggregate” and looked at the individual behaviour of all the departments it doesn’t seem like any such bias existed. The gender bias in total admissions was caused by the fact that women tended to apply to departments with stricter admission standards.\nFrom a legal perspective, that would probably put the university in the clear. Postgraduate admissions are determined at the level of the individual department, and at the level of individual departments, the decisions are more or less unbiased. Since the university can’t dictate which departments people choose to apply to, and the decision making takes place at the level of the department it can hardly be held accountable for any biases that those choices produce.\nHowever that’s not the whole story, is it?\nAfter all, if we’re interested in this from a more sociological and psychological perspective, we might want to ask why there are such strong gender differences in applications. Why do males tend to apply to engineering more often than females, and why is this reversed for the English department? And why is it it the case that the departments that tend to have a female-application bias tend to have lower overall admission rates than those departments that have a male-application bias? Might this not still reflect a gender bias, even though every single department is itself unbiased? It might. Suppose, hypothetically, that males preferred to apply to “hard sciences” and females prefer “humanities”. And suppose further that the reason for why the humanities departments have low admission rates is because the government doesn’t want to fund the humanities (Ph.D. places, for instance, are often tied to government funded research projects). Does that constitute a gender bias? Or just an unenlightened view of the value of the humanities? What if someone at a high level in the government cut the humanities funds because they felt that the humanities are ’too feminine”. That seems pretty blatantly gender biased.\nNone of this falls within the purview of the statistical analysis, but it matters to the research project. If you’re interested in the overall structural effects of subtle gender biases, then you probably want to look at both the aggregated and disaggregated data. If you’re interested in the decision making process at Berkeley itself then you’re probably only interested in the disaggregated data.\nIn short there are a lot of critical questions that you can’t answer with statistics, but the answers to those questions will have a huge impact on how you analyse and interpret data. And this is the reason why you should always think of statistics as a tool to help you learn about your data, no more and no less. It’s a powerful tool to that end, but there’s no substitute for careful thought."
  },
  {
    "objectID": "chapters/introduction.html#statistics-in-psychology",
    "href": "chapters/introduction.html#statistics-in-psychology",
    "title": "1  Why statistics? Why R?",
    "section": "1.3 Statistics in psychology",
    "text": "1.3 Statistics in psychology\nI hope that the discussion above helped explain why science in general is so focused on statistics. But I’m guessing that you have a lot more questions about what role statistics plays in psychology, and specifically why psychology classes always devote so many lectures to stats. So here’s my attempt to answer a few of them…\n\n1.3.1 Why does psychology have so much statistics?\nTo be perfectly honest, there’s a few different reasons, some of which are better than others. The most important reason is that psychology is a statistical science. What I mean by that is that the “things” that we study are people. Real, complicated, gloriously messy, infuriatingly perverse people. The “things” of physics include object like electrons, and while there are all sorts of complexities that arise in physics, electrons don’t have minds of their own. They don’t have opinions, they don’t differ from each other in weird and arbitrary ways, they don’t get bored in the middle of an experiment, and they don’t get angry at the experimenter and then deliberately try to sabotage the data set (not that I’ve ever done that…). At a fundamental level psychology is harder than physics.5\nBasically, we teach statistics to you as psychologists because you need to be better at stats than physicists. There’s actually a saying used sometimes in physics, to the effect that “if your experiment needs statistics, you should have done a better experiment”. They have the luxury of being able to say that because their objects of study are pathetically simple in comparison to the vast mess that confronts social scientists. It’s not just psychology, really: most social sciences are desperately reliant on statistics. Not because we’re bad experimenters, but because we’ve picked a harder problem to solve. We teach you stats because you really, really need it.\n\n\n1.3.2 Can’t someone else do the statistics?\nTo some extent, but not completely. It’s true that you don’t need to become a fully trained statistician just to do psychology, but you do need to reach a certain level of statistical competence. In my view, there’s three reasons that every psychological researcher ought to be able to do basic statistics:\n\nFirstly, there’s the fundamental reason: statistics is deeply intertwined with research design. If you want to be good at designing psychological studies, you need to at least understand the basics of stats.\nSecondly, if you want to be good at the psychological side of the research, then you need to be able to understand the psychological literature, right? But almost every paper in the psychological literature reports the results of statistical analyses. So if you really want to understand the psychology, you need to be able to understand what other people did with their data. And that means understanding a certain amount of statistics.\nThirdly, there’s a big practical problem with being dependent on other people to do all your statistics: statistical analysis is expensive. You may not be in a financial position to be able to afford a statistician. That’s not at all uncommon!\n\nNote that a lot of these reasons generalise beyond researchers. If you want to be a practicing psychologist and stay on top of the field, it helps to be able to read the scientific literature, which relies pretty heavily on statistics.\n\n\n1.3.3 I don’t care about jobs, research, or clinical work. Do I need statistics?\nOkay, now you’re just messing with me. Still, I think it should matter to you too. Statistics should matter to you in the same way that statistics should matter to everyone: we live in the 21st century, and data are everywhere. Frankly, given the world in which we live these days, a basic knowledge of statistics is pretty damn close to a survival tool! Which is the topic of the next section…"
  },
  {
    "objectID": "chapters/introduction.html#statistics-in-everyday-life",
    "href": "chapters/introduction.html#statistics-in-everyday-life",
    "title": "1  Why statistics? Why R?",
    "section": "1.4 Statistics in everyday life",
    "text": "1.4 Statistics in everyday life\nWhen I started writing up my lecture notes I took the 20 most recent news articles posted to the ABC news website. Of those 20 articles, it turned out that 8 of them involved a discussion of something that I would call a statistical topic; 6 of those made a mistake. The most common error, if you’re curious, was failing to report baseline data (e.g., the article mentions that 5% of people in situation X have some characteristic Y, but doesn’t say how common the characteristic is for everyone else!) The point I’m trying to make here isn’t that journalists are bad at statistics (though they almost always are), it’s that a basic knowledge of statistics is very helpful for trying to figure out when someone else is either making a mistake or even lying to you. In fact, one of the biggest things that a knowledge of statistics does to you is cause you to get angry at the newspaper or the internet on a far more frequent basis."
  },
  {
    "objectID": "chapters/introduction.html#theres-more-to-research-methods-than-statistics",
    "href": "chapters/introduction.html#theres-more-to-research-methods-than-statistics",
    "title": "1  Why statistics? Why R?",
    "section": "1.5 There’s more to research methods than statistics",
    "text": "1.5 There’s more to research methods than statistics\nSo far, most of what I’ve talked about is statistics, and so you’d be forgiven for thinking that statistics is all I care about in life. To be fair, you wouldn’t be far wrong, but research methodology is a broader concept than statistics. So most research methods courses will cover a lot of topics that relate much more to the pragmatics of research design, and in particular the issues that you encounter when trying to do research with humans. However, about 99% of student fears relate to the statistics part of the course, so I’ve focused on the stats in this discussion, and hopefully I’ve convinced you that statistics matters, and more importantly, that it’s not to be feared.\nThat being said, it’s pretty typical for introductory research methods classes to be very stats-heavy. This is not (usually) because the lecturers are evil people. Quite the contrary, in fact. Introductory classes focus a lot on the statistics because you almost always find yourself needing statistics before you need the other research methods training. Why? Because almost all of your assignments in other classes will rely on statistical training, to a much greater extent than they rely on other methodological tools. It’s not common for undergraduate assignments to require you to design your own study from the ground up (in which case you would need to know a lot about research design), but it is common for assignments to ask you to analyse and interpret data that were collected in a study that someone else designed (in which case you need statistics). In that sense, from the perspective of allowing you to do well in all your other classes, the statistics is more urgent.\nBut note that “urgent” is different from “important” – they both matter. I really do want to stress that research design is just as important as data analysis, and this book does spend a fair amount of time on it. However, while statistics has a kind of universality, and provides a set of core tools that are useful for most types of psychological research, the research methods side isn’t quite so universal. There are some general principles that everyone should think about, but a lot of research design is very idiosyncratic, and is specific to the area of research that you want to engage in. To the extent that it’s the details that matter, those details don’t usually show up in an introductory stats and research methods class."
  },
  {
    "objectID": "chapters/introduction.html#why-use-r",
    "href": "chapters/introduction.html#why-use-r",
    "title": "1  Why statistics? Why R?",
    "section": "1.6 Why use R?",
    "text": "1.6 Why use R?\n\nR, the mysterious and powerful language of the statisticians, holds secrets beyond the realm of mortal understanding. As a data scientist, I delve into its dark depths, unearthing hidden truths buried deep within the data.\nBut be warned, for R is not for the faint of heart. Its community is vast and ancient, with thousands of packages available for use, each holding its own eldritch power. These packages, written in a language known only to the initiated, can save one from certain doom by providing pre-written code for common tasks. But beware, for to gaze upon the ggplot2 package is to behold true terror, as it unveils the horrors of the data in a manner both beautiful and terrifying.\nIn the end, R is a tool to be respected and feared, for it holds the power to unveil the hidden mysteries of the data, but at what cost? Only the bravest of souls should dare to tread its path.\n– The ChatGPT model, when I asked it to write about R in a gothic horror style\n\nBefore starting any discussion of how R works, I ought to talk a bit about why you might want to want to use R at all. If you’re approaching R as a complete novice, your mental model of R might look quite similar to the output of ChatGPT in the quote above. So let’s take a moment to reassure you that a dive into R is not in face a descent into a Lovecraftian nightmare.\nWhy use R? Given that you’re reading this, you’ve probably got your own reasons. However, if those reasons are “because that’s what my stats class uses”, it might be worth explaining a little why your lecturer has chosen to use R for the class. Of course, I don’t really know why other people choose R, so I’m really talking about why I use it.\n\nIt’s sort of obvious, but worth saying anyway: doing your statistics on a computer is faster, easier and more powerful than doing statistics by hand. Computers excel at mindless repetitive tasks, and a lot of statistical calculations are both mindless and repetitive. For most people, the only reason to ever do statistical calculations with pencil and paper is for learning purposes. In my class I do occasionally suggest doing some calculations that way, but the only real value to it is pedagogical. It does help you to get a “feel” for statistics to do some calculations yourself, so it’s worth doing it once. But only once!\nDoing statistics in a spreadsheet (e.g., Microsoft Excel) is generally a bad idea in the long run. Although many people are likely feel more familiar with them, spreadsheets are very limited in terms of what analyses they allow you do. If you get into the habit of trying to do your real life data analysis using spreadsheets, then you’ve dug yourself into a very deep hole.\nAvoiding proprietary software is a very good idea. There are a lot of commercial packages out there that you can buy, some of which I like and some of which I don’t. They’re usually very glossy in their appearance, and generally very powerful (much more powerful than spreadsheets). However, they’re also very expensive: usually, the company sells “student versions” (crippled versions of the real thing) very cheaply; they sell full powered “educational versions” at a price that makes me wince; and they sell commercial licences with a staggeringly high price tag. The business model here is to suck you in during your student days, and then leave you dependent on their tools when you go out into the real world. It’s hard to blame them for trying, but personally I’m not in favour of shelling out thousands of dollars if I can avoid it. And you can avoid it: if you make use of packages like R that are open source and free, you never get trapped having to pay exorbitant licensing fees.\nSomething that you might not appreciate now, but will love later on if you do anything involving data analysis, is the fact that R is highly extensible. When you download and install R, you get all the basic “packages”, and those are very powerful on their own. However, because R is so open and so widely used, it’s become something of a standard tool in statistics, and so lots of people write their own packages that extend the system. And these are freely available too. One of the consequences of this, I’ve noticed, is that if you open up an advanced textbook rather than introductory textbooks, is that a lot of them use R. In other words, if you learn how to do your basic statistics in R, then you’re a lot closer to being able to use the state of the art methods than you would be if you’d started out with a “simpler” system: so if you want to become a genuine expert in psychological data analysis, learning R is a very good use of your time.\nRelated to the previous point: R is a real programming language. As you get better at using R for data analysis, you’re also learning to program. To some people this might seem like a bad thing, but in truth, programming is a core research skill across a lot of the social and behavioural sciences. Think about how many surveys and experiments are done online, or presented on computers. Think about all those online social environments which you might be interested in studying; and maybe collecting data from in an automated fashion. Think about artificial intelligence systems, computer vision and speech recognition. If any of these are things that you think you might want to be involved in – as someone “doing research in psychology”, that is – you’ll need to know a bit of programming. And if you don’t already know how to program, then learning how to do statistics using R is a nice way to start.\n\nThose are the main reasons I use R. It’s not without its flaws: it’s not easy to learn, and it has a few very annoying quirks to it that we’re all pretty much stuck with, but on the whole I think the strengths outweigh the weakness.\n\n\n\n\nBickel, P. J., E. A. Hammel, and J. W. O’Connell. 1975. “Sex Bias in Graduate Admissions: Data from Berkeley.” Science 187: 398–404.\n\n\nEvans, J. St. B. T., J. L. Barston, and P. Pollard. 1983. “On the Conflict Between Logic and Belief in Syllogistic Reasoning.” Memory and Cognition 11: 295–306."
  },
  {
    "objectID": "chapters/introduction.html#footnotes",
    "href": "chapters/introduction.html#footnotes",
    "title": "1  Why statistics? Why R?",
    "section": "",
    "text": "Including the suggestion that common sense is in short supply among scientists.↩︎\nIn my more cynical moments I feel like this fact alone explains most of what I read on the internet.↩︎\nEarlier versions of these notes incorrectly suggested that they actually were sued – apparently that’s not true. There’s a nice commentary on this here: www.refsmmat.com/posts/2016-05-08-simpsons-paradox-berkeley.html. A big thank you to Wilfried Van Hirtum for pointing this out to me!↩︎\nRevisiting these notes in 2023, I find myself slightly irritated by the way this example doesn’t clearly articulate what is intended when gender categories are used. It is a data set of its time, and I suppose very few researchers in 1973 would have thought carefully about sex, gender, and gender identity. Perhaps in a future revision I will find a better example.↩︎\nWhich might explain why physics is just a teensy bit further advanced as a science.↩︎"
  },
  {
    "objectID": "chapters/installation.html#windows-installation",
    "href": "chapters/installation.html#windows-installation",
    "title": "2  Installing R",
    "section": "2.1 Windows installation",
    "text": "2.1 Windows installation\nThe CRAN homepage changes from time to time, and it’s not particularly pretty. But it’s not difficult to find what you’re after. Assuming it doesn’t change, it’s a three-step process:\n\nYou’ll find a link at the top of the page with the text “Download R for Windows”. Click on that.\nThis will take you to a page that offers you a few options. At the very top of the page you’ll see a link for folks installing R for the first time. Click on that.\nThis will take you to a page that has a prominent link at the top called “Download R 4.2.2 for Windows”. Click on that and your browser should start downloading a file called R-4.2.2-win.exe.\n\nThe file may take some time depending on how fast your internet connection is. Once you’ve downloaded the file, double click to install it. As with any software you download online, Windows will ask you some questions about whether you trust the file and so on. After you click through those, it’ll ask you where you want to install it, and what components you want to install. The default values should be fine for most people, so again, just click through. Once all that is done, you should have R installed on your system. You can access it from the Start menu, or from the desktop if you asked it to add a shortcut there. You can now open up R in the usual way if you want to, but what I’m going to suggest is that instead of doing that you should now install RStudio (Section 2.4)."
  },
  {
    "objectID": "chapters/installation.html#mac-os-installation",
    "href": "chapters/installation.html#mac-os-installation",
    "title": "2  Installing R",
    "section": "2.2 Mac OS installation",
    "text": "2.2 Mac OS installation\nWhen you click on the Mac OS link, you should find yourself on a page with the title “R for Mac OS”. Here you’ll see several different options. The exact option that you want depends on what kind of Mac you have, and what version of the operating system you’re running. Most likely, however, what you’ll want is one of the first two options:\n\nIf you’re using an M1 Mac or higher, select the R-4.2.2-arm64.pkg option\nIf you’re using an Intel Mac, select the R-4.2.2.pkg option.\n\nEither way, your browser will start downloading the package file. Once it’s completed, all you need to do is open it by double clicking on the package file. The installation should go smoothly from there: just follow all the instructions just like you usually do when you install something.\nOnce it’s finished, you’ll find a file called R.app in the Applications folder. You can now open up R in the usual way if you want to, but what I’m going to suggest is that instead of doing that you should now install RStudio (Section 2.4)."
  },
  {
    "objectID": "chapters/installation.html#linux-installation",
    "href": "chapters/installation.html#linux-installation",
    "title": "2  Installing R",
    "section": "2.3 Linux installation",
    "text": "2.3 Linux installation\nIf you’re successfully managing to run a Linux box, regardless of what distribution, then you should find the instructions on the website easy enough. You can compile R from source yourself if you want, or install it through your package management system, which will probably have R in it. Alternatively, the CRAN site has precompiled binaries for Debian, Red Hat, Suse and Ubuntu and has separate instructions for each. Once you’ve got R installed, you can run it from the command line just by typing R. However, if you’re feeling envious of Windows and Mac users for their fancy GUIs, you can download RStudio too (Section 2.4)."
  },
  {
    "objectID": "chapters/installation.html#sec-installingrstudio",
    "href": "chapters/installation.html#sec-installingrstudio",
    "title": "2  Installing R",
    "section": "2.4 Installing RStudio",
    "text": "2.4 Installing RStudio\nOkay, so regardless of what operating system you’re using, the last thing that I told you to do is to download RStudio. To understand why I’ve suggested this, you need to understand a little bit more about R itself. The term R doesn’t really refer to a specific application on your computer. Rather, it refers to the underlying statistical language. You can use this language through lots of different applications. When you install R initially, it comes with one application that lets you do this: it’s the R.exe application on a Windows machine, and the R.app application on a Mac. But that’s not the only way to do it. There are lots of different applications that you can use that will let you interact with R. One of those is called RStudio, and it’s the one I’m going to suggest that you use. RStudio provides a clean, professional interface to R that I find much nicer to work with than either the Windows or Mac defaults. Like R itself, RStudio is free software: you can find all the details on their webpage. In the meantime, you can download it here:\nhttps://posit.co/download/rstudio-desktop/\nThis link should take you to a page with several possible downloads: there’s a different one for each operating system. Click on the appropriate link, and the RStudio installer file will start downloading. Once it’s finished downloading, open the installer file in the usual way to install RStudio. After it’s finished installing, you can start R by opening RStudio. You don’t need to open R.app or R.exe in order to access R. RStudio will take care of that for you. To illustrate what RStudio looks like, the figure below shows a screenshot of an R session in progress. In this screenshot it happens to be running on linux, but it looks almost identical no matter what operating system you have.\n\n\n\n\n\nAn R session in progress running inside RStudio."
  },
  {
    "objectID": "chapters/installation.html#sec-startingR",
    "href": "chapters/installation.html#sec-startingR",
    "title": "2  Installing R",
    "section": "2.5 Starting R",
    "text": "2.5 Starting R\nOne way or another, regardless of what operating system you’re using and regardless of whether you’re using RStudio, or the default GUI, or even the command line, it’s time to open R and get started. When you do that, the first thing you’ll see (assuming that you’re looking at the R console, that is) is a whole lot of text that doesn’t make much sense. It should look something like this:\nR version 4.2.2 Patched (2022-11-10 r83330) -- \"Innocent and Trusting\"\nCopyright (C) 2022 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu (64-bit)\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\n\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\n&gt; \nMost of this text is pretty uninteresting, and when doing real data analysis you’ll never really pay much attention to it. The important part of it is this…\n&gt;\n… which has a flashing cursor next to it. That’s the command prompt. When you see this, it means that R is waiting patiently for you to do something!"
  },
  {
    "objectID": "chapters/installation.html#quitting-r",
    "href": "chapters/installation.html#quitting-r",
    "title": "2  Installing R",
    "section": "2.6 Quitting R",
    "text": "2.6 Quitting R\nThere’s one last thing I should cover in this chapter: how to quit R. When I say this, I’m not trying to imply that R is some kind of pathological addition and that you need to call the R QuitLine or wear patches to control the cravings.1 I just mean how to exit the program. Assuming you’re running R in the usual way (i.e., through RStudio or the default GUI on a Windows or Mac computer), then you can just shut down the application in the normal way. However, R also has a function, called q() that you can use to quit, which is pretty handy if you’re running R in a terminal window.\nRegardless of what method you use to quit R, when you do so for the first time R will probably ask you if you want to save the “workspace image”. We’ll talk a lot more about loading and saving data in ?sec-load, but I figured we’d better quickly cover this now otherwise you’re going to get annoyed when you close R at the end of the chapter. If you’re using RStudio, you’ll see a dialog box with buttons to click. If you’re using a text based interface you’ll see this:\n\nq()\n\nSave workspace image? [y/n/c]: \nThe y/n/c part here is short for “yes / no / cancel”. Type y if you want to save, n if you don’t, and c if you’ve changed your mind and you don’t want to quit after all.\nWhat does this actually mean? What’s going on is that R wants to know if you want to save all those variables that you’ve been creating, so that you can use them later. This sounds like a great idea, so it’s really tempting to type y or click the “Save” button. To be honest though, I never do this, and it kind of annoys me a little bit… what R is really asking is if you want it to store these variables in a “default” data file, which it will automatically reload for you next time you open R. And quite frankly, if I’d wanted to save the variables, then I’d have already saved them before trying to quit. Not only that, I’d have saved them to a location of my choice, so that I can find it again later. So I personally never bother with this.\nIn fact, every time I install R on a new machine one of the first things I do is change the settings so that it never asks me again. You can do this in RStudio really easily: use the menu system to find the RStudio option. The window that comes up will give you an option to tell R never to whine about this again, as shown below:\n\n\n\n\n\nThe options window in RStudio. The highlighted settings are used to control the exit options\n\n\n\n\nOn a Mac, you can open this window by going to the “RStudio” menu and selecting “Preferences”. On a Windows machine you go to the “Tools” menu and select “Global Options”. Under the “General” tab you’ll see an option that reads “Save workspace to .Rdata on exit”. By default this is set to “ask”. If you want R to stop asking, change it to “never”."
  },
  {
    "objectID": "chapters/installation.html#footnotes",
    "href": "chapters/installation.html#footnotes",
    "title": "2  Installing R",
    "section": "",
    "text": "Although you certainly might argue that there’s something seriously pathological about being addicted to R↩︎"
  },
  {
    "objectID": "chapters/commands.html#sec-firstcommand",
    "href": "chapters/commands.html#sec-firstcommand",
    "title": "3  Our first R commands",
    "section": "3.1 Typing commands",
    "text": "3.1 Typing commands\nOne of the easiest things you can do with R is use it as a simple calculator, so it’s a good place to start. For instance, try typing 10 + 20, and hitting enter.1 When you do this, you’ve entered a command, and R will “execute” that command. What you see on screen now will be this:\n&gt; 10 + 20\n[1] 30\nNot a lot of surprises in this extract. But there’s a few things worth talking about, even with such a simple example. Firstly, it’s important that you understand how to read the extract. In this example, what I typed was the 10 + 20 part. I didn’t type the &gt; symbol: that’s just the R command prompt and isn’t part of the actual command. And neither did I type the [1] 30 part. That’s what R printed out in response to my command. Secondly, it’s important to understand how the output is formatted. Obviously, the correct answer to the sum 10 + 20 is 30, and not surprisingly R has printed that out as part of its response. But it’s also printed out this [1] part, which probably doesn’t make a lot of sense to you right now. You’re going to see that a lot. I’ll talk about what this means in a bit more detail later on, but for now you can think of [1] 30 as if R were saying “the answer to the 1st question you asked is 30”. That’s not quite the truth, but it’s close enough for now. And in any case it’s not really very interesting at the moment: we only asked R to calculate one thing, so obviously there’s only one answer printed on the screen. Later on this will change, and the [1] part will start to make a bit more sense. For now, I just don’t want you to get confused or concerned by it.\n\n3.1.1 Formatting\nNow that I’ve taught you these rules I’m going to change them pretty much immediately. That is because I want you to be able to copy code from the book directly into R if if you want to test things or conduct your own analyses. However, if you copy this code directly into R you will get an error. So instead I’ll show code and output like this:\n\n10 + 20\n\n[1] 30\n\n\nThe section shaded in grey is the R command, and the text underneath is the output. Displaying the code like this makes it easier to copy and past from the book into the R console.\n\n\n3.1.2 Avoid typos\nBefore we go on to talk about other types of calculations that we can do with R, there’s a few other things I want to point out. The first thing is that, while R is good software, it’s still software. It’s pretty stupid, and because it’s stupid it can’t handle typos. It takes it on faith that you meant to type exactly what you did type.\nFor example, suppose that you forgot to hit the shift key when trying to type +, and as a result your command ended up being 10 = 20 rather than 10 + 20. Here’s what happens:\n\n10 = 20\n\nError in 10 = 20: invalid (do_set) left-hand side to assignment\n\n\nWhat’s happened here is that R has attempted to interpret 10 = 20 as a command, and churns out an error message because the command doesn’t make any sense to it. When a human looks at this, and then looks down at their keyboard and sees that + and = are on the same key, it’s pretty obvious that the command was a typo.\nBut R doesn’t know this, so it gets upset.\nAnd, if you look at it from its perspective, this makes sense. All that R “knows” is that 10 is a legitimate number, 20 is a legitimate number, and = is a legitimate part of the language too. In other words, from its perspective this really does look like the user meant to type 10 = 20, since all the individual parts of that statement are legitimate and it’s too stupid to realise that this is probably a typo. Therefore, R takes it on faith that this is exactly what you meant… it only “discovers” that the command is nonsense when it tries to follow your instructions, typo and all. And then it complains, and out comes an error message.\nEven more subtle is the fact that some typos won’t produce errors at all, because they happen to correspond to “well-formed” R commands. For instance, suppose that not only did I forget to hit the shift key when trying to type 10 + 20, I also managed to press the key next to one I meant do. The resulting typo would produce the command 10 - 20. Clearly, R has no way of knowing that you meant to add 20 to 10, not subtract 20 from 10, so what happens this time is this:\n\n10 - 20\n\n[1] -10\n\n\nIn this case, R produces the right answer, but to the the wrong question.\nTo some extent, I’m stating the obvious here, but it’s important. The people who wrote R are smart. You, the user, are smart. But R itself is not. And because it isn’t smart, it has to be mindlessly obedient. It does exactly what you ask it to do. There is no equivalent to autocorrect in R. When doing advanced stuff – and even the simplest of statistics is pretty advanced in a lot of ways – it’s dangerous to let a mindless automaton like R try to overrule the human user. But because of this, it’s your responsibility to be careful. Always make sure you type exactly what you mean. When dealing with computers, it’s not enough to type “approximately” the right thing. In general, you absolutely must be precise in what you say to R … it is too stupid to be anything other than absurdly literal in its interpretation.\n\n\n3.1.3 Spacing\nOf course, now that I’ve been so uptight about the importance of always being precise, I should point out that there are some exceptions. Or, more accurately, there are some situations in which R does show a bit more flexibility than my previous description suggests. The first thing R is smart enough to do is ignore redundant spacing. What I mean by this is that, when I typed 10 + 20 before, I could equally have done this\n\n10    + 20\n\n[1] 30\n\n\nor this\n\n10+20\n\n[1] 30\n\n\nand I would get exactly the same answer. However, that doesn’t mean that you can insert spaces in any old place.\nFor example, the message that prints out when you open R mentions that that you can type citation() to get some information about how to cite R. If I do so…\n\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2023). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2023},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\n… it tells me to cite the R manual.\nLet’s see what happens when I try changing the spacing. If I insert spaces in between the word and the parentheses, or inside the parentheses themselves, then all is well. That is, either of these two commands\n\ncitation ()\n\n\ncitation(  )\n\nwill produce exactly the same response. However, what I can’t do is insert spaces in the middle of the word. If I try to do this, R gets upset:\n\ncitat ion()\n\nError: &lt;text&gt;:1:7: unexpected symbol\n1: citat ion\n          ^\n\n\nThroughout this book I’ll vary the way I use spacing a little bit, just to give you a feel for the different ways in which spacing can be used. I’ll try not to do it too much though, since it’s generally considered to be good practice to be consistent in how you format your commands.\n\n\n3.1.4 Incomplete commands\nOne more thing I should point out. If you hit enter in a situation where it’s “obvious” to R that you haven’t actually finished typing the command, R is just smart enough to keep waiting. For example, if you type 10 + and then press enter, even R is smart enough to realise that you probably wanted to type in another number. So here’s what happens (for illustrative purposes I’m breaking my own code formatting rules in this section):\n&gt; 10+\n+ \nand there’s a blinking cursor next to the plus sign. What this means is that R is still waiting for you to finish. It “thinks” you’re still typing your command, so it hasn’t tried to execute it yet. In other words, this plus sign is actually another command prompt. It’s different from the usual one (i.e., the &gt; symbol) to remind you that R is going to “add” whatever you type now to what you typed last time. For example, if I then go on to type 3 and hit enter, what I get is this:\n&gt; 10 +\n+ 20\n[1] 30\nAnd as far as R is concerned, this is exactly the same as if you had typed 10 + 20. Similarly, consider the citation() command that we talked about in the previous section. Suppose you hit enter after typing citation(. Once again, R is smart enough to realise that there must be more coming – since you need to add the ) character – so it waits. I can even hit enter several times and it will keep waiting:\n&gt; citation(\n+ \n+ \n+ )\nI’ll make use of this a lot in this book. A lot of the commands that we’ll have to type are pretty long, and they’re visually a bit easier to read if I break it up over several lines. If you start doing this yourself, you’ll eventually get yourself in trouble (it happens to us all). Maybe you start typing a command, and then you realise you’ve screwed up. For example,\n&gt; citblation( \n+ \n+ \nYou’d probably prefer R not to try running this command, right? If you want to get out of this situation, just hit the ‘escape’ key.2 R will return you to the normal command prompt (i.e. &gt;) without attempting to execute the botched command.\nThat being said, it’s not often the case that R is smart enough to tell that there’s more coming. For instance, in the same way that I can’t add a space in the middle of a word, I can’t hit enter in the middle of a word either. If I hit enter after typing citat I get an error, because R thinks I’m interested in an “object” called citat and can’t find it:\n&gt; citat\nError: object 'citat' not found\nWhat about if I typed citation and hit enter? In this case we get something very odd, something that we definitely don’t want, at least not at this stage. Switching back to my usual way of writing R commands, here’s what happens:\n\ncitation\n\nfunction (package = \"base\", lib.loc = NULL, auto = NULL) \n{\n    if (!is.null(auto) && !is.logical(auto) && !anyNA(match(c(\"Package\", \n        \"Version\", \"Title\"), names(meta &lt;- as.list(auto)))) && \n        !all(is.na(match(c(\"Authors@R\", \"Author\"), names(meta))))) {\n        auto_was_meta &lt;- TRUE\n        package &lt;- meta$Package\n    }\n    else {\n        auto_was_meta &lt;- FALSE\n\nBLAH BLAH BLAH\n\n\nwhere the BLAH BLAH BLAH goes on for rather a long time, and you don’t know enough R yet to understand what all this gibberish actually means. Of course, it doesn’t actually say BLAH BLAH BLAH: it says some other things we don’t understand or need to know.\nThis incomprehensible output can be quite intimidating to novice users, and unfortunately it’s very easy to forget to type the parentheses; so almost certainly you’ll do this by accident. Do not panic when this happens. Simply ignore the gibberish. As you become more experienced this gibberish will start to make sense, and you’ll find it quite handy to print this stuff out.3 But for now just try to remember to add the parentheses when typing your commands.\n\n\n3.1.5 Function arguments, their names and their defaults\n[TODO: use citation() instead of round()]\nThere’s two more fairly important things that you need to understand about how functions work in R, and that’s the use of “named” arguments, and default values” for arguments. Not surprisingly, that’s not to say that this is the last we’ll hear about how functions work, but they are the last things we desperately need to discuss in order to get you started. To understand what these two concepts are all about, I’ll introduce another function. The round() function can be used to round some value to the nearest whole number. For example, I could type this:\n\nround(3.1415)\n\n[1] 3\n\n\nPretty straightforward, really. However, suppose I only wanted to round it to two decimal places: that is, I want to get 3.14 as the output. The round() function supports this, by allowing you to input a second argument to the function that specifies the number of decimal places that you want to round the number to. In other words, I could do this:\n\nround(3.14165, 2)\n\n[1] 3.14\n\n\nWhat’s happening here is that I’ve specified two arguments: the first argument is the number that needs to be rounded (i.e., 3.1415), the second argument is the number of decimal places that it should be rounded to (i.e., 2), and the two arguments are separated by a comma. In this simple example, it’s quite easy to remember which one argument comes first and which one comes second, but for more complicated functions this is not easy. Fortunately, most R functions make use of argument names. For the round() function, for example the number that needs to be rounded is specified using the x argument, and the number of decimal points that you want it rounded to is specified using the digits argument. Because we have these names available to us, we can specify the arguments to the function by name. We do so like this:\n\nround(x = 3.1415, digits = 2)\n\n[1] 3.14\n\n\nNotice that this is kind of similar in spirit to variable assignment (Section 5.1), except that I used = here, rather than &lt;-. In both cases we’re specifying values to be associated with a label. However, there are some differences between what I was doing earlier on when creating variables, and what I’m doing here when specifying arguments, and so as a consequence it’s important that you use = in this context.\nAs you can see, specifying the arguments by name involves a lot more typing, but it’s also a lot easier to read. Because of this, the commands in this book will usually specify arguments by name,4 since that makes it clearer to you what I’m doing. However, one important thing to note is that when specifying the arguments using their names, it doesn’t matter what order you type them in. But if you don’t use the argument names, then you have to input the arguments in the correct order. In other words, these three commands all produce the same output…\n\nround(3.14165, 2)\nround(x = 3.1415, digits = 2)\nround(digits = 2, x = 3.1415)\n\n[1] 3.14\n[1] 3.14\n[1] 3.14\n\n\nbut this one does not…\n\nround(2, 3.14165)\n\n[1] 2\n\n\nOkay, so that’s the first thing I said you’d need to know: argument names. The second thing you need to know about is default values. Notice that the first time I called the round() function I didn’t actually specify the digits argument at all, and yet R somehow knew that this meant it should round to the nearest whole number. How did that happen? The answer is that the digits argument has a default value of 0, meaning that if you decide not to specify a value for digits then R will act as if you had typed digits = 0. This is quite handy: the vast majority of the time when you want to round a number you want to round it to the nearest whole number, and it would be pretty annoying to have to specify the digits argument every single time. On the other hand, sometimes you actually do want to round to something other than the nearest whole number, and it would be even more annoying if R didn’t allow this! Thus, by having digits = 0 as the default value, we get the best of both worlds."
  },
  {
    "objectID": "chapters/commands.html#using-tab-autocomplete",
    "href": "chapters/commands.html#using-tab-autocomplete",
    "title": "3  Our first R commands",
    "section": "3.2 Using “tab autocomplete”",
    "text": "3.2 Using “tab autocomplete”\nTime for a bit of a digression. At this stage you know how to type in basic commands, including how to use R functions. And it’s probably beginning to dawn on you that there are a lot of R functions, all of which have their own arguments. You’re probably also worried that you’re going to have to remember all of them! Thankfully, it’s not that bad. In fact, very few data analysts bother to try to remember all the commands. What they really do is use tricks to make their lives easier. The first (and arguably most important one) is to use the internet. If you don’t know how a particular R function works, Google it. There’s a lot of information out there!\nThe first thing I want to call your attention to is the autocomplete ability in RStudio.5\nLet’s stick to our example above and assume that what you want to do is to round a number. This time around, start typing the name of the function that you want, and then hit the “tab” key. RStudio will then display a little window like the one shown in the screenshot below. What you’re seeing here is what happens when I type the letters ro at the command line, and then hit tab\n\n\n\n\n\nStart typing the name of a function or a variable, and hit the “tab” key. RStudio brings up a little menu like this one that lets you select the command you want, and even prints out some information about it.\n\n\n\n\nThe window has two panels. On the left, there’s a list of variables and functions that start with the letters that I’ve typed shown in black text, and some grey text that tells you where that variable/function is stored. Ignore the grey text for now: it won’t make much sense to you until we’ve talked about packages in ?sec-packageinstall.\nAs you can see from the screenshot, there’s quite a few things that start with the letters ro: there’s something called rock, something called round, something called round.Date and so on. The one we want is round, but if you’re typing this yourself you’ll notice that when you hit the tab key the window pops up with the top entry (i.e., rock) highlighted. You can use the up and down arrow keys to select the one that you want. Or, if none of the options look right to you, you can hit the escape key (“esc”) or the left arrow key to make the window go away.\nIn our case, the thing we want is the round option, so we’ll select that. When you do this, you’ll see that the panel on the right changes. Previously, it had been telling us something about the rock data set (i.e., “Measurements on 48 rock samples…”) that is distributed as part of R. But when we select round, it displays information about the round() function, exactly as it is shown in the screenshot.\nThis display is really handy. The very first thing it says is round(x, digits = 0): what this is telling you is that the round() function has two arguments. The first argument is called x, and it doesn’t have a default value. The second argument is digits, and it has a default value of 0. In a lot of situations, that’s all the information you need. But RStudio goes a bit further, and provides some additional information about the function underneath. Sometimes that additional information is very helpful, sometimes it’s not: RStudio pulls that text from the R help documentation, and my experience is that the helpfulness of that documentation varies wildly. Anyway, if you’ve decided that round() is the function that you want to use, you can hit the right arrow or the enter key, and RStudio will finish typing the rest of the function name for you.\nThe autocomplete tool works slightly differently if you’ve already got the name of the function typed and you’re now trying to type the arguments. For instance, suppose I’ve typed round( into the console, and then I hit tab. RStudio is smart enough to recognise that I already know the name of the function that I want, because I’ve already typed it! Instead, it figures that what I’m interested in is the arguments to that function. So that’s what pops up in the little window:\n\n\n\n\n\nIf you’ve typed the name of a function already along with the left parenthesis and then hit the “tab” key, RStudio brings up a different window to the one shown above. This one lists all the arguments to the function on the left, and information about each argument on the right.\n\n\n\n\nAgain, the window has two panels, and you can interact with this window using arrow keys. On the left hand panel, you can see a list of the argument names. On the right hand side, it displays some information about what the selected argument does."
  },
  {
    "objectID": "chapters/commands.html#your-command-history",
    "href": "chapters/commands.html#your-command-history",
    "title": "3  Our first R commands",
    "section": "3.3 Your command history",
    "text": "3.3 Your command history\nOne thing that R does automatically is keep track of your “command history”. That is, it remembers all the commands that you’ve previously typed. You can access this history in a few different ways. The simplest way is to use the up and down arrow keys. If you hit the up key, the R console will show you the most recent command that you’ve typed. Hit it again, and it will show you the command before that. If you want the text on the screen to go away, hit escape6 Using the up and down keys can be really handy if you’ve typed a long command that had one typo in it. Rather than having to type it all again from scratch, you can use the up key to bring up the command and fix it.\nThe second way to get access to your command history is to look at the history panel in RStudio. On the upper right hand side of the RStudio window you’ll see a tab labelled “History”. Click on that, and you’ll see a list of all your recent commands displayed in that panel: it should look something like Figure @ref(fig:RStudiohistory). If you double click on one of the commands, it will be copied to the R console. (You can achieve the same result by selecting the command you want with the mouse and then clicking the “To Console” button).7\n\n\n\n\n\nThe history panel is located in the top right hand side of the RStudio window. Click on the word “History” and it displays this panel."
  },
  {
    "objectID": "chapters/commands.html#comments",
    "href": "chapters/commands.html#comments",
    "title": "3  Our first R commands",
    "section": "3.4 Using comments",
    "text": "3.4 Using comments\nBefore discussing any of the more complicated stuff, I want to introduce the comment character, #. It has a simple meaning: it tells R to ignore everything else you’ve written on this line. You won’t have much need of the # character immediately, but it’s very useful later on when writing scripts (see Chapter @ref(scripting)). However, while you don’t need to use it, I want to be able to include comments in my R extracts. For instance, if you read this:8\n\nseeker &lt;- 3.1415           # create the first variable\nlover &lt;- 2.7183            # create the second variable\nkeeper &lt;- seeker * lover   # now multiply them to create a third one\nprint( keeper )            # print out the value of 'keeper'\n\n[1] 8.539539\n\n\nit’s a lot easier to understand what I’m doing than if I just write this:\n\nseeker &lt;- 3.1415\nlover &lt;- 2.7183\nkeeper &lt;- seeker * lover\nprint( keeper )    \n\n[1] 8.539539\n\n\nYou might have already noticed that the code extracts in Chapter @ref(introR) included the # character, but from now on, you’ll start seeing # characters appearing in the extracts, with some human-readable explanatory remarks next to them. These are still perfectly legitimate commands, since R knows that it should ignore the # character and everything after it. But hopefully they’ll help make things a little easier to understand."
  },
  {
    "objectID": "chapters/commands.html#summary",
    "href": "chapters/commands.html#summary",
    "title": "3  Our first R commands",
    "section": "3.5 Summary",
    "text": "3.5 Summary"
  },
  {
    "objectID": "chapters/commands.html#footnotes",
    "href": "chapters/commands.html#footnotes",
    "title": "3  Our first R commands",
    "section": "",
    "text": "Seriously. If you’re in a position to do so, open up R and start typing. The simple act of typing it rather than “just reading” makes a big difference. It makes the concepts more concrete, and it ties the abstract ideas (programming and statistics) to the actual context in which you need to use them. Statistics is something you do, not just something you read about in a textbook.↩︎\nIf you’re running R from the terminal rather than from RStudio, escape doesn’t work: use CTRL-C instead.↩︎\nFor advanced users: yes, as you’ve probably guessed, R is printing out the source code for the function.↩︎\nThe two functions discussed previously, sqrt() and abs(), both only have a single argument, x. So I could have typed something like sqrt(x = 225) or abs(x = -13) earlier. The fact that all these functions use x as the name of the argument that corresponds the “main” variable that you’re working with is no coincidence. That’s a fairly widely used convention. Quite often, the writers of R functions will try to use conventional names like this to make your life easier. Or at least that’s the theory. In practice it doesn’t always work as well as you’d hope.↩︎\nFor advanced users: this isn’t just an RStudio thing. If you’re running R in a terminal window, tab autocomplete still works, and does so in exactly the way you’d expect. It’s not as visually pretty as the RStudio version and lacks some of the cooler features that RStudio provides. I don’t bother to document that here: my assumption is that if you are running R in the terminal then you’re already familiar with using tab autocomplete.↩︎\nIncidentally, that always works: if you’ve started typing a command and you want to clear it and start again, hit escape.↩︎\nAnother method is to start typing some text and then hit the Control key and the up arrow together (on Windows or Linux) or the Command key and the up arrow together (on a Mac). This will bring up a window showing all your recent commands that started with the same text as what you’ve currently typed. That can come in quite handy sometimes.↩︎\nNotice that I used print(keeper) rather than just typing keeper. Later on in the text I’ll sometimes use the print() function to display things because I think it helps make clear what I’m doing, but in practice people rarely do this.↩︎"
  },
  {
    "objectID": "chapters/calculations.html#sec-arithmetic",
    "href": "chapters/calculations.html#sec-arithmetic",
    "title": "4  Doing calculations",
    "section": "4.1 Adding, subtracting, multiplying and dividing",
    "text": "4.1 Adding, subtracting, multiplying and dividing\nSo, now that we have the terminology, let’s learn how to perform some arithmetic operations in R. To that end, the table below lists the operators that correspond to the basic arithmetic we learned in primary school: addition, subtraction, multiplication and division.\n\n\n\nBasic arithmetic operations in R. These five operators are used very frequently throughout the text, so it’s important to be familiar with them at the outset.\n\n\noperation\noperator\nexample input\nexample output\n\n\n\n\naddition\n+\n10 + 2\n12\n\n\nsubtraction\n-\n9 - 3\n6\n\n\nmultiplication\n*\n5 * 5\n25\n\n\ndivision\n/\n10 / 3\n3\n\n\npower\n^\n5 ^ 2\n25\n\n\n\n\n\nAs you can see, R uses fairly standard symbols to denote each of the different operations you might want to perform: addition is done using the + operator, subtraction is performed by the - operator, and so on. So if I wanted to find out what 57 times 61 is (and who wouldn’t?), I can use R instead of a calculator, like so:\n\n57 * 61\n\n[1] 3477\n\n\nSo that’s handy."
  },
  {
    "objectID": "chapters/calculations.html#taking-powers",
    "href": "chapters/calculations.html#taking-powers",
    "title": "4  Doing calculations",
    "section": "4.2 Taking powers",
    "text": "4.2 Taking powers\nThe first four operations listed in Table @ref(tab:arithmetic1) are things we all learned in primary school, but they aren’t the only arithmetic operations built into R. There are three other arithmetic operations that I should probably mention: taking powers, doing integer division, and calculating a modulus. Of the three, the only one that is of any real importance for the purposes of this book is taking powers, so I’ll discuss that one here: the other two are discussed in (datahandling?).\nFor those of you who can still remember your high school maths, this should be familiar. But for some people high school maths was a long time ago, and others of us didn’t listen very hard in high school. It’s not complicated. As I’m sure everyone will probably remember the moment they read this, the act of multiplying a number \\(x\\) by itself \\(n\\) times is called “raising \\(x\\) to the \\(n\\)-th power”. Mathematically, this is written as \\(x^n\\). Some values of \\(n\\) have special names: in particular \\(x^2\\) is called \\(x\\)-squared, and \\(x^3\\) is called \\(x\\)-cubed. So, the 4th power of 5 is calculated like this: \\[\n5^4 = 5 \\times 5 \\times 5 \\times 5\n\\]\nOne way that we could calculate \\(5^4\\) in R would be to type in the complete multiplication as it is shown in the equation above. That is, we could do this\n\n5 * 5 * 5 * 5\n\n[1] 625\n\n\nbut it does seem a bit tedious. It would be very annoying indeed if you wanted to calculate \\(5^{15}\\), since the command would end up being quite long. Therefore, to make our lives easier, we use the power operator instead. When we do that, our command to calculate \\(5^4\\) goes like this:\n\n5 ^ 4\n\n[1] 625\n\n\nMuch easier."
  },
  {
    "objectID": "chapters/calculations.html#bedmas",
    "href": "chapters/calculations.html#bedmas",
    "title": "4  Doing calculations",
    "section": "4.3 Doing calculations in the right order",
    "text": "4.3 Doing calculations in the right order\nOkay. At this point, you know how to take one of the most powerful pieces of statistical software in the world, and use it as a $2 calculator. And as a bonus, you’ve learned a few very basic programming concepts. That’s not nothing (you could argue that you’ve just saved yourself $2) but on the other hand, it’s not very much either. In order to use R more effectively, we need to introduce more programming concepts.\nIn most situations where you would want to use a calculator, you might want to do multiple calculations. R lets you do this, just by typing in longer commands.1 In fact, we’ve already seen an example of this earlier, when I typed in 5 * 5 * 5 * 5. However, let’s try a slightly different example:\n\n1 + 2 * 4\n\n[1] 9\n\n\nClearly, this isn’t a problem for R either. However, it’s worth stopping for a second, and thinking about what R just did. Clearly, since it gave us an answer of 9 it must have multiplied 2 * 4 (to get an interim answer of 8) and then added 1 to that. But, suppose it had decided to just go from left to right: if R had decided instead to add 1 + 2 (to get an interim answer of 3) and then multiplied by 4, it would have come up with an answer of 12.\nTo answer this, you need to know the order of operations that R uses. If you remember back to your high school maths classes, it’s actually the same order that you got taught when you were at school: the “BEDMAS” order.2 That is, first calculate things inside Brackets (), then calculate Exponents ^, then Division / and Multiplication *, then Addition + and Subtraction -. So, to continue the example above, if we want to force R to calculate the 1 + 2 part before the multiplication, all we would have to do is enclose it in brackets:\n\n(1 + 2) * 4 \n\n[1] 12\n\n\nThis is a fairly useful thing to be able to do. The only other thing I should point out about order of operations is what to expect when you have two operations that have the same priority: that is, how does R resolve ties? For instance, multiplication and division are actually the same priority, but what should we expect when we give R a problem like 4 / 2 * 3 to solve? If it evaluates the multiplication first and then the division, it would calculate a value of two-thirds. But if it evaluates the division first it calculates a value of 6. The answer, in this case, is that R goes from left to right, so in this case the division step would come first:\n\n4 / 2 * 3\n\n[1] 6\n\n\nAll of the above being said, it’s helpful to remember that brackets always come first. So, if you’re ever unsure about what order R will do things in, an easy solution is to enclose the thing you want it to do first in brackets. There’s nothing stopping you from typing (4 / 2) * 3. By enclosing the division in brackets we make it clear which thing is supposed to happen first. In this instance you wouldn’t have needed to, since R would have done the division first anyway, but when you’re first starting out it’s better to make sure R does what you want!"
  },
  {
    "objectID": "chapters/calculations.html#sec-usingfunctions",
    "href": "chapters/calculations.html#sec-usingfunctions",
    "title": "4  Doing calculations",
    "section": "4.4 Using functions to do calculations",
    "text": "4.4 Using functions to do calculations\nThe symbols +, -, * and so on are examples of operators. As we’ve seen, you can do quite a lot of calculations just by using these operators. However, in order to do more advanced calculations (and later on, to do actual statistics), you’re going to need to start using functions.3 I’ll talk in more detail about functions and how they work in ?sec-functions, but for now let’s just dive in and use a few. To get started, suppose I wanted to take the square root of 225. The square root, in case your high school maths is a bit rusty, is just the opposite of squaring a number. So, for instance, since “5 squared is 25” I can say that “5 is the square root of 25”. The usual notation for this is\n\\[\n\\sqrt{25} = 5\n\\]\nthough sometimes you’ll also see it written like this\n\\(25^{0.5} = 5.\\)\nThis second way of writing it is kind of useful to “remind” you of the mathematical fact that “square root of \\(x\\)” is actually the same as “raising \\(x\\) to the power of 0.5”. Personally, I’ve never found this to be terribly meaningful psychologically, though I have to admit it’s quite convenient mathematically. Anyway, it’s not important. What is important is that you remember what a square root is, since we’re going to need it later on.\nTo calculate the square root of 25, I can do it in my head pretty easily, since I memorised my multiplication tables when I was a kid. It gets harder when the numbers get bigger, and pretty much impossible if they’re not whole numbers. This is where something like R comes in very handy. Let’s say I wanted to calculate \\(\\sqrt{225}\\), the square root of 225. There’s two ways I could do this using R. Firstly, since the square root of 255 is the same thing as raising 225 to the power of 0.5, I could use the power operator ^, just like we did earlier:\n\n225 ^ 0.5\n\n[1] 15\n\n\nHowever, there’s a second way that we can do this, since R also provides a square root function, sqrt(). To calculate the square root of 255 using this function, what I do is insert the number 225 in the parentheses. That is, the command I type is this:\n\nsqrt(225)\n\n[1] 15\n\n\nWhen we use a function to do something, we generally refer to this as calling the function, and the values that we type into the function (there can be more than one) are referred to as the arguments of that function.\nObviously, the sqrt() function doesn’t really give us any new functionality, since we already knew how to do square root calculations by using the power operator ^, though I do think it looks nicer when we use sqrt(). However, there are lots of other functions in R: in fact, almost everything of interest that I’ll talk about in this book is an R function of some kind. For example, one function that we will need to use in this book is the absolute value function. Compared to the square root function, it’s extremely simple: it just converts negative numbers to positive numbers, and leaves positive numbers alone. Mathematically, the absolute value of \\(x\\) is written \\(|x|\\) or sometimes \\(\\mbox{abs}(x)\\). Calculating absolute values in R is pretty easy, since R provides the abs() function that you can use for this purpose. When you feed it a positive number…\n\nabs(21)\n\n[1] 21\n\n\nthe absolute value function does nothing to it at all. But when you feed it a negative number, it spits out the positive version of the same number, like this:\n\nabs(-13)\n\n[1] 13\n\n\nIn all honesty, there’s nothing that the absolute value function does that you couldn’t do just by looking at the number and erasing the minus sign if there is one. However, there’s a few places later in the book where we have to use absolute values, so I thought it might be a good idea to explain the meaning of the term early on.\nBefore moving on, it’s worth noting that – in the same way that R allows us to put multiple operations together into a longer command, like 1 + 2 * 4 for instance – it also lets us put functions together and even combine functions with operators if we so desire. For example, the following is a perfectly legitimate command:\n\nsqrt(1 + abs(-8))\n\n[1] 3\n\n\nWhen R executes this command, starts out by calculating the value of abs(-8), which produces an intermediate value of 8. Having done so, the command simplifies to sqrt(1 + 8). To solve the square root4 it first needs to add 1 + 8 to get 9, at which point it evaluates sqrt(9), and so it finally outputs a value of 3."
  },
  {
    "objectID": "chapters/calculations.html#assessing-mathematical-truths",
    "href": "chapters/calculations.html#assessing-mathematical-truths",
    "title": "4  Doing calculations",
    "section": "4.5 Assessing mathematical truths",
    "text": "4.5 Assessing mathematical truths\nA key concept in that a lot of R relies on is the idea of a logical value. A logical value is an assertion about whether something is true or false. This is implemented in R in a pretty straightforward way. There are two logical values, namely TRUE and FALSE. Despite the simplicity, a logical values are very useful things. Let’s see how they work.\nIn George Orwell’s classic book 1984, one of the slogans used by the totalitarian Party was “two plus two equals five”, the idea being that the political domination of human freedom becomes complete when it is possible to subvert even the most basic of truths. It’s a terrifying thought, especially when the protagonist Winston Smith finally breaks down under torture and agrees to the proposition. “Man is infinitely malleable”, the book says. I’m pretty sure that this isn’t true of humans5 but it’s definitely not true of R. R is not infinitely malleable. It has rather firm opinions on the topic of what is and isn’t true, at least as regards basic mathematics. If I ask it to calculate 2 + 2, it always gives the same answer, and it’s not bloody 5:\n\n2 + 2\n\n[1] 4\n\n\nOf course, so far R is just doing the calculations. I haven’t asked it to explicitly assert that \\(2+2 = 4\\) is a true statement. If I want R to make an explicit judgement, I can use a command like this:\n\n2 + 2 == 4\n\n[1] TRUE\n\n\nWhat I’ve done here is use the equality operator, ==, to force R to make a “true or false” judgement.6 Okay, let’s see what R thinks of the Party slogan:\n\n2 + 2 == 5\n\n[1] FALSE\n\n\nWoohoo! Freedom and ponies for all! Or something like that. Anyway, it’s worth having a look at what happens if I try to force R to believe that two plus two is five by making an assignment statement like 2 + 2 = 5 or 2 + 2 &lt;- 5. When I do this, here’s what happens:\n\n2 + 2 = 5\n\nError in 2 + 2 = 5: target of assignment expands to non-language object\n\n\nR doesn’t like this very much. It recognises that 2 + 2 is not a variable (that’s what the “non-language object” part is saying), and it won’t let you try to “reassign” it. While R is pretty flexible, and actually does let you do some quite remarkable things to redefine parts of R itself, there are just some basic, primitive truths that it refuses to give up. It won’t change the laws of addition, and it won’t change the definition of the number 2.\nThat’s probably for the best."
  },
  {
    "objectID": "chapters/calculations.html#logical-operations",
    "href": "chapters/calculations.html#logical-operations",
    "title": "4  Doing calculations",
    "section": "4.6 Logical operations",
    "text": "4.6 Logical operations\nSo now we’ve seen logical operations at work, but so far we’ve only seen the simplest possible example. You probably won’t be surprised to discover that we can combine logical operations with other operations and functions in a more complicated way, like this:\n\n3*3 + 4*4 == 5*5\n\n[1] TRUE\n\n\nor this\n\nsqrt(25) == 5\n\n[1] TRUE\n\n\nNot only that, but as the table below illustrates, there are several other logical operators that you can use, corresponding to some basic mathematical concepts.\n\n\n\nSome logical operators. Technically I should be calling these “binary relational operators”, but quite frankly I don’t want to. It’s my book so no-one can make me.\n\n\noperation\noperator\nexample input\nanswer\n\n\n\n\nless than\n&lt;\n2 &lt; 3\nTRUE\n\n\nless than or equal to\n&lt;=\n2 &lt;= 2\nTRUE\n\n\ngreater than\n&gt;\n2 &gt; 3\nFALSE\n\n\ngreater than or equal to\n&gt;=\n2 &gt;= 2\nTRUE\n\n\nequal to\n==\n2 == 3\nFALSE\n\n\nnot equal to\n!=\n2 != 3\nTRUE\n\n\n\n\n\nHopefully these are all pretty self-explanatory: for example, the less than operator &lt; checks to see if the number on the left is less than the number on the right. If it’s less, then R returns an answer of TRUE:\n\n99 &lt; 100\n\n[1] TRUE\n\n\nbut if the two numbers are equal, or if the one on the right is larger, then R returns an answer of FALSE, as the following two examples illustrate:\n\n100 &lt; 100\n\n[1] FALSE\n\n100 &lt; 99\n\n[1] FALSE\n\n\nIn contrast, the less than or equal to operator &lt;= will do exactly what it says. It returns a value of TRUE if the number of the left hand side is less than or equal to the number on the right hand side. So if we repeat the previous two examples using &lt;=, here’s what we get:\n\n100 &lt;= 100\n\n[1] TRUE\n\n100 &lt;= 99\n\n[1] FALSE\n\n\nAnd at this point I hope it’s pretty obvious what the greater than operator &gt; and the greater than or equal to operator &gt;= do! Next on the list of logical operators is the not equal to operator != which – as with all the others – does what it says it does. It returns a value of TRUE when things on either side are not identical to each other. Therefore, since \\(2+2\\) isn’t equal to \\(5\\), we get:\n\n2 + 2 != 5\n\n[1] TRUE\n\n\nWe’re not quite done yet. There are three more logical operations that are worth knowing about, listed below:\n\n\n\nSome more logical operators.\n\n\noperation\noperator\nexample input\nanswer\n\n\n\n\nnot\n!\n!(1==1)\nFALSE\n\n\nor\n&#124;\n(1==1) &#124; (2==3)\nTRUE\n\n\nand\n&\n(1==1) & (2==3)\nFALSE\n\n\n\n\n\nThese are the not operator !, the and operator &, and the or operator |. Like the other logical operators, their behaviour is more or less exactly what you’d expect given their names. For instance, if I ask you to assess the claim that “either \\(2+2 = 4\\) or \\(2+2 = 5\\)” you’d say that it’s true. Since it’s an “either-or” statement, all we need is for one of the two parts to be true. That’s what the | operator does:\n\n(2+2 == 4) | (2+2 == 5)\n\n[1] TRUE\n\n\nOn the other hand, if I ask you to assess the claim that “both \\(2+2 = 4\\) and \\(2+2 = 5\\)” you’d say that it’s false. Since this is an and statement we need both parts to be true. And that’s what the & operator does:\n\n(2+2 == 4) & (2+2 == 5)\n\n[1] FALSE\n\n\nFinally, there’s the not operator, which is simple but annoying to describe in English. If I ask you to assess my claim that “it is not true that \\(2+2 = 5\\)” then you would say that my claim is true; because my claim is that “\\(2+2 = 5\\) is false”. And I’m right. If we write this as an R command we get this:\n\n!(2+2 == 5)\n\n[1] TRUE\n\n\nIn other words, since 2+2 == 5 is a FALSE statement, it must be the case that !(2+2 == 5) is a TRUE one. Essentially, what we’ve really done is claim that “not false” is the same thing as “true”. Obviously, this isn’t really quite right in real life. But R lives in a much more black or white world: for R everything is either true or false. No shades of gray are allowed. We can actually see this much more explicitly, like this:\n\n!FALSE\n\n[1] TRUE\n\n\nOf course, in our \\(2+2 = 5\\) example, we didn’t really need to use “not” ! and “equals to” == as two separate operators. We could have just used the “not equals to” operator != like this:\n\n2+2 != 5\n\n[1] TRUE\n\n\nBut there are many situations where you really do need to use the ! operator. We’ll see some later on.7"
  },
  {
    "objectID": "chapters/calculations.html#summary",
    "href": "chapters/calculations.html#summary",
    "title": "4  Doing calculations",
    "section": "4.7 Summary",
    "text": "4.7 Summary"
  },
  {
    "objectID": "chapters/calculations.html#footnotes",
    "href": "chapters/calculations.html#footnotes",
    "title": "4  Doing calculations",
    "section": "",
    "text": "If you’re reading this with R open, a good learning trick is to try typing in a few different variations on what I’ve done here. If you experiment with your commands, you’ll quickly learn what works and what doesn’t.↩︎\nFor advanced users: if you want a table showing the complete order of operator precedence in R, type ?Syntax. I haven’t included it in this book since there are quite a few different operators, and we don’t need that much detail. Besides, in practice most people seem to figure it out from seeing examples: until writing this book I never looked at the formal statement of operator precedence for any language I ever coded in, and never ran into any difficulties.↩︎\nA side note for students with a programming background. Technically speaking, operators are functions in R: the addition operator + is actually a convenient way of calling the addition function `+`(). Thus 10 + 20 is equivalent to the function call `+`(20, 30). Not surprisingly, no-one ever uses this version. Because that would be stupid.↩︎\nA note for the mathematically inclined: R does support complex numbers, but unless you explicitly specify that you want them it assumes all calculations must be real valued. By default, the square root of a negative number is treated as undefined: sqrt(-9) will produce NaN (not a number) as its output. To get complex numbers, you would type sqrt(-9+0i) and R would now return 0+3i. However, since we won’t have any need for complex numbers in this book, I won’t refer to them again.↩︎\nI offer up my youthful attempts to be “cool” as evidence that some things just can’t be done.↩︎\nNote that this is a very different operator to the assignment operator = that I talked about in Section 5.1. A common typo that people make when trying to write logical commands in R (or other languages, since the “= versus ==” distinction is important in most programming languages) is to accidentally type = when you really mean ==. Be especially cautious with this – I’ve been programming in various languages since I was a teenager, and I still screw this up a lot. Hm. I think I see why I wasn’t cool as a teenager. And why I’m still not cool.↩︎\nA note for those of you who have taken a computer science class: yes, R does have a function for exclusive-or, namely xor(). Also worth noting is the fact that R makes the distinction between element-wise operators & and | and operators that look only at the first element of the vector, namely && and ||. To see the distinction, compare the behaviour of a command like c(FALSE,TRUE) & c(TRUE,TRUE) to the behaviour of something like c(FALSE,TRUE) && c(TRUE,TRUE). If this doesn’t mean anything to you, ignore this footnote entirely. It’s not important for the content of this book.↩︎"
  },
  {
    "objectID": "chapters/variables.html#sec-assign",
    "href": "chapters/variables.html#sec-assign",
    "title": "5  Variables",
    "section": "5.1 Storing a number as a variable",
    "text": "5.1 Storing a number as a variable\nOne of the most important things to be able to do in R (or any programming language, for that matter) is to store information in variables. Variables in R aren’t exactly the same thing as the variables we talked about in the last chapter on research methods, but they are similar. At a conceptual level you can think of a variable as “label” for a certain piece of information, or even several different pieces of information. When doing statistical analysis in R all of your data (the variables you measured in your study) will be stored as variables in R, but as well see later in the book you’ll find that you end up creating variables for other things too. However, before we delve into all the messy details of data sets and statistical analysis, let’s look at the very basics for how we create variables and work with them.\n\n5.1.1 Variable assignment using &lt;- and -&gt;\nSince we’ve been working with numbers so far, let’s start by creating variables to store our numbers. And since most people like concrete examples, let’s invent one. Suppose I’m trying to calculate how much money I’m going to make from this book. There’s several different numbers I might want to store. Firstly, I need to figure out how many copies I’ll sell. Given that I don’t actually sell copies of the book, the correct answer to this is zero, but once upon a time I did sell hard copies so let’s guess that the answer is 350.\nLet’s create a variable called sales to keep track of this number. What I want to do is assign a value to my variable sales, and that value should be 350. We do this by using the assignment operator, which is &lt;-. Here’s how we do it:\n\nsales &lt;- 350\n\nWhen you hit enter, R doesn’t print out any output.1 It just gives you another command prompt. However, behind the scenes R has created a variable called sales and given it a value of 350. You can check that this has happened by asking R to print the variable on screen. And the simplest way to do that is to type the name of the variable and hit enter2.\n\nsales\n\n[1] 350\n\n\nSo that’s nice to know. Anytime you can’t remember what R has got stored in a particular variable, you can just type the name of the variable and hit enter.\nOkay, so now we know how to assign variables. Actually, there’s a bit more you should know. Firstly, one of the curious features of R is that there are several different ways of making assignments. In addition to the &lt;- operator, we can also use -&gt; and =, and it’s pretty important to understand the differences between them.3\nLet’s start by considering -&gt;, since that’s the easy one (we’ll discuss = in Section 3.1.5). As you might expect from just looking at the symbol, it’s almost identical to &lt;-. It’s just that the arrow (i.e., the assignment) goes from left to right. So if I wanted to define my sales variable using -&gt;, I would write it like this:\n\n350 -&gt; sales\n\nThis has the same effect: and it still means that I’m only going to sell 350 copies. Sigh. Apart from this superficial difference, &lt;- and -&gt; are identical. In fact, as far as R is concerned, they’re actually the same operator, just in a “left form” and a “right form”.4\n\n\n5.1.2 Doing calculations using variables\nOkay, let’s get back to my original story. In my quest to become rich, I’ve written this book. To figure out how good a strategy is, I’ve started creating some variables in R. In addition to defining a sales variable that counts the number of copies I’m going to sell, I can also create a variable called royalty, indicating how much money I get per copy. Let’s say that my royalties are about $7 per book:\n\nsales &lt;- 350\nroyalty &lt;- 7\n\nThe nice thing about variables (in fact, the whole point of having variables) is that we can do anything with a variable that we ought to be able to do with the information that it stores. That is, since R allows me to multiply 350 by 7\n\n350 * 7\n\n[1] 2450\n\n\nit also allows me to multiply sales by royalty\n\nsales * royalty\n\n[1] 2450\n\n\nAs far as R is concerned, the sales * royalty command is the same as the 350 * 7 command. Not surprisingly, I can assign the output of this calculation to a new variable, which I’ll call revenue. And when we do this, the new variable revenue gets the value 2450. So let’s do that, and then get R to print out the value of revenue so that we can verify that it’s done what we asked:\n\nrevenue &lt;- sales * royalty\nrevenue\n\n[1] 2450\n\n\nThat’s fairly straightforward.\nA slightly more subtle thing we can do is reassign the value of my variable, based on its current value. For instance, suppose that one of my readers, no doubt under the influence of psychotropic drugs loves the book so much that they donate me an extra $550. The simplest way to capture this is by a command like this:\n\nrevenue &lt;- revenue + 550\nrevenue\n\n[1] 3000\n\n\nIn this calculation, R has taken the old value of revenue (i.e., 2450) and added 550 to that value, producing a value of 3000. This new value is assigned to the revenue variable, overwriting its previous value. In any case, we now know that I’m expecting to make $3000 off this. Pretty sweet, I thinks to myself. Or at least, that’s what I thinks until I do a few more calculation and work out what the implied hourly wage I’m making off this looks like.\n\n\n5.1.3 Rules and conventions for naming variables\nIn the examples that we’ve seen so far, my variable names (sales and revenue) have just been English-language words written using lowercase letters. However, R allows a lot more flexibility when it comes to naming your variables, as the following list of rules5 illustrates:\n\nVariable names can only use the upper case alphabetic characters A-Z as well as the lower case characters a-z. You can also include numeric characters 0-9 in the variable name, as well as the period . or underscore _ character. In other words, you can use SaL.e_s as a variable name (though I can’t think why you would want to), but you can’t use Sales?.\nVariable names cannot include spaces: therefore my sales is not a valid name, but my.sales is.\nVariable names are case sensitive: that is, Sales and sales are different variable names.\nVariable names must start with a letter or a period. You can’t use something like _sales or 1sales as a variable name. You can use .sales as a variable name if you want, but it’s not usually a good idea. By convention, variables starting with a . are used for special purposes, so you should avoid doing so.\nVariable names cannot be one of the reserved keywords. These are special names that R needs to keep “safe” from us mere users, so you can’t use them as the names of variables. The keywords are: if, else, repeat, while, function, for, in, next, break, TRUE, FALSE, NULL, Inf, NaN, NA, NA_integer_, NA_real_, NA_complex_, and finally, NA_character_. Don’t feel especially obliged to memorise these: if you make a mistake and try to use one of the keywords as a variable name, R will complain about it like the whiny little automaton it is.\n\nIn addition to those rules that R enforces, there are some informal conventions that people tend to follow when naming variables. One of them you’ve already seen: i.e., don’t use variables that start with a period. But there are several others. You aren’t obliged to follow these conventions, and there are many situations in which it’s advisable to ignore them, but it’s generally a good idea to follow them when you can:\n\nUse informative variable names. As a general rule, using meaningful names like sales and revenue is preferred over arbitrary ones like variable1 and variable2. Otherwise it’s very hard to remember what the contents of different variables are, and it becomes hard to understand what your commands actually do.\nUse short variable names. Typing is a pain and no-one likes doing it. So we much prefer to use a name like sales over a name like sales_for_this_book_that_you_are_reading. Obviously there’s a bit of a tension between using informative names (which tend to be long) and using short names (which tend to be meaningless), so use a bit of common sense when trading off these two conventions.\nUse one of the conventional naming styles for multi-word variable names. Suppose I want to name a variable that stores “my new salary”. Obviously I can’t include spaces in the variable name, so how should I do this? There are three different conventions that you sometimes see R users employing. Firstly, you can separate the words using underscores, which would give you my_new_salary as the variable name. Alternatively, you could use capital letters at the beginning of each word (except the first one), which gives you myNewSalary as the variable name. I don’t think there’s any strong reason to prefer one over the other,6 but it’s important to be consistent."
  },
  {
    "objectID": "chapters/variables.html#sec-vectors",
    "href": "chapters/variables.html#sec-vectors",
    "title": "5  Variables",
    "section": "5.2 Storing many numbers as a vector",
    "text": "5.2 Storing many numbers as a vector\nAt this point we’ve covered functions in enough detail to get us safely through the next couple of chapters (with one small exception: see ?sec-generics, so let’s return to our discussion of variables. When I introduced variables in Section 5.1 I showed you how we can use variables to store a single number. In this section, we’ll extend this idea and look at how to store multiple numbers within the one variable. In R, the name for a variable that can store multiple values is a vector. So let’s create one.\n\n5.2.1 Creating a vector\nLet’s stick to my silly “get rich quick by textbook writing” example. Suppose the textbook company (if I actually had one, that is) sends me sales data on a monthly basis. Since my class start in late February, we might expect most of the sales to occur towards the start of the year. Let’s suppose that I have 100 sales in February, 200 sales in March and 50 sales in April, and no other sales for the rest of the year. What I would like to do is have a variable – let’s call it sales_by_month – that stores all this sales data. The first number stored should be 0 since I had no sales in January, the second should be 100, and so on. The simplest way to do this in R is to use the combine function, c(). To do so, all we have to do is type all the numbers you want to store in a comma separated list, like this:7\n\nsales_by_month &lt;- c(0, 100, 200, 50, 0, 0, 0, 0, 0, 0, 0, 0)\nsales_by_month\n\n [1]   0 100 200  50   0   0   0   0   0   0   0   0\n\n\nTo use the correct terminology here, we have a single variable here called sales_by_month: this variable is a vector that consists of 12 elements.\n\n\n5.2.2 A handy digression\nNow that we’ve learned how to put information into a vector, the next thing to understand is how to pull that information back out again. However, before I do so it’s worth taking a slight detour. If you’ve been following along, typing all the commands into R yourself, it’s possible that the output that you saw when we printed out the sales_by_month vector was slightly different to what I showed above. This would have happened if the window (or the RStudio panel) that contains the R console is really, really narrow. If that were the case, you might have seen output that looks something like this:\n\nsales_by_month\n\n [1]   0 100 200  50\n [5]   0   0   0   0\n [9]   0   0   0   0\n\n\nBecause there wasn’t much room on the screen, R has printed out the results over three lines. But that’s not the important thing to notice. The important point is that the first line has a [1] in front of it, whereas the second line starts with [5] and the third with [9]. It’s pretty clear what’s happening here. For the first row, R has printed out the 1st element through to the 4th element, so it starts that row with a [1]. For the second row, R has printed out the 5th element of the vector through to the 8th one, and so it begins that row with a [5] so that you can tell where it’s up to at a glance. It might seem a bit odd to you that R does this, but in some ways it’s a kindness, especially when dealing with larger data sets!\n\n\n5.2.3 Getting information out of vectors\nTo get back to the main story, let’s consider the problem of how to get information out of a vector. At this point, you might have a sneaking suspicion that the answer has something to do with the [1] and [9] things that R has been printing out. And of course you are correct. Suppose I want to pull out the February sales data only. February is the second month of the year, so let’s try this:\n\nsales_by_month[2]\n\n[1] 100\n\n\nYep, that’s the February sales all right. But there’s a subtle detail to be aware of here: notice that R outputs [1] 100, not [2] 100. This is because R is being extremely literal. When we typed in sales_by_month[2], we asked R to find exactly one thing, and that one thing happens to be the second element of our sales_by_month vector. So, when it outputs [1] 100 what R is saying is that the first number that we just asked for is 100. This behaviour makes more sense when you realise that we can use this trick to create new variables. For example, I could create a february_sales variable like this:\n\nfebruary_sales &lt;- sales_by_month[2]\nfebruary_sales\n\n[1] 100\n\n\nObviously, the new variable february_sales should only have one element and so when I print it out this new variable, the R output begins with a [1] because 100 is the value of the first (and only) element of february_sales. The fact that this also happens to be the value of the second element of sales_by_month is irrelevant. We’ll pick this topic up again in Section 5.5.\n\n\n5.2.4 Altering the elements of a vector\nSometimes you’ll want to change the values stored in a vector. Imagine my surprise when the publisher rings me up to tell me that the sales data for May are wrong. There were actually an additional 25 books sold in May, but there was an error or something so they hadn’t told me about it. How can I fix my sales_by_month variable? One possibility would be to assign the whole vector again from the beginning, using c(). But that’s a lot of typing. Also, it’s a little wasteful: why should R have to redefine the sales figures for all 12 months, when only the 5th one is wrong? Fortunately, we can tell R to change only the 5th element, using this trick:\n\nsales_by_month[5] &lt;- 25\nsales_by_month\n\n [1]   0 100 200  50  25   0   0   0   0   0   0   0\n\n\nAnother way to edit variables is to use the edit() or fix() functions. I won’t discuss them in detail right now, but you can check them out on your own.\n\n\n5.2.5 Useful things to know about vectors\nBefore moving on, I want to mention a couple of other things about vectors. Firstly, you often find yourself wanting to know how many elements there are in a vector (usually because you’ve forgotten). You can use the length() function to do this. It’s quite straightforward:\n\nlength(sales_by_month)\n\n[1] 12\n\n\nSecondly, you often want to alter all of the elements of a vector at once. For instance, suppose I wanted to figure out how much money I made in each month. Since I’m earning an exciting $7 per book,8 what I want to do is multiply each element in the sales_by_month vector by 7.\nR makes this pretty easy, as the following example shows:\n\nsales_by_month * 7\n\n [1]    0  700 1400  350  175    0    0    0    0    0    0    0\n\n\nIn other words, when you multiply a vector by a single number, all elements in the vector get multiplied. The same is true for addition, subtraction, division and taking powers. So that’s neat. On the other hand, suppose I wanted to know how much money I was making per day, rather than per month. Since not every month has the same number of days, I need to do something slightly different. Firstly, I’ll create two new vectors:\n\ndays_per_month &lt;- c(31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31)\nprofit &lt;- sales_by_month * 7\n\nObviously, the profit variable is the same one we created earlier, and the days_per_month variable is pretty straightforward. What I want to do is divide every element of profit by the corresponding element of days_per_month. Again, R makes this pretty easy:\n\nprofit / days_per_month\n\n [1]  0.000000 25.000000 45.161290 11.666667  5.645161  0.000000  0.000000\n [8]  0.000000  0.000000  0.000000  0.000000  0.000000\n\n\nI still don’t like all those zeros, but that’s not what matters here. Notice that the second element of the output is 25, because R has divided the second element of profit (i.e. 700) by the second element of days_per_month (i.e. 28). Similarly, the third element of the output is equal to 1400 divided by 31, and so on. We’ll talk more about calculations involving vectors later on, but that’s enough detail for now."
  },
  {
    "objectID": "chapters/variables.html#sec-text",
    "href": "chapters/variables.html#sec-text",
    "title": "5  Variables",
    "section": "5.3 Storing text data",
    "text": "5.3 Storing text data\nA lot of the time your data will be numeric in nature, but not always. Sometimes your data really needs to be described using text, not using numbers. To address this, we need to consider the situation where our variables store text. To create a variable that stores the word “hello”, we can type this:\n\ngreeting &lt;- \"hello\"\ngreeting\n\n[1] \"hello\"\n\n\nWhen interpreting this, it’s important to recognise that the quote marks here aren’t part of the string itself. They’re just something that we use to make sure that R knows to treat the characters that they enclose as a piece of text data, known as a character string. In other words, R treats \"hello\" as a string containing the word “hello”; but if I had typed hello instead, R would go looking for a variable by that name! You can also use 'hello' to specify a character string.\nOkay, so that’s how we store the text. Next, it’s important to recognise that when we do this, R stores the entire word \"hello\" as a single element: our greeting variable is not a vector of five different letters. Rather, it has only the one element, and that element corresponds to the entire character string \"hello\". To illustrate this, if I actually ask R to find the first element of greeting, it prints the whole string:\n\ngreeting[1]\n\n[1] \"hello\"\n\n\nOf course, there’s no reason why I can’t create a vector of character strings. For instance, if we were to continue with the example of my attempts to look at the monthly sales data for my book, one variable I might want would include the names of all 12 months.9 To do so, I could type in a command like this\n\nmonths &lt;- c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n            \"July\", \"August\", \"September\", \"October\", \"November\", \n            \"December\")\n\nThis is a character vector containing 12 elements, each of which is the name of a month. So if I wanted R to tell me the name of the fourth month, all I would do is this:\n\nmonths[4]\n\n[1] \"April\"\n\n\n\n5.3.1 Working with text\nWorking with text data is somewhat more complicated than working with numeric data, and I discuss some of the basic ideas in ?sec-textprocessing, but for purposes of the current chapter we only need this bare bones sketch. The only other thing I want to do before moving on is show you an example of a function that can be applied to text data. So far, most of the functions that we have seen (i.e., sqrt(), abs() and round()) only make sense when applied to numeric data (e.g., you can’t calculate the square root of “hello”), and we’ve seen one function that can be applied to pretty much any variable or vector (i.e., length()). So it might be nice to see an example of a function that can be applied to text.\nThe function I’m going to introduce you to is called nchar(), and what it does is count the number of individual characters that make up a string. Recall earlier that when we tried to calculate the length() of our greeting variable it returned a value of 1: the greeting variable contains only the one string, which happens to be \"hello\". But what if I want to know how many letters there are in the word? Sure, I could count them, but that’s boring, and more to the point it’s a terrible strategy if what I wanted to know was the number of letters in War and Peace. That’s where the nchar() function is helpful:\n\nnchar(greeting)\n\n[1] 5\n\n\nThat makes sense, since there are in fact 5 letters in the string \"hello\". Better yet, you can apply nchar() to whole vectors. So, for instance, if I want R to tell me how many letters there are in the names of each of the 12 months, I can do this:\n\nnchar(months)\n\n [1] 7 8 5 5 3 4 4 6 9 7 8 8\n\n\nSo that’s nice to know. The nchar() function can do a bit more than this, and there’s a lot of other functions that you can do to extract more information from text or do all sorts of fancy things. However, the goal here is not to teach any of that! The goal right now is just to see an example of a function that actually does work when applied to text."
  },
  {
    "objectID": "chapters/variables.html#sec-logicals",
    "href": "chapters/variables.html#sec-logicals",
    "title": "5  Variables",
    "section": "5.4 Logical values as data",
    "text": "5.4 Logical values as data\nUp to this point, I’ve introduced numeric data (Section 5.1 and Section 5.2) and character data (Section 5.3). So you might not be surprised to discover that these TRUE and FALSE values that R has been producing are actually a third kind of data, called logical data. That is, when I asked R if 2 + 2 == 5 and it said [1] FALSE in reply, it was actually producing information that we can store in variables. For instance, I could create a variable called is_the_party_correct, which would store R’s opinion:\n\nis_the_party_correct &lt;- 2 + 2 == 5\nis_the_party_correct\n\n[1] FALSE\n\n\nAlternatively, you can assign the value directly, by typing TRUE or FALSE in your command. Like this:\n\nis_the_party_correct &lt;- FALSE\nis_the_party_correct\n\n[1] FALSE\n\n\nAs an aside, because it’s kind of tedious to type TRUE or FALSE over and over again, R provides you with a shortcut: you can use T and F instead. However, it’s generally not recommended because it’s possible for the values of T and F to be changed. In contrast TRUE and FALSE cannot be changed or overwritten.\n\n5.4.1 Vectors of logicals\nThe next thing to mention is that you can store vectors of logical values in exactly the same way that you can store vectors of numbers (Section 5.2) and vectors of text data (Section 5.3). Again, we can define them directly via the c() function, like this:\n\nx &lt;- c(TRUE, TRUE, FALSE)\nx\n\n[1]  TRUE  TRUE FALSE\n\n\nor you can produce a vector of logicals by applying a logical operator to a vector. This might not make a lot of sense to you, so let’s unpack it slowly. First, let’s suppose we have a vector of numbers (i.e., a “non-logical vector”). For instance, we could use the sales_by_month vector that we were using in Section 5.2. Suppose I wanted R to tell me, for each month of the year, whether I actually sold a book in that month. I can do that by typing this:\n\nsales_by_month &gt; 0\n\n [1] FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n[12] FALSE\n\n\nand again, I can store this in a vector if I want, as the example below illustrates:\n\nany_sales_this_month &lt;- sales_by_month &gt; 0\nany_sales_this_month\n\n [1] FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n[12] FALSE\n\n\nIn other words, any_sales_this_month is a logical vector whose elements are TRUE only if the corresponding element of sales_by_month is greater than zero. For instance, since I sold zero books in January, the first element is FALSE.\n\n\n5.4.2 Applying logical operation to text\nIn a moment (Section 5.5) I’ll show you why these logical operations and logical vectors are so handy, but before I do so I want to very briefly point out that you can apply them to text as well as to logical data. It’s just that we need to be a bit more careful in understanding how R interprets the different operations. In this section I’ll talk about how the equal to operator == applies to text, since this is the most important one. Obviously, the not equal to operator != gives the exact opposite answers to == so I’m implicitly talking about that one too, but I won’t give specific commands showing the use of !=. As for the other operators, I’ll defer a more detailed discussion of this topic to ?sec-logictext2.\nOkay, let’s see how it works. In one sense, it’s very simple. For instance, I can ask R if the word \"cat\" is the same as the word \"dog\", like this:\n\n\"cat\" == \"dog\"\n\n[1] FALSE\n\n\nThat’s pretty obvious, and it’s good to know that even R can figure that out. Similarly, R does recognise that a \"cat\" is a \"cat\":\n\n\"cat\" == \"cat\"\n\n[1] TRUE\n\n\nAgain, that’s exactly what we’d expect. However, what you need to keep in mind is that R is not at all tolerant when it comes to grammar and spacing. If two strings differ in any way whatsoever, R will say that they’re not equal to each other, as the following examples indicate:\n\n\"cat\" == \" cat\"\n\"cat\" == \"CAT\"\n\"cat\" == \"c a t\"\n\n[1] FALSE\n[1] FALSE\n[1] FALSE"
  },
  {
    "objectID": "chapters/variables.html#sec-indexing",
    "href": "chapters/variables.html#sec-indexing",
    "title": "5  Variables",
    "section": "5.5 Indexing vectors",
    "text": "5.5 Indexing vectors\nOne last thing to add before finishing up this chapter. So far, whenever I’ve had to get information out of a vector, all I’ve done is typed something like months[4]; and when I do this R prints out the fourth element of the months vector. In this section, I’ll show you two additional tricks for getting information out of the vector.\n\n5.5.1 Extracting multiple elements\nOne very useful thing we can do is pull out more than one element at a time. In the previous example, we only used a single number (i.e., 2) to indicate which element we wanted. Alternatively, we can use a vector. So, suppose I wanted the data for February, March and April. What I could do is use the vector c(2,3,4) to indicate which elements I want R to pull out. That is, I’d type this:\n\nsales_by_month[c(2, 3, 4)]\n\n[1] 100 200  50\n\n\nNotice that the order matters here. If I asked for the data in the reverse order (i.e., April first, then March, then February) by using the vector c(4,3,2), then R outputs the data in the reverse order:\n\nsales_by_month[c(4, 3, 2)]\n\n[1]  50 200 100\n\n\nA second thing to be aware of is that R provides you with handy shortcuts for very common situations. For instance, suppose that I wanted to extract everything from the 2nd month through to the 8th month. One way to do this is to do the same thing I did above, and use the vector c(2,3,4,5,6,7,8) to indicate the elements that I want. That works just fine\n\nsales_by_month[c(2, 3, 4, 5, 6, 7, 8)]\n\n[1] 100 200  50  25   0   0   0\n\n\nbut it’s kind of a lot of typing. To help make this easier, R lets you use 2:8 as shorthand for c(2,3,4,5,6,7,8), which makes things a lot simpler. First, let’s just check that this is true:\n\n2:8\n\n[1] 2 3 4 5 6 7 8\n\n\nNext, let’s check that we can use the 2:8 shorthand as a way to pull out the 2nd through 8th elements of sales_by_months:\n\nsales_by_month[2:8]\n\n[1] 100 200  50  25   0   0   0\n\n\nSo that’s kind of neat.\n\n\n5.5.2 Logical indexing\nAt this point, I can introduce an extremely useful tool called logical indexing. In the last section, I created a logical vector any_sales_this_month, whose elements are TRUE for any month in which I sold at least one book, and FALSE for all the others. However, that big long list of TRUEs and FALSEs is a little bit hard to read, so what I’d like to do is to have R select the names of the months for which I sold any books. Earlier on, I created a vector months that contains the names of each of the months. This is where logical indexing is handy. What I need to do is this:\n\nmonths[sales_by_month &gt; 0]\n\n[1] \"February\" \"March\"    \"April\"    \"May\"     \n\n\nTo understand what’s happening here, it’s helpful to notice that sales_by_month &gt; 0 is the same logical expression that we used to create the any_sales_this_month vector in the last section. In fact, I could have just done this:\n\nmonths[any_sales_this_month]\n\n[1] \"February\" \"March\"    \"April\"    \"May\"     \n\n\nand gotten exactly the same result. In order to figure out which elements of months to include in the output, what R does is look to see if the corresponding element in any_sales_this_month is TRUE. Thus, since element 1 of any_sales_this_month is FALSE, R does not include \"January\" as part of the output; but since element 2 of any_sales_this_month is TRUE, R does include \"February\" in the output. Note that there’s no reason why I can’t use the same trick to find the actual sales numbers for those months. The command to do that would just be this:\n\nsales_by_month[sales_by_month &gt; 0]\n\n[1] 100 200  50  25\n\n\nIn fact, we can do the same thing with text. Here’s an example. Suppose that – to continue the saga of the textbook sales – I later find out that the bookshop only had sufficient stocks for a few months of the year. They tell me that early in the year they had \"high\" stocks, which then dropped to \"low\" levels, and in fact for one month they were \"out\" of copies of the book for a while before they were able to replenish them. Thus I might have a variable called stock_levels which looks like this:\n\nstock_levels&lt;-c(\"high\", \"high\", \"low\", \"out\", \"out\", \"high\",\n                \"high\", \"high\", \"high\", \"high\", \"high\", \"high\")\nstock_levels\n\n [1] \"high\" \"high\" \"low\"  \"out\"  \"out\"  \"high\" \"high\" \"high\" \"high\" \"high\"\n[11] \"high\" \"high\"\n\n\nThus, if I want to know the months for which the bookshop was out of my book, I could apply the logical indexing trick, but with the character vector stock_levels, like this:\n\nmonths[stock_levels == \"out\"]\n\n[1] \"April\" \"May\"  \n\n\nAlternatively, if I want to know when the bookshop was either low on copies or out of copies, I could do this:\n\nmonths[stock_levels == \"out\" | stock_levels == \"low\"]\n\n[1] \"March\" \"April\" \"May\"  \n\n\nor this\n\nmonths[stock_levels != \"high\"]\n\n[1] \"March\" \"April\" \"May\"  \n\n\nEither way, I get the answer I want.\nAt this point, I hope you can see why logical indexing is such a useful thing. It’s a very basic, yet very powerful way to manipulate data. We’ll talk a lot more about how to manipulate data in (datahandling?), since it’s a critical skill for real world research that is often overlooked in introductory research methods classes (or at least, that’s been my experience). It does take a bit of practice to become completely comfortable using logical indexing, so it’s a good idea to play around with these sorts of commands. Try creating a few different variables of your own, and then ask yourself questions like “how do I get R to spit out all the elements that are [blah]”. Practice makes perfect, and it’s only by practicing logical indexing that you’ll perfect the art of yelling frustrated insults at your computer.10"
  },
  {
    "objectID": "chapters/variables.html#useful",
    "href": "chapters/variables.html#useful",
    "title": "5  Variables",
    "section": "5.6 Useful things to know about variables",
    "text": "5.6 Useful things to know about variables\nIn Chapter @ref(introR) I talked a lot about variables, how they’re assigned and some of the things you can do with them, but there’s a lot of additional complexities. That’s not a surprise of course. However, some of those issues are worth drawing your attention to now. So that’s the goal of this section; to cover a few extra topics. As a consequence, this section is basically a bunch of things that I want to briefly mention, but don’t really fit in anywhere else. In short, I’ll talk about several different issues in this section, which are only loosely connected to one another.\n\n5.6.1 Special values\nThe first thing I want to mention are some of the “special” values that you might see R produce. Most likely you’ll see them in situations where you were expecting a number, but there are quite a few other ways you can encounter them. These values are Inf, NaN, NA and NULL. These values can crop up in various different places, and so it’s important to understand what they mean.\n\nInfinity (Inf). The easiest of the special values to explain is Inf, since it corresponds to a value that is infinitely large. You can also have -Inf. The easiest way to get Inf is to divide a positive number by 0:\n\n\n1 / 0\n\n[1] Inf\n\n\nIn most real world data analysis situations, if you’re ending up with infinite numbers in your data, then something has gone awry. Hopefully you’ll never have to see them.\n\nNot a Number (NaN). The special value of NaN is short for “not a number”, and it’s basically a reserved keyword that means “there isn’t a mathematically defined number for this”. If you can remember your high school maths, remember that it is conventional to say that \\(0/0\\) doesn’t have a proper answer: mathematicians would say that \\(0/0\\) is undefined. R says that it’s not a number:\n\n\n 0 / 0\n\n[1] NaN\n\n\nNevertheless, it’s still treated as a “numeric” value. To oversimplify, NaN corresponds to cases where you asked a proper numerical question that genuinely has no meaningful answer.\n\nNot available (NA). NA indicates that the value that is “supposed” to be stored here is missing. To understand what this means, it helps to recognise that the NA value is something that you’re most likely to see when analysing data from real world experiments. Sometimes you get equipment failures, or you lose some of the data, or whatever. The point is that some of the information that you were “expecting” to get from your study is just plain missing. Note the difference between NA and NaN. For NaN, we really do know what’s supposed to be stored; it’s just that it happens to correspond to something like \\(0/0\\) that doesn’t make any sense at all. In contrast, NA indicates that we actually don’t know what was supposed to be there. The information is missing.\nNo value (NULL). The NULL value takes this “absence” concept even further. It basically asserts that the variable genuinely has no value whatsoever. This is quite different to both NaN and NA. For NaN we actually know what the value is, because it’s something insane like \\(0/0\\). For NA, we believe that there is supposed to be a value “out there”, but a dog ate our homework and so we don’t quite know what it is. But for NULL we strongly believe that there is no value at all.\n\n\n\n5.6.2 Assigning names to vector elements\nOne thing that is sometimes a little unsatisfying about the way that R prints out a vector is that the elements come out unlabelled. Here’s what I mean. Suppose I’ve got data reporting the quarterly profits for some company. If I just create a no-frills vector, I have to rely on memory to know which element corresponds to which event. That is:\n\nprofit &lt;- c( 3.1, 0.1, -1.4, 1.1 )\nprofit\n\n[1]  3.1  0.1 -1.4  1.1\n\n\nYou can probably guess that the first element corresponds to the first quarter, the second element to the second quarter, and so on, but that’s only because I’ve told you the back story and because this happens to be a very simple example. In general, it can be quite difficult. This is where it can be helpful to assign names to each of the elements. Here’s how you do it:\n\nnames(profit) &lt;- c(\"Q1\",\"Q2\",\"Q3\",\"Q4\")\nprofit\n\n  Q1   Q2   Q3   Q4 \n 3.1  0.1 -1.4  1.1 \n\n\nThis is a slightly odd looking command, admittedly, but it’s not too difficult to follow. All we’re doing is assigning a vector of labels (character strings) to names(profit). You can always delete the names again by using the command names(profit) &lt;- NULL. It’s also worth noting that you don’t have to do this as a two stage process. You can get the same result with this command:\n\nprofit &lt;- c( \"Q1\" = 3.1, \"Q2\" = 0.1, \"Q3\" = -1.4, \"Q4\" = 1.1 )\nprofit\n\n  Q1   Q2   Q3   Q4 \n 3.1  0.1 -1.4  1.1 \n\n\nThe important things to notice are that (a) this does make things much easier to read, but (b) the names at the top aren’t the “real” data. The value of profit[1] is still 3.1; all I’ve done is added a name to profit[1] as well. Nevertheless, names aren’t purely cosmetic, since R allows you to pull out particular elements of the vector by referring to their names:\n\nprofit[\"Q1\"]\n\n Q1 \n3.1 \n\n\nAnd if I ever need to pull out the names themselves, then I just type names(profit).\n\n\n5.6.3 Variable classes\nAs we’ve seen, R allows you to store different kinds of data. In particular, the variables we’ve defined so far have either been character data (text), numeric data, or logical data.11 It’s important that we remember what kind of information each variable stores (and even more important that R remembers) since different kinds of variables allow you to do different things to them. For instance, if your variables have numerical information in them, then it’s okay to multiply them together:\n\nx &lt;- 5   # x is numeric\ny &lt;- 4   # y is numeric\nx * y    \n\n[1] 20\n\n\nBut if they contain character data, multiplication makes no sense whatsoever, and R will complain if you try to do it:\n\nx &lt;- \"apples\"   # x is character\ny &lt;- \"oranges\"  # y is character\nx * y           \n\nError in x * y: non-numeric argument to binary operator\n\n\nEven R is smart enough to know you can’t multiply \"apples\" by \"oranges\". It knows this because the quote marks are indicators that the variable is supposed to be treated as text, not as a number.\nThis is quite useful, but notice that it means that R makes a big distinction between 5 and \"5\". Without quote marks, R treats 5 as the number five, and will allow you to do calculations with it. With the quote marks, R treats \"5\" as the textual character five, and doesn’t recognise it as a number any more than it recognises \"p\" or \"five\" as numbers. As a consequence, there’s a big difference between typing x &lt;- 5 and typing x &lt;- \"5\". In the former, we’re storing the number 5; in the latter, we’re storing the character \"5\". Thus, if we try to do multiplication with the character versions, R gets stroppy:\n\nx &lt;- \"5\"   # x is character\ny &lt;- \"4\"   # y is character\nx * y     \n\nError in x * y: non-numeric argument to binary operator\n\n\nOkay, let’s suppose that I’ve forgotten what kind of data I stored in the variable x (which happens depressingly often). R provides a function that will let us find out. Or, more precisely, it provides three functions: class(), mode() and typeof(). Why the heck does it provide three functions, you might be wondering? Basically, because R actually keeps track of three different kinds of information about a variable:\n\nThe class of a variable is a “high level” classification, and it captures psychologically (or statistically) meaningful distinctions. For instance \"2011-09-12\" and \"my birthday\" are both text strings, but there’s an important difference between the two: one of them is a date. So it would be nice if we could get R to recognise that \"2011-09-12\" is a date, and allow us to do things like add or subtract from it. The class of a variable is what R uses to keep track of things like that. Because the class of a variable is critical for determining what R can or can’t do with it, the class() function is very handy.\nThe mode of a variable refers to the format of the information that the variable stores. It tells you whether R has stored text data or numeric data, for instance, which is kind of useful, but it only makes these “simple” distinctions. It can be useful to know about, but it’s not the main thing we care about. So I’m not going to use the mode() function very much.12\nThe type of a variable is a very low level classification. We won’t use it in this book, but (for those of you that care about these details) this is where you can see the distinction between integer data, double precision numeric, etc. Almost none of you actually will care about this, so I’m not even going to bother demonstrating the typeof() function.\n\nFor purposes, it’s the class() of the variable that we care most about. Later on, I’ll talk a bit about how you can convince R to “coerce” a variable to change from one class to another (Section @ref(coercion)). That’s a useful skill for real world data analysis, but it’s not something that we need right now. In the meantime, the following examples illustrate the use of the class() function:\n\nx &lt;- \"hello world\"     # x is text\nclass(x)\n\n[1] \"character\"\n\nx &lt;- TRUE     # x is logical \nclass(x)\n\n[1] \"logical\"\n\nx &lt;- 100     # x is a number\nclass(x)\n\n[1] \"numeric\"\n\n\nExciting, no?"
  },
  {
    "objectID": "chapters/variables.html#workspace",
    "href": "chapters/variables.html#workspace",
    "title": "5  Variables",
    "section": "5.7 Managing the workspace",
    "text": "5.7 Managing the workspace\nLet’s suppose that you’re reading through this book, and what you’re doing is sitting down with it once a week and working through a whole chapter in each sitting. Not only that, you’ve been following my advice and typing in all these commands into R. So far during this chapter, you’d have typed quite a few commands, although the only ones that actually involved creating variables were the ones you typed during Section @ref(comments). As a result, you currently have three variables; seeker, lover, and keeper. These three variables are the contents of your workspace, also referred to as the global environment. The workspace is a key concept in R, so in this section we’ll talk a lot about what it is and how to manage its contents.\n\n5.7.1 Listing variables\nThe first thing that you need to know how to do is examine the contents of the workspace. If you’re using RStudio, you will probably find that the easiest way to do this is to use the “Environment” panel in the top right hand corner. Click on that, and you’ll see a list that looks very much like the one shown in Figures @ref(fig:workspace) and @ref(fig:workspace2). If you’re using the commmand line, then the objects() function may come in handy:\n\nobjects()\n\n [1] \"any_sales_this_month\" \"days_per_month\"       \"february_sales\"      \n [4] \"greeting\"             \"has_annotations\"      \"hook_output\"         \n [7] \"is_the_party_correct\" \"months\"               \"profit\"              \n[10] \"revenue\"              \"royalty\"              \"sales\"               \n[13] \"sales_by_month\"       \"status\"               \"stock_levels\"        \n[16] \"x\"                    \"y\"                   \n\n\nOf course, in the true R tradition, the objects() function has a lot of fancy capabilities that I’m glossing over in this example. Moreover there are also several other functions that you can use, including ls() which is pretty much identical to objects(), and ls.str() which you can use to get a fairly detailed description of all the variables in the workspace. In fact, the lsr package actually includes its own function that you can use for this purpose, called who(). The reason for using the who() function is pretty straightforward: in my everyday work I find that the output produced by the objects() command isn’t quite informative enough, because the only thing it prints out is the name of each variable; but the ls.str() function is too informative, because it prints out a lot of additional information that I really don’t like to look at. The who() function is a compromise between the two. First, now that we’ve got the lsr package installed, we need to load it:\n\nlibrary(lsrbook)\n\nand now we can use the show_environment() function:\n\nshow_environment()\n\n# A tibble: 17 × 3\n   variable             class     size      \n   &lt;chr&gt;                &lt;chr&gt;     &lt;chr&gt;     \n 1 any_sales_this_month logical   length: 12\n 2 days_per_month       numeric   length: 12\n 3 february_sales       numeric   length: 1 \n 4 greeting             character length: 1 \n 5 has_annotations      function  &lt;NA&gt;      \n 6 hook_output          function  &lt;NA&gt;      \n 7 is_the_party_correct logical   length: 1 \n 8 months               character length: 12\n 9 profit               numeric   length: 4 \n10 revenue              numeric   length: 1 \n11 royalty              numeric   length: 1 \n12 sales                numeric   length: 1 \n13 sales_by_month       numeric   length: 12\n14 status               function  &lt;NA&gt;      \n15 stock_levels         character length: 12\n16 x                    numeric   length: 1 \n17 y                    character length: 1 \n\n\nAs you can see, the show_environment() function lists all the variables and provides some basic information about what kind of variable each one is and how many elements it contains. Personally, I find this output much easier more useful than the very compact output of the objects() function, but less overwhelming than the extremely verbose ls.str() function. Throughout this book you’ll see me using the show_environment() function a lot. You don’t have to use it yourself: in fact, I suspect you’ll find it easier to look at the RStudio environment panel. But for the purposes of writing a textbook I found it handy to have a nice text based description: otherwise there would be about another 100 or so screenshots added to the book.13\n\n\n5.7.2 Removing variables\nLooking over that list of variables, it occurs to me that I really don’t need them any more. I created them originally just to make a point, but they don’t serve any useful purpose anymore, and now I want to get rid of them. I’ll show you how to do this, but first I want to warn you – there’s no “undo” option for variable removal. Once a variable is removed, it’s gone forever unless you save it to disk. I’ll show you how to do that in Section @ref(load), but quite clearly we have no need for these variables at all, so we can safely get rid of them.\nIn RStudio, the easiest way to remove variables is to use the environment panel. Assuming that you’re in grid view (i.e., Figure @ref(fig:workspace2)), check the boxes next to the variables that you want to delete, then click on the “Clear” button at the top of the panel. When you do this, RStudio will show a dialog box asking you to confirm that you really do want to delete the variables. It’s always worth checking that you really do, because as RStudio is at pains to point out, you can’t undo this. Once a variable is deleted, it’s gone.14 In any case, if you click “yes”, that variable will disappear from the workspace: it will no longer appear in the environment panel, and it won’t show up when you use the show_environment() command.\nSuppose you don’t access to RStudio, and you still want to remove variables. This is where the remove function rm() comes in handy. The simplest way to use rm() is just to type in a (comma separated) list of all the variables you want to remove. Let’s say I want to get rid of seeker and lover, but I would like to keep keeper. To do this, all I have to do is type:\n\nrm( seeker, lover )\n\nWarning in rm(seeker, lover): object 'seeker' not found\n\n\nWarning in rm(seeker, lover): object 'lover' not found\n\n\nThere’s no visible output, but if I now inspect the workspace\n\nshow_environment()\n\n# A tibble: 17 × 3\n   variable             class     size      \n   &lt;chr&gt;                &lt;chr&gt;     &lt;chr&gt;     \n 1 any_sales_this_month logical   length: 12\n 2 days_per_month       numeric   length: 12\n 3 february_sales       numeric   length: 1 \n 4 greeting             character length: 1 \n 5 has_annotations      function  &lt;NA&gt;      \n 6 hook_output          function  &lt;NA&gt;      \n 7 is_the_party_correct logical   length: 1 \n 8 months               character length: 12\n 9 profit               numeric   length: 4 \n10 revenue              numeric   length: 1 \n11 royalty              numeric   length: 1 \n12 sales                numeric   length: 1 \n13 sales_by_month       numeric   length: 12\n14 status               function  &lt;NA&gt;      \n15 stock_levels         character length: 12\n16 x                    numeric   length: 1 \n17 y                    character length: 1 \n\n\nI see that there’s only the keeper variable left. As you can see, rm() can be very handy for keeping the workspace tidy."
  },
  {
    "objectID": "chapters/variables.html#summary",
    "href": "chapters/variables.html#summary",
    "title": "5  Variables",
    "section": "5.8 Summary",
    "text": "5.8 Summary"
  },
  {
    "objectID": "chapters/variables.html#footnotes",
    "href": "chapters/variables.html#footnotes",
    "title": "5  Variables",
    "section": "",
    "text": "If you are using RStudio, and the “environment” panel is visible when you typed the command, then you probably saw something happening there. That’s to be expected, and is quite helpful. However, there’s two things to note here (1) I haven’t yet explained what that panel does, so for now just ignore it, and (2) this is one of the helpful things RStudio does, not a part of R itself.↩︎\nAs we’ll discuss later, by doing this we are implicitly using the print() function↩︎\nActually, in keeping with the R tradition of providing you with a billion different screwdrivers (even when you’re actually looking for a hammer) these aren’t the only options. There’s also theassign() function, and the &lt;&lt;- and -&gt;&gt; operators. However, we won’t be using these at all in this book.↩︎\nA quick reminder: when using operators like &lt;- and -&gt; that span multiple characters, you can’t insert spaces in the middle. That is, if you type - &gt; or &lt; -, R will interpret your command the wrong way. And I will cry.↩︎\nActually, you can override any of these rules if you want to, and quite easily. All you have to do is add quote marks or backticks around your non-standard variable name. For instance `my sales ` &lt;- 350 would work just fine, but it’s almost never a good idea to do this.↩︎\nFor advanced users: there is one exception to this. If you’re naming a function, don’t use . in the name unless you are intending to use the S3 object oriented programming system. If you don’t know what S3 is, then you definitely don’t want to be using it!↩︎\nNotice that I didn’t specify any argument names here. The c() function is one of those cases where we don’t use names. We just type all the numbers, and R just dumps them all in a single variable.↩︎\nNo seriously, that’s actually pretty close to what authors get on the very expensive textbooks that you’re expected to purchase… if they are lucky.↩︎\nThough actually there’s no real need to do this, since R has an inbuilt variable called month.name that you can use for this purpose.↩︎\nWell, I say that… but in my personal experience it wasn’t until I started learning “regular expressions” that my loathing of computers reached its peak.↩︎\nOr functions. But let’s ignore functions for the moment.↩︎\nActually, I don’t think I ever use this in practice. I don’t know why I bother to talk about it in the book anymore.↩︎\nThis would be especially annoying if you’re reading an electronic copy of the book because the text displayed by the show_environment() function is searchable, whereas text shown in a screen shot isn’t!↩︎\nMind you, all that means is that it’s been removed from the workspace. If you’ve got the data saved to file somewhere, then that file is perfectly safe.↩︎"
  },
  {
    "objectID": "chapters/file-system.html#filesystem",
    "href": "chapters/file-system.html#filesystem",
    "title": "6  The file system",
    "section": "6.1 The file system itself",
    "text": "6.1 The file system itself\nIn this section I describe the basic idea behind file locations and file paths. Regardless of whether you’re using Window, Mac OS or Linux, every file on the computer is assigned a (fairly) human readable address, and every address has the same basic structure: it describes a path that starts from a root location , through as series of folders (or if you’re an old-school computer user, directories), and finally ends up at the file.\nOn a Windows computer the root is the physical drive1 on which the file is stored, and for most home computers the name of the hard drive that stores all your files is C: and therefore most file names on Windows begin with C:. After that comes the folders, and on Windows the folder names are separated by a \\ symbol. So, the complete path to this book on my Windows computer might be something like this:\nC:\\Users\\danRbook\\LSR.pdf\nand what that means is that the book is called LSR.pdf, and it’s in a folder called book which itself is in a folder called dan which itself is … well, you get the idea. On Linux, Unix and Mac OS systems, the addresses look a little different, but they’re more or less identical in spirit. Instead of using the backslash, folders are separated using a forward slash, and unlike Windows, they don’t treat the physical drive as being the root of the file system. So, the path to this book on my Mac might be something like this:\n/Users/dan/Rbook/LSR.pdf\nSo that’s what we mean by the “path” to a file. The next concept to grasp is the idea of a working directory and how to change it. For those of you who have used command line interfaces previously, this should be obvious already. But if not, here’s what I mean. The working directory is just “whatever folder I’m currently looking at”. Suppose that I’m currently looking for files in Explorer (if you’re using Windows) or using Finder (on a Mac). The folder I currently have open is my user directory (i.e., C:\\Users\\dan or /Users/dan). That’s my current working directory.\nThe fact that we can imagine that the program is “in” a particular directory means that we can talk about moving from our current location to a new one. What that means is that we might want to specify a new location in relation to our current location. To do so, we need to introduce two new conventions. Regardless of what operating system you’re using, we use . to refer to the current working directory, and .. to refer to the directory above it. This allows us to specify a path to a new location in relation to our current location, as the following examples illustrate. Let’s assume that I’m using my Windows computer, and my working directory is C:\\Users\\danRbook). The table below shows several addresses in relation to my current one:\n\n\n\nBasic arithmetic operations in R. These five operators are used very frequently throughout the text, so it’s important to be familiar with them at the outset.\n\n\n\n\n\n\nabsolute path (i.e., from root)\nrelative path (i.e. from C:)\n\n\n\n\nC:\\Users\\dan\n..\n\n\nC:\\Users\n..\\.. \\\n\n\nC:\\Users\\danRbook\\source\n.\\source\n\n\nC:\\Users\\dan\\nerdstuff\n..\\nerdstuff\n\n\n\n\n\nThere’s one last thing I want to call attention to: the ~ directory. I normally wouldn’t bother, but R makes reference to this concept sometimes. It’s quite common on computers that have multiple users to define ~ to be the user’s home directory. On my Mac, for instance, the home directory ~ for the “dan” user is \\Users\\dan\\. And so, not surprisingly, it is possible to define other directories in terms of their relationship to the home directory. For example, an alternative way to describe the location of the LSR.pdf file on my Mac would be\n~Rbook\\LSR.pdf\nThat’s about all you really need to know about file paths. And since this section already feels too long, it’s time to look at how to navigate the file system in R."
  },
  {
    "objectID": "chapters/file-system.html#navigationR",
    "href": "chapters/file-system.html#navigationR",
    "title": "6  The file system",
    "section": "6.2 Navigating the file system using the R console",
    "text": "6.2 Navigating the file system using the R console\nIn this section I’ll talk about how to navigate this file system from within R itself. It’s not particularly user friendly, and so you’ll probably be happy to know that RStudio provides you with an easier method, and I will describe it in Section @ref(nav3). So in practice, you won’t really need to use the commands that I babble on about in this section, but I do think it helps to see them in operation at least once before forgetting about them forever.\nOkay, let’s get started. When you want to load or save a file in R it’s important to know what the working directory is. You can find out by using the getwd() command. For the moment, let’s assume that I’m using Mac OS or Linux, since there’s some subtleties to Windows. Here’s what happens:\ngetwd()\n## [1] \"/Users/dan\"\nWe can change the working directory quite easily using setwd(). The setwd() function has only the one argument, dir, is a character string specifying a path to a directory, or a path relative to the working directory. Since I’m currently located at /Users/dan, the following two are equivalent:\nsetwd(\"/Users/dan/Rbook/data\")\nsetwd(\"./Rbook/data\")\nNow that we’re here, we can type list.files() command to get a listing of all the files in that directory. Since this is the directory in which I store all of the data files that we’ll use in this book, here’s what we get as the result:\nlist.files()\n## [1] \"afl24.Rdata\"             \"aflsmall.Rdata\"          \"aflsmall2.Rdata\"        \n## [4] \"agpp.Rdata\"              \"all.zip\"                 \"annoying.Rdata\"         \n## [7] \"anscombesquartet.Rdata\"  \"awesome.Rdata\"           \"awesome2.Rdata\"         \n## [10] \"booksales.csv\"           \"booksales.Rdata\"         \"booksales2.csv\"         \n## [13] \"cakes.Rdata\"             \"cards.Rdata\"             \"chapek9.Rdata\"          \n## [16] \"chico.Rdata\"             \"clinicaltrial_old.Rdata\" \"clinicaltrial.Rdata\"    \n## [19] \"coffee.Rdata\"            \"drugs.wmc.rt.Rdata\"      \"dwr_all.Rdata\"          \n## [22] \"effort.Rdata\"            \"happy.Rdata\"             \"harpo.Rdata\"            \n## [25] \"harpo2.Rdata\"            \"likert.Rdata\"            \"nightgarden.Rdata\"      \n## [28] \"nightgarden2.Rdata\"      \"parenthood.Rdata\"        \"parenthood2.Rdata\"      \n## [31] \"randomness.Rdata\"        \"repeated.Rdata\"          \"rtfm.Rdata\"             \n## [34] \"salem.Rdata\"             \"zeppo.Rdata\"\nNot terribly exciting, I’ll admit, but it’s useful to know about. In any case, there’s only one more thing I want to make a note of, which is that R also makes use of the home directory. You can find out what it is by using the path.expand() function, like this:\npath.expand(\"~\")\n## [1] \"/Users/dan\"\nYou can change the user directory if you want, but we’re not going to make use of it very much so there’s no reason to. The only reason I’m even bothering to mention it at all is that when you use RStudio to open a file, you’ll see output on screen that defines the path to the file relative to the ~ directory. I’d prefer you not to be confused when you see it.2"
  },
  {
    "objectID": "chapters/file-system.html#why-do-the-windows-paths-use-the-wrong-slash",
    "href": "chapters/file-system.html#why-do-the-windows-paths-use-the-wrong-slash",
    "title": "6  The file system",
    "section": "6.3 Why do the Windows paths use the wrong slash?",
    "text": "6.3 Why do the Windows paths use the wrong slash?\nLet’s suppose I’m on Windows. As before, I can find out what my current working directory is like this:\ngetwd()\n## [1] \"C:/Users/dan/\nThis seems about right, but you might be wondering why R is displaying a Windows path using the wrong type of slash. The answer is slightly complicated, and has to do with the fact that R treats the \\ character as “special” (see Section @ref(escapechars)). If you’re deeply wedded to the idea of specifying a path using the Windows style slashes, then what you need to do is to type / whenever you mean \\. In other words, if you want to specify the working directory on a Windows computer, you need to use one of the following commands:\nsetwd( \"C:/Users/dan\" )\nsetwd( \"C:\\\\Users\\\\dan\" )\nIt’s kind of annoying to have to do it this way, but as you’ll see later on in Section @ref(escapechars) it’s a necessary evil. Fortunately, as we’ll see in the next section, RStudio provides a much simpler way of changing directories…"
  },
  {
    "objectID": "chapters/file-system.html#nav3",
    "href": "chapters/file-system.html#nav3",
    "title": "6  The file system",
    "section": "6.4 Navigating the file system using the RStudio file panel",
    "text": "6.4 Navigating the file system using the RStudio file panel\nAlthough I think it’s important to understand how all this command line stuff works, in many (maybe even most) situations there’s an easier way. For our purposes, the easiest way to navigate the file system is to make use of RStudio’s built in tools. The “file” panel – the lower right hand area in Figure @ref(fig:filepanel) – is actually a pretty decent file browser. Not only can you just point and click on the names to move around the file system, you can also use it to set the working directory, and even load files.\nHere’s what you need to do to change the working directory using the file panel. Let’s say I’m looking at the actual screen shown in Figure @ref(fig:filepanel). At the top of the file panel you see some text that says “Home \\(&gt;\\) Rbook \\(&gt;\\) data”. What that means is that it’s displaying the files that are stored in the\n/Users/dan/Rbook/data\ndirectory on my computer. It does not mean that this is the R working directory. If you want to change the R working directory, using the file panel, you need to click on the button that reads “More”. This will bring up a little menu, and one of the options will be “Set as Working Directory”. If you select that option, then R really will change the working directory. You can tell that it has done so because this command appears in the console:\nsetwd(\"~/Rbook/data\")\nIn other words, RStudio sends a command to the R console, exactly as if you’d typed it yourself. The file panel can be used to do other things too. If you want to move “up” to the parent folder (e.g., from /Users/dan/Rbook/data to /Users/dan/Rbook click on the “..” link in the file panel. To move to a subfolder, click on the name of the folder that you want to open. You can open some types of file by clicking on them. You can delete files from your computer using the “delete” button, rename them with the “rename” button, and so on.\nAs you can tell, the file panel is a very handy little tool for navigating the file system. But it can do more than just navigate. As we’ll see later, it can be used to open files. And if you look at the buttons and menu options that it presents, you can even use it to rename, delete, copy or move files, and create new folders. However, since most of that functionality isn’t critical to the basic goals of this book, I’ll let you discover those on your own."
  },
  {
    "objectID": "chapters/file-system.html#summary",
    "href": "chapters/file-system.html#summary",
    "title": "6  The file system",
    "section": "6.5 Summary",
    "text": "6.5 Summary"
  },
  {
    "objectID": "chapters/file-system.html#footnotes",
    "href": "chapters/file-system.html#footnotes",
    "title": "6  The file system",
    "section": "",
    "text": "Well, the partition, technically.↩︎\nOne additional thing worth calling your attention to is the file.choose() function. Suppose you want to load a file and you don’t quite remember where it is, but would like to browse for it. Typing file.choose() at the command line will open a window in which you can browse to find the file; when you click on the file you want, R will print out the full path to that file. This is kind of handy.↩︎"
  },
  {
    "objectID": "chapters/packages.html#the-package-panel-in-rstudio",
    "href": "chapters/packages.html#the-package-panel-in-rstudio",
    "title": "7  R packages",
    "section": "7.1 The package panel in RStudio",
    "text": "7.1 The package panel in RStudio\nRight, lets get started. The first thing you need to do is look in the lower right hand panel in RStudio. You’ll see a tab labelled “Packages”. Click on the tab, and you’ll see a list of packages that looks something like Figure @ref(fig:packagepanel). Every row in the panel corresponds to a different package, and every column is a useful piece of information about that package.3 Going from left to right, here’s what each column is telling you:\n\nThe check box on the far left column indicates whether or not the package is loaded.\nThe one word of text immediately to the right of the check box is the name of the package.\nThe short passage of text next to the name is a brief description of the package.\nThe number next to the description tells you what version of the package you have installed.\nThe little x-mark next to the version number is a button that you can push to uninstall the package from your computer (you almost never need this)."
  },
  {
    "objectID": "chapters/packages.html#packageload",
    "href": "chapters/packages.html#packageload",
    "title": "7  R packages",
    "section": "7.2 Loading a package",
    "text": "7.2 Loading a package\nThat seems straightforward enough, so let’s try loading and unloading packades. For this example, I’ll use the foreign package. The foreign package is a collection of tools that are very handy when R needs to interact with files that are produced by other software packages (e.g., SPSS). It comes bundled with R, so it’s one of the ones that you have installed already, but it won’t be one of the ones loaded. Inside the foreign package is a function called read.spss(). It’s a handy little function that you can use to import an SPSS data file into R, so let’s pretend we want to use it. Currently, the foreign package isn’t loaded, so if I ask R to tell me if it knows about a function called read.spss() it tells me that there’s no such thing…\n\nexists( \"read.spss\" )\n\n[1] FALSE\n\n\nNow let’s load the package. In RStudio, the process is dead simple: go to the package tab, find the entry for the foreign package, and check the box on the left hand side. The moment that you do this, you’ll see a command like this appear in the R console:\n\nlibrary(\"foreign\", lib.loc=\"/Library/Frameworks/R.framework/Versions/3.0/Resources/library\")\n\nThe lib.loc bit will look slightly different on Macs versus on Windows, because that part of the command is just RStudio telling R where to look to find the installed packages. What I’ve shown you above is the Mac version. On a Windows machine, you’ll probably see something that looks like this:\n\nlibrary(\"foreign\", lib.loc=\"C:/Program Files/R/R-3.0.2/library\")\n\nBut actually it doesn’t matter much. The lib.loc bit is almost always unnecessary. Unless you’ve taken to installing packages in idiosyncratic places (which is something that you can do if you really want) R already knows where to look. So in the vast majority of cases, the command to load the foreign package is just this:\n\nlibrary(\"foreign\")\n\nThroughout this book, you’ll often see me typing in library() commands. You don’t actually have to type them in yourself: you can use the RStudio package panel to do all your package loading for you. The only reason I include the library() commands sometimes is as a reminder to you to make sure that you have the relevant package loaded. Oh, and I suppose we should check to see if our attempt to load the package actually worked. Let’s see if R now knows about the existence of the read.spss() function…\n\nexists( \"read.spss\" )\n\n[1] TRUE\n\n\nYep. All good."
  },
  {
    "objectID": "chapters/packages.html#packageunload",
    "href": "chapters/packages.html#packageunload",
    "title": "7  R packages",
    "section": "7.3 Unloading a package",
    "text": "7.3 Unloading a package\nSometimes, especially after a long session of working with R, you find yourself wanting to get rid of some of those packages that you’ve loaded. The RStudio package panel makes this exactly as easy as loading the package in the first place. Find the entry corresponding to the package you want to unload, and uncheck the box. When you do that for the foreign package, you’ll see this command appear on screen:\n\ndetach(\"package:foreign\", unload=TRUE)\n\nAnd the package is unloaded. We can verify this by seeing if the read.spss() function still exists():\n\nexists( \"read.spss\" )\n\n[1] FALSE\n\n\nNope. Definitely gone."
  },
  {
    "objectID": "chapters/packages.html#a-few-extra-comments",
    "href": "chapters/packages.html#a-few-extra-comments",
    "title": "7  R packages",
    "section": "7.4 A few extra comments",
    "text": "7.4 A few extra comments\nSections @ref(packageload) and @ref(packageunload) cover the main things you need to know about loading and unloading packages. However, there’s a couple of other details that I want to draw your attention to. A concrete example is the best way to illustrate. One of the other packages that you already have installed on your computer is the Matrix package, so let’s load that one and see what happens:\n\nlibrary( Matrix )\n\n## Loading required package: lattice\n\nThis is slightly more complex than the output that we got last time, but it’s not too complicated. The Matrix package makes use of some of the tools in the lattice package, and R has kept track of this dependency. So when you try to load the Matrix package, R recognises that you’re also going to need to have the lattice package loaded too. As a consequence, both packages get loaded, and R prints out a helpful little note on screen to tell you that it’s done so.\nR is pretty aggressive about enforcing these dependencies. Suppose, for example, I try to unload the lattice package while the Matrix package is still loaded. This is easy enough to try: all I have to do is uncheck the box next to “lattice” in the packages panel. But if I try this, here’s what happens:\n\ndetach(\"package:lattice\", unload=TRUE)\n\n## Error: package `lattice' is required by `Matrix' so will not be detached\n\nR refuses to do it. This can be quite useful, since it stops you from accidentally removing something that you still need. So, if I want to remove both Matrix and lattice, I need to do it in the correct order\nSomething else you should be aware of. Sometimes you’ll attempt to load a package, and R will print out a message on screen telling you that something or other has been “masked”. This will be confusing to you if I don’t explain it now, and it actually ties very closely to the whole reason why R forces you to load packages separately from installing them. Here’s an example. Two of the package that I’ll refer to a lot in this book are called car and psych. The car package is short for “Companion to Applied Regression” (which is a really great book, I’ll add), and it has a lot of tools that I’m quite fond of. The car package was written by a guy called John Fox, who has written a lot of great statistical tools for social science applications. The psych package was written by William Revelle, and it has a lot of functions that are very useful for psychologists in particular, especially in regards to psychometric techniques. For the most part, car and psych are quite unrelated to each other. They do different things, so not surprisingly almost all of the function names are different. But… there’s one exception to that. The car package and the psych package both contain a function called logit().4 This creates a naming conflict. If I load both packages into R, an ambiguity is created. If the user types in logit(100), should R use the logit() function in the car package, or the one in the psych package? The answer is: R uses whichever package you loaded most recently, and it tells you this very explicitly. Here’s what happens when I load the car package, and then afterwards load the psych package:\n\n#library(car)\n#library(psych)\n\nThe output here is telling you that the logit object (i.e., function) in the car package is no longer accessible to you. It’s been hidden (or “masked”) from you by the one in the psych package.5"
  },
  {
    "objectID": "chapters/packages.html#downloading-new-packages",
    "href": "chapters/packages.html#downloading-new-packages",
    "title": "7  R packages",
    "section": "7.5 Downloading new packages",
    "text": "7.5 Downloading new packages\nOne of the main selling points for R is that there are thousands of packages that have been written for it, and these are all available online. So whereabouts online are these packages to be found, and how do we download and install them? There is a big repository of packages called the “Comprehensive R Archive Network” (CRAN), and the easiest way of getting and installing a new package is from one of the many CRAN mirror sites. Conveniently for us, R provides a function called install.packages() that you can use to do this. Even more conveniently, the RStudio team runs its own CRAN mirror and RStudio has a clean interface that lets you install packages without having to learn how to use the install.packages() command6\nUsing the RStudio tools is, again, dead simple. In the top left hand corner of the packages panel (Figure @ref(fig:packagepanel)) you’ll see a button called “Install Packages”. If you click on that, it will bring up a window like the one shown in Figure @ref(fig:packageinstalla).\nThere are a few different buttons and boxes you can play with. Ignore most of them. Just go to the line that says “Packages” and start typing the name of the package that you want. As you type, you’ll see a dropdown menu appear (Figure @ref(fig:packageinstallb)), listing names of packages that start with the letters that you’ve typed so far.\nYou can select from this list, or just keep typing. Either way, once you’ve got the package name that you want, click on the install button at the bottom of the window. When you do, you’ll see the following command appear in the R console:\n\ninstall.packages(\"psych\")\n\nThis is the R command that does all the work. R then goes off to the internet, has a conversation with CRAN, downloads some stuff, and installs it on your computer. You probably don’t care about all the details of R’s little adventure on the web, but the install.packages() function is rather chatty, so it reports a bunch of gibberish that you really aren’t all that interested in:\ntrying URL 'http://cran.rstudio.com/bin/macosx/contrib/3.0/psych_1.4.1.tgz'\nContent type 'application/x-gzip' length 2737873 bytes (2.6 Mb)\nopened URL\n==================================================\ndownloaded 2.6 Mb\n\n\nThe downloaded binary packages are in\n    /var/folders/cl/thhsyrz53g73q0w1kb5z3l_80000gn/T//RtmpmQ9VT3/downloaded_packages\nDespite the long and tedious response, all thar really means is “I’ve installed the psych package”. I find it best to humour the talkative little automaton. I don’t actually read any of this garbage, I just politely say “thanks” and go back to whatever I was doing."
  },
  {
    "objectID": "chapters/packages.html#updating-r-and-r-packages",
    "href": "chapters/packages.html#updating-r-and-r-packages",
    "title": "7  R packages",
    "section": "7.6 Updating R and R packages",
    "text": "7.6 Updating R and R packages\nEvery now and then the authors of packages release updated versions. The updated versions often add new functionality, fix bugs, and so on. It’s generally a good idea to update your packages periodically. There’s an update.packages() function that you can use to do this, but it’s probably easier to stick with the RStudio tool. In the packages panel, click on the “Update Packages” button. This will bring up a window that looks like the one shown in Figure @ref(fig:updatepackages). In this window, each row refers to a package that needs to be updated. You can to tell R which updates you want to install by checking the boxes on the left. If you’re feeling lazy and just want to update everything, click the “Select All” button, and then click the “Install Updates” button. R then prints out a lot of garbage on the screen, individually downloading and installing all the new packages. This might take a while to complete depending on how good your internet connection is. Go make a cup of coffee. Come back, and all will be well.\nAbout every six months or so, a new version of R is released. You can’t update R from within RStudio (not to my knowledge, at least): to get the new version you can go to the CRAN website and download the most recent version of R, and install it in the same way you did when you originally installed R on your computer. This used to be a slightly frustrating event, because whenever you downloaded the new version of R, you would lose all the packages that you’d downloaded and installed, and would have to repeat the process of re-installing them. This was pretty annoying, and there were some neat tricks you could use to get around this. However, newer versions of R don’t have this problem so I no longer bother explaining the workarounds for that issue."
  },
  {
    "objectID": "chapters/packages.html#what-packages-does-this-book-use",
    "href": "chapters/packages.html#what-packages-does-this-book-use",
    "title": "7  R packages",
    "section": "7.7 What packages does this book use?",
    "text": "7.7 What packages does this book use?\nThere are several packages that I make use of in this book. The most prominent ones are:\n\nlsr. This is the Learning Statistics with R package that accompanies this book. It doesn’t have a lot of interesting high-powered tools: it’s just a small collection of handy little things that I think can be useful to novice users. As you get more comfortable with R this package should start to feel pretty useless to you.\npsych. This package, written by William Revelle, includes a lot of tools that are of particular use to psychologists. In particular, there’s several functions that are particularly convenient for producing analyses or summaries that are very common in psych, but less common in other disciplines.\ncar. This is the Companion to Applied Regression package, which accompanies the excellent book of the same name by (Fox and Weisberg 2011). It provides a lot of very powerful tools, only some of which we’ll touch in this book."
  },
  {
    "objectID": "chapters/packages.html#summary",
    "href": "chapters/packages.html#summary",
    "title": "7  R packages",
    "section": "7.8 Summary",
    "text": "7.8 Summary\n\n\n\n\nFox, J., and S. Weisberg. 2011. An R Companion to Applied Regression. 2nd ed. Los Angeles: Sage."
  },
  {
    "objectID": "chapters/packages.html#footnotes",
    "href": "chapters/packages.html#footnotes",
    "title": "7  R packages",
    "section": "",
    "text": "More precisely, there are 5000 or so packages on CRAN, the Comprehensive R Archive Network.↩︎\nBasically, the reason is that there are 5000 packages, and probably about 4000 authors of packages, and no-one really knows what all of them do. Keeping the installation separate from the loading minimizes the chances that two packages will interact with each other in a nasty way.↩︎\nIf you’re using the command line, you can get the same information by typing library() at the command line.↩︎\nThe logit function a simple mathematical function that happens not to have been included in the basic R distribution.↩︎\nTip for advanced users. You can get R to use the one from the car package by using car::logit() as your command rather than logit(), since the car:: part tells R explicitly which package to use. See also ::: if you’re especially keen to force R to use functions it otherwise wouldn’t, but take care, since ::: can be dangerous.↩︎\nIt is not very difficult.↩︎"
  },
  {
    "objectID": "chapters/data-objects.html#factors",
    "href": "chapters/data-objects.html#factors",
    "title": "8  Representing data",
    "section": "8.1 Factors",
    "text": "8.1 Factors\nOkay, it’s time to start introducing some of the data types that are somewhat more specific to statistics. If you remember back to Chapter @ref(studydesign), when we assign numbers to possible outcomes, these numbers can mean quite different things depending on what kind of variable we are attempting to measure. In particular, we commonly make the distinction between nominal, ordinal, interval and ratio scale data. How do we capture this distinction in R? Currently, we only seem to have a single numeric data type. That’s probably not going to be enough, is it?\nA little thought suggests that the numeric variable class in R is perfectly suited for capturing ratio scale data. For instance, if I were to measure response time (RT) for five different events, I could store the data in R like this:\n\nRT &lt;- c(342, 401, 590, 391, 554)\n\nwhere the data here are measured in milliseconds, as is conventional in the psychological literature. It’s perfectly sensible to talk about “twice the response time”, \\(2 \\times \\mbox{RT}\\), or the “response time plus 1 second”, \\(\\mbox{RT} + 1000\\), and so both of the following are perfectly reasonable things for R to do:\n\n2 * RT\n\n[1]  684  802 1180  782 1108\n\nRT + 1000\n\n[1] 1342 1401 1590 1391 1554\n\n\nAnd to a lesser extent, the “numeric” class is okay for interval scale data, as long as we remember that multiplication and division aren’t terribly interesting for these sorts of variables. That is, if my IQ score is 110 and yours is 120, it’s perfectly okay to say that you’re 10 IQ points smarter than me1, but it’s not okay to say that I’m only 92% as smart as you are, because intelligence doesn’t have a natural zero.2 We might even be willing to tolerate the use of numeric variables to represent ordinal scale variables, such as those that you typically get when you ask people to rank order items (e.g., like we do in Australian elections), though as we will see R actually has a built in tool for representing ordinal data (see Section @ref(orderedfactors)) However, when it comes to nominal scale data, it becomes completely unacceptable, because almost all of the “usual” rules for what you’re allowed to do with numbers don’t apply to nominal scale data. It is for this reason that R has factors.\n\n8.1.1 Introducing factors\nSuppose, I was doing a study in which people could belong to one of three different treatment conditions. Each group of people were asked to complete the same task, but each group received different instructions. Not surprisingly, I might want to have a variable that keeps track of what group people were in. So I could type in something like this\n\ngroup &lt;- c(1,1,1,2,2,2,3,3,3)\n\nso that group[i] contains the group membership of the i-th person in my study. Clearly, this is numeric data, but equally obviously this is a nominal scale variable. There’s no sense in which “group 1” plus “group 2” equals “group 3”, but nevertheless if I try to do that, R won’t stop me because it doesn’t know any better:\n\ngroup + 2\n\n[1] 3 3 3 4 4 4 5 5 5\n\n\nApparently R seems to think that it’s allowed to invent “group 4” and “group 5”, even though they didn’t actually exist. Unfortunately, R is too stupid to know any better: it thinks that 3 is an ordinary number in this context, so it sees no problem in calculating 3 + 2. But since we’re not that stupid, we’d like to stop R from doing this. We can do so by instructing R to treat group as a factor. This is easy to do using the as.factor() function.3\n\ngroup &lt;- as.factor(group)\ngroup\n\n[1] 1 1 1 2 2 2 3 3 3\nLevels: 1 2 3\n\n\nIt looks more or less the same as before (though it’s not immediately obvious what all that Levels rubbish is about), but if we ask R to tell us what the class of the group variable is now, it’s clear that it has done what we asked:\n\nclass(group)\n\n[1] \"factor\"\n\n\nNeat. Better yet, now that I’ve converted group to a factor, look what happens when I try to add 2 to it:\n\ngroup + 2\n\nWarning in Ops.factor(group, 2): '+' not meaningful for factors\n\n\n[1] NA NA NA NA NA NA NA NA NA\n\n\nThis time even R is smart enough to know that I’m being an idiot, so it tells me off and then produces a vector of missing values. (i.e., NA: see Section @ref(specials)).\n\n\n8.1.2 Labelling the factor levels\nI have a confession to make. My memory is not infinite in capacity; and it seems to be getting worse as I get older. So it kind of annoys me when I get data sets where there’s a nominal scale variable called gender, with two levels corresponding to males and females. But when I go to print out the variable I get something like this:\n\ngender\n\n[1] 1 1 1 1 1 2 2 2 2\nLevels: 1 2\n\n\nOkaaaay. That’s not helpful at all, and it makes me very sad. Which number corresponds to the males and which one corresponds to the females? Wouldn’t it be nice if R could actually keep track of this? It’s way too hard to remember which number corresponds to which gender. To fix this problem what we need to do is assign meaningful labels to the different levels of each factor. We can do that like this:\n\nlevels(group) &lt;- c(\"group 1\", \"group 2\", \"group 3\")\nprint(group)\n\n[1] group 1 group 1 group 1 group 2 group 2 group 2 group 3 group 3 group 3\nLevels: group 1 group 2 group 3\n\nlevels(gender) &lt;- c(\"male\", \"female\")\nprint(gender)\n\n[1] male   male   male   male   male   female female female female\nLevels: male female\n\n\nThat’s much easier on the eye.\n\n\n8.1.3 Moving on…\nFactors are very useful things, and we’ll use them a lot in this book: they’re the main way to represent a nominal scale variable. And there are lots of nominal scale variables out there. I’ll talk more about factors in Section @ref(orderedfactors), but for now you know enough to be able to get started."
  },
  {
    "objectID": "chapters/data-objects.html#dataframes",
    "href": "chapters/data-objects.html#dataframes",
    "title": "8  Representing data",
    "section": "8.2 Data frames",
    "text": "8.2 Data frames\nIt’s now time to go back and deal with the somewhat confusing thing that happened in Section @ref(loadingcsv) when we tried to open up a CSV file. Apparently we succeeded in loading the data, but it came to us in a very odd looking format. At the time, I told you that this was a data frame. Now I’d better explain what that means.\n\n8.2.1 Introducing data frames\n\n\nWarning in rm(books, keeper, profit, RT, x, y): object 'books' not found\n\n\nWarning in rm(books, keeper, profit, RT, x, y): object 'keeper' not found\n\n\nWarning in rm(books, keeper, profit, RT, x, y): object 'profit' not found\n\n\nWarning in rm(books, keeper, profit, RT, x, y): object 'x' not found\n\n\nWarning in rm(books, keeper, profit, RT, x, y): object 'y' not found\n\n\nIn order to understand why R has created this funny thing called a data frame, it helps to try to see what problem it solves. So let’s go back to the little scenario that I used when introducing factors in Section @ref(factors). In that section I recorded the group and gender for all 9 participants in my study. Let’s also suppose I recorded their ages and their score on “Dan’s Terribly Exciting Psychological Test”:\n\nage &lt;- c(17, 19, 21, 37, 18, 19, 47, 18, 19)\nscore &lt;- c(12, 10, 11, 15, 16, 14, 25, 21, 29)\n\nAssuming no other variables are in the workspace, if I type show_environment() I get this:\n\nshow_environment()\n\n# A tibble: 7 × 3\n  variable        class    size     \n  &lt;chr&gt;           &lt;chr&gt;    &lt;chr&gt;    \n1 age             numeric  length: 9\n2 gender          factor   length: 9\n3 group           factor   length: 9\n4 has_annotations function &lt;NA&gt;     \n5 hook_output     function &lt;NA&gt;     \n6 score           numeric  length: 9\n7 status          function &lt;NA&gt;     \n\n\nSo there are four variables in the workspace, age, gender, group and score. And it just so happens that all four of them are the same size (i.e., they’re all vectors with 9 elements). Aaaand it just so happens that age[1] corresponds to the age of the first person, and gender[1] is the gender of that very same person, etc. In other words, you and I both know that all four of these variables correspond to the same data set, and all four of them are organised in exactly the same way.\nHowever, R doesn’t know this! As far as it’s concerned, there’s no reason why the age variable has to be the same length as the gender variable; and there’s no particular reason to think that age[1] has any special relationship to gender[1] any more than it has a special relationship to gender[4]. In other words, when we store everything in separate variables like this, R doesn’t know anything about the relationships between things. It doesn’t even really know that these variables actually refer to a proper data set. The data frame fixes this: if we store our variables inside a data frame, we’re telling R to treat these variables as a single, fairly coherent data set.\nTo see how they do this, let’s create one. So how do we create a data frame? One way we’ve already seen: if we import our data from a CSV file, R will store it as a data frame. A second way is to create it directly from some existing variables using the data.frame() function. All you have to do is type a list of variables that you want to include in the data frame. The output of a data.frame() command is, well, a data frame. So, if I want to store all four variables from my experiment in a data frame called expt I can do so like this:\n\nexpt &lt;- data.frame ( age, gender, group, score ) \nexpt \n\n  age gender   group score\n1  17   male group 1    12\n2  19   male group 1    10\n3  21   male group 1    11\n4  37   male group 2    15\n5  18   male group 2    16\n6  19 female group 2    14\n7  47 female group 3    25\n8  18 female group 3    21\n9  19 female group 3    29\n\n\nNote that expt is a completely self-contained variable. Once you’ve created it, it no longer depends on the original variables from which it was constructed. That is, if we make changes to the original age variable, it will not lead to any changes to the age data stored in expt.\n\n\n8.2.2 Pulling out the contents of the data frame using $\nAt this point, our workspace contains only the one variable, a data frame called expt. But as we can see when we told R to print the variable out, this data frame contains 4 variables, each of which has 9 observations. So how do we get this information out again? After all, there’s no point in storing information if you don’t use it, and there’s no way to use information if you can’t access it. So let’s talk a bit about how to pull information out of a data frame.\nThe first thing we might want to do is pull out one of our stored variables, let’s say score. One thing you might try to do is ignore the fact that score is locked up inside the expt data frame. For instance, you might try to print it out like this:\n\nscore\n\nError in eval(expr, envir, enclos): object 'score' not found\n\n\nThis doesn’t work, because R doesn’t go “peeking” inside the data frame unless you explicitly tell it to do so. There’s actually a very good reason for this, which I’ll explain in a moment, but for now let’s just assume R knows what it’s doing. How do we tell R to look inside the data frame? As is always the case with R there are several ways. The simplest way is to use the $ operator to extract the variable you’re interested in, like this:\n\nexpt$score\n\n[1] 12 10 11 15 16 14 25 21 29\n\n\n\n\n8.2.3 Getting information about a data frame\nOne problem that sometimes comes up in practice is that you forget what you called all your variables. Normally you might try to type objects() or show_environment(), but neither of those commands will tell you what the names are for those variables inside a data frame! One way is to ask R to tell you what the names of all the variables stored in the data frame are, which you can do using the names() function:\n\nnames(expt)\n\n[1] \"age\"    \"gender\" \"group\"  \"score\" \n\n\n\n\n8.2.4 Looking for more on data frames?\nThere’s a lot more that can be said about data frames: they’re fairly complicated beasts, and the longer you use R the more important it is to make sure you really understand them. We’ll talk a lot more about them in Chapter @ref(datahandling)."
  },
  {
    "objectID": "chapters/data-objects.html#lists",
    "href": "chapters/data-objects.html#lists",
    "title": "8  Representing data",
    "section": "8.3 Lists",
    "text": "8.3 Lists\nThe next kind of data I want to mention are lists. Lists are an extremely fundamental data structure in R, and as you start making the transition from a novice to a savvy R user you will use lists all the time. I don’t use lists very often in this book – not directly – but most of the advanced data structures in R are built from lists (e.g., data frames are actually a specific type of list). Because lists are so important to how R stores things, it’s useful to have a basic understanding of them. Okay, so what is a list, exactly? Like data frames, lists are just “collections of variables.” However, unlike data frames – which are basically supposed to look like a nice “rectangular” table of data – there are no constraints on what kinds of variables we include, and no requirement that the variables have any particular relationship to one another. In order to understand what this actually means, the best thing to do is create a list, which we can do using the list() function. If I type this as my command:\n\nDan &lt;- list( age = 34,\n            nerd = TRUE,\n            parents = c(\"Joe\",\"Liz\") \n)\n\nR creates a new list variable called Dan, which is a bundle of three different variables: age, nerd and parents. Notice, that the parents variable is longer than the others. This is perfectly acceptable for a list, but it wouldn’t be for a data frame. If we now print out the variable, you can see the way that R stores the list:\n\nprint( Dan )\n\n$age\n[1] 34\n\n$nerd\n[1] TRUE\n\n$parents\n[1] \"Joe\" \"Liz\"\n\n\nAs you might have guessed from those $ symbols everywhere, the variables are stored in exactly the same way that they are for a data frame (again, this is not surprising: data frames are a type of list). So you will (I hope) be entirely unsurprised and probably quite bored when I tell you that you can extract the variables from the list using the $ operator, like so:\n\nDan$nerd\n\n[1] TRUE\n\n\nIf you need to add new entries to the list, the easiest way to do so is to again use $, as the following example illustrates. If I type a command like this\n\nDan$children &lt;- \"Alex\"\n\nthen R creates a new entry to the end of the list called children, and assigns it a value of \"Alex\". If I were now to print() this list out, you’d see a new entry at the bottom of the printout. Finally, it’s actually possible for lists to contain other lists, so it’s quite possible that I would end up using a command like Dan$children$age to find out how old my son is. Or I could try to remember it myself I suppose."
  },
  {
    "objectID": "chapters/data-objects.html#formulas",
    "href": "chapters/data-objects.html#formulas",
    "title": "8  Representing data",
    "section": "8.4 Formulas",
    "text": "8.4 Formulas\nThe last kind of variable that I want to introduce before finally being able to start talking about statistics is the formula. Formulas were originally introduced into R as a convenient way to specify a particular type of statistical model (see Chapter @ref(regression)) but they’re such handy things that they’ve spread. Formulas are now used in a lot of different contexts, so it makes sense to introduce them early.\nStated simply, a formula object is a variable, but it’s a special type of variable that specifies a relationship between other variables. A formula is specified using the “tilde operator” ~. A very simple example of a formula is shown below:4\n\nformula1 &lt;- out ~ pred\nformula1\n\nout ~ pred\n\n\nThe precise meaning of this formula depends on exactly what you want to do with it, but in broad terms it means “the out (outcome) variable, analysed in terms of the pred (predictor) variable”. That said, although the simplest and most common form of a formula uses the “one variable on the left, one variable on the right” format, there are others. For instance, the following examples are all reasonably common\n\nformula2 &lt;-  out ~ pred1 + pred2   # more than one variable on the right\nformula3 &lt;-  out ~ pred1 * pred2   # different relationship between predictors \nformula4 &lt;-  ~ var1 + var2         # a 'one-sided' formula\n\nand there are many more variants besides. Formulas are pretty flexible things, and so different functions will make use of different formats, depending on what the function is intended to do."
  },
  {
    "objectID": "chapters/data-objects.html#generics",
    "href": "chapters/data-objects.html#generics",
    "title": "8  Representing data",
    "section": "8.5 Generic functions",
    "text": "8.5 Generic functions\nThere’s one really important thing that I omitted when I discussed functions earlier on in Section @ref(usingfunctions), and that’s the concept of a generic function. The two most notable examples that you’ll see in the next few chapters are summary() and plot(), although you’ve already seen an example of one working behind the scenes, and that’s the print() function. The thing that makes generics different from the other functions is that their behaviour changes, often quite dramatically, depending on the class() of the input you give it. The easiest way to explain the concept is with an example. With that in mind, lets take a closer look at what the print() function actually does. I’ll do this by creating a formula, and printing it out in a few different ways. First, let’s stick with what we know:\n\nmy.formula &lt;- blah ~ blah.blah    # create a variable of class \"formula\"\nprint( my.formula )               # print it out using the generic print() function\n\nblah ~ blah.blah\n\n\nSo far, there’s nothing very surprising here. But there’s actually a lot going on behind the scenes here. When I type print( my.formula ), what actually happens is the print() function checks the class of the my.formula variable. When the function discovers that the variable it’s been given is a formula, it goes looking for a function called print.formula(), and then delegates the whole business of printing out the variable to the print.formula() function.5 For what it’s worth, the name for a “dedicated” function like print.formula() that exists only to be a special case of a generic function like print() is a method, and the name for the process in which the generic function passes off all the hard work onto a method is called method dispatch. You won’t need to understand the details at all for this book, but you do need to know the gist of it; if only because a lot of the functions we’ll use are actually generics. Anyway, to help expose a little more of the workings to you, let’s bypass the print() function entirely and call the formula method directly:\n\nprint.formula( my.formula )       # print it out using the print.formula() method\n\n## Appears to be deprecated\n\nThere’s no difference in the output at all. But this shouldn’t surprise you because it was actually the print.formula() method that was doing all the hard work in the first place. The print() function itself is a lazy bastard that doesn’t do anything other than select which of the methods is going to do the actual printing.\nOkay, fair enough, but you might be wondering what would have happened if print.formula() didn’t exist? That is, what happens if there isn’t a specific method defined for the class of variable that you’re using? In that case, the generic function passes off the hard work to a “default” method, whose name in this case would be print.default(). Let’s see what happens if we bypass the print() formula, and try to print out my.formula using the print.default() function:\n\nprint.default( my.formula )      # print it out using the print.default() method\n\nblah ~ blah.blah\nattr(,\"class\")\n[1] \"formula\"\nattr(,\".Environment\")\n&lt;environment: R_GlobalEnv&gt;\n\n\nHm. You can kind of see that it is trying to print out the same formula, but there’s a bunch of ugly low-level details that have also turned up on screen. This is because the print.default() method doesn’t know anything about formulas, and doesn’t know that it’s supposed to be hiding the obnoxious internal gibberish that R produces sometimes.\nAt this stage, this is about as much as we need to know about generic functions and their methods. In fact, you can get through the entire book without learning any more about them than this, so it’s probably a good idea to end this discussion here."
  },
  {
    "objectID": "chapters/data-objects.html#summary",
    "href": "chapters/data-objects.html#summary",
    "title": "8  Representing data",
    "section": "8.6 Summary",
    "text": "8.6 Summary\n\nUseful things to know about variables. In particular, we talked about special values, element names and classes.\nMore complex types of variables. R has a number of important variable types that will be useful when analysing real data. I talked about factors in Section @ref(factors), data frames in Section @ref(dataframes), lists in Section @ref(lists) and formulas in Section @ref(formulas).\nGeneric functions. How is it that some function seem to be able to do lots of different things? Section @ref(generics) tells you how."
  },
  {
    "objectID": "chapters/data-objects.html#footnotes",
    "href": "chapters/data-objects.html#footnotes",
    "title": "8  Representing data",
    "section": "",
    "text": "Taking all the usual caveats that attach to IQ measurement as a given, of course.↩︎\nOr, more precisely, we don’t know how to measure it. Arguably, a rock has zero intelligence. But it doesn’t make sense to say that the IQ of a rock is 0 in the same way that we can say that the average human has an IQ of 100. And without knowing what the IQ value is that corresponds to a literal absence of any capacity to think, reason or learn, then we really can’t multiply or divide IQ scores and expect a meaningful answer.↩︎\nOnce again, this is an example of coercing a variable from one class to another. I’ll talk about coercion in more detail in Section @ref(coercion).↩︎\nNote that, when I write out the formula, R doesn’t check to see if the out and pred variables actually exist: it’s only later on when you try to use the formula for something that this happens.↩︎\nFor readers with a programming background: what I’m describing is the very basics of how S3 methods work. However, you should be aware that R has two entirely distinct systems for doing object oriented programming, known as S3 and S4. Of the two, S3 is simpler and more informal, whereas S4 supports all the stuff that you might expect of a fully object oriented language. Most of the generics we’ll run into in this book use the S3 system, which is convenient for me because I’m still trying to figure out S4. ↩︎"
  },
  {
    "objectID": "chapters/reading-data.html#loading-workspace-files-using-r",
    "href": "chapters/reading-data.html#loading-workspace-files-using-r",
    "title": "9  Loading and saving data",
    "section": "9.1 Loading workspace files using R",
    "text": "9.1 Loading workspace files using R\nWhen I used the list.files() command to list the contents of the /Users/dan/Rbook/data directory (in Section @ref(navigationR)), the output referred to a file called booksales.Rdata. Let’s say I want to load the data from this file into my workspace. The way I do this is with the load() function. There are two arguments to this function, but the only one we’re interested in is\n\nfile. This should be a character string that specifies a path to the file that needs to be loaded. You can use an absolute path or a relative path to do so.\n\nUsing the absolute file path, the command would look like this:\nload( file = \"/Users/dan/Rbook/data/booksales.Rdata\" )\nbut this is pretty lengthy. Given that the working directory (remember, we changed the directory at the end of Section @ref(nav3)) is /Users/dan/Rbook/data, I could use a relative file path, like so:\nload( file = \"../data/booksales.Rdata\" )\nHowever, my preference is usually to change the working directory first, and then load the file. What that would look like is this:\nsetwd( \"../data\" )         # move to the data directory\nload( \"booksales.Rdata\" )  # load the data\nIf I were then to type who() I’d see that there are several new variables in my workspace now. Throughout this book, whenever you see me loading a file, I will assume that the file is actually stored in the working directory, or that you’ve changed the working directory so that R is pointing at the directory that contains the file. Obviously, you don’t need type that command yourself: you can use the RStudio file panel to do the work."
  },
  {
    "objectID": "chapters/reading-data.html#loading-workspace-files-using-rstudio",
    "href": "chapters/reading-data.html#loading-workspace-files-using-rstudio",
    "title": "9  Loading and saving data",
    "section": "9.2 Loading workspace files using RStudio",
    "text": "9.2 Loading workspace files using RStudio\nOkay, so how do we open an .Rdata file using the RStudio file panel? It’s terribly simple. First, use the file panel to find the folder that contains the file you want to load. If you look at Figure @ref(fig:filepanel), you can see that there are several .Rdata files listed. Let’s say I want to load the booksales.Rdata file. All I have to do is click on the file name. RStudio brings up a little dialog box asking me to confirm that I do want to load this file. I click yes. The following command then turns up in the console,\nload(\"~/Rbook/data/booksales.Rdata\")\nand the new variables will appear in the workspace (you’ll see them in the Environment panel in RStudio, or if you type who()). So easy it barely warrants having its own section."
  },
  {
    "objectID": "chapters/reading-data.html#loadingcsv",
    "href": "chapters/reading-data.html#loadingcsv",
    "title": "9  Loading and saving data",
    "section": "9.3 Importing data from CSV files using loadingcsv",
    "text": "9.3 Importing data from CSV files using loadingcsv\nOne quite commonly used data format is the humble “comma separated value” file, also called a CSV file, and usually bearing the file extension .csv. CSV files are just plain old-fashioned text files, and what they store is basically just a table of data. This is illustrated in Figure @ref(fig:booksalescsv), which shows a file called booksales.csv that I’ve created. As you can see, each row corresponds to a variable, and each row represents the book sales data for one month. The first row doesn’t contain actual data though: it has the names of the variables.\nIf RStudio were not available to you, the easiest way to open this file would be to use the read.csv() function.2 This function is pretty flexible, and I’ll talk a lot more about it’s capabilities in Section @ref(importing) for more details, but for now there’s only two arguments to the function that I’ll mention:\n\nfile. This should be a character string that specifies a path to the file that needs to be loaded. You can use an absolute path or a relative path to do so.\nheader. This is a logical value indicating whether or not the first row of the file contains variable names. The default value is TRUE.\n\nTherefore, to import the CSV file, the command I need is:\n\nbooks &lt;- read.csv(file = \"booksales.csv\")\n\nThere are two very important points to notice here. Firstly, notice that I didn’t try to use the load() function, because that function is only meant to be used for .Rdata files. If you try to use load() on other types of data, you get an error. Secondly, notice that when I imported the CSV file I assigned the result to a variable, which I imaginatively called books.3 file. There’s a reason for this. The idea behind an .Rdata file is that it stores a whole workspace. So, if you had the ability to look inside the file yourself you’d see that the data file keeps track of all the variables and their names. So when you load() the file, R restores all those original names. CSV files are treated differently: as far as R is concerned, the CSV only stores one variable, but that variable is big table. So when you import that table into the workspace, R expects you to give it a name.] Let’s have a look at what we’ve got:\n\nprint(books)\n\n       Month Days Sales Stock.Levels\n1    January   31     0         high\n2   February   28   100         high\n3      March   31   200          low\n4      April   30    50          out\n5        May   31     0          out\n6       June   30     0         high\n7       July   31     0         high\n8     August   31     0         high\n9  September   30     0         high\n10   October   31     0         high\n11  November   30     0         high\n12  December   31     0         high\n\n\nClearly, it’s worked, but the format of this output is a bit unfamiliar. We haven’t seen anything like this before. What you’re looking at is a data frame, which is a very important kind of variable in R, and one I’ll discuss in Section @ref(dataframes). For now, let’s just be happy that we imported the data and that it looks about right."
  },
  {
    "objectID": "chapters/reading-data.html#importing-data-from-csv-files-using-rstudio",
    "href": "chapters/reading-data.html#importing-data-from-csv-files-using-rstudio",
    "title": "9  Loading and saving data",
    "section": "9.4 Importing data from CSV files using RStudio",
    "text": "9.4 Importing data from CSV files using RStudio\nYet again, it’s easier in RStudio. In the environment panel in RStudio you should see a button called “Import Dataset”. Click on that, and it will give you a couple of options: select the “From Text File…” option, and it will open up a very familiar dialog box asking you to select a file: if you’re on a Mac, it’ll look like the usual Finder window that you use to choose a file; on Windows it looks like an Explorer window. An example of what it looks like on a Mac is shown in Figure @ref(fig:fileopen). I’m assuming that you’re familiar with your own computer, so you should have no problem finding the CSV file that you want to import! Find the one you want, then click on the “Open” button. When you do this, you’ll see a window that looks like the one in Figure @ref(fig:import).\nThe import data set window is relatively straightforward to understand.\nIn the top left corner, you need to type the name of the variable you R to create. By default, that will be the same as the file name: our file is called booksales.csv, so RStudio suggests the name booksales. If you’re happy with that, leave it alone. If not, type something else. Immediately below this are a few things that you can tweak to make sure that the data gets imported correctly:\n\nHeading. Does the first row of the file contain raw data, or does it contain headings for each variable? The booksales.csv file has a header at the top, so I selected “yes”.\nSeparator. What character is used to separate different entries? In most CSV files this will be a comma (it is “comma separated” after all). But you can change this if your file is different.\nDecimal. What character is used to specify the decimal point? In English speaking countries, this is almost always a period (i.e., .). That’s not universally true: many European countries use a comma. So you can change that if you need to.\nQuote. What character is used to denote a block of text? That’s usually going to be a double quote mark. It is for the booksales.csv file, so that’s what I selected.\n\nThe nice thing about the RStudio window is that it shows you the raw data file at the top of the window, and it shows you a preview of the data at the bottom. If the data at the bottom doesn’t look right, try changing some of the settings on the left hand side. Once you’re happy, click “Import”. When you do, two commands appear in the R console:\nbooksales &lt;- read.csv(\"~/Rbook/data/booksales.csv\")\nView(booksales)\nThe first of these commands is the one that loads the data. The second one will display a pretty table showing the data in RStudio."
  },
  {
    "objectID": "chapters/reading-data.html#saving-a-workspace-file-using-save",
    "href": "chapters/reading-data.html#saving-a-workspace-file-using-save",
    "title": "9  Loading and saving data",
    "section": "9.5 Saving a workspace file using save",
    "text": "9.5 Saving a workspace file using save\nNot surprisingly, saving data is very similar to loading data. Although RStudio provides a simple way to save files (see below), it’s worth understanding the actual commands involved. There are two commands you can use to do this, save() and save.image(). If you’re happy to save all of the variables in your workspace into the data file, then you should use save.image(). And if you’re happy for R to save the file into the current working directory, all you have to do is this:\n\nsave.image( file = \"myfile.Rdata\" )\n\nSince file is the first argument, you can shorten this to save.image(\"myfile.Rdata\"); and if you want to save to a different directory, then (as always) you need to be more explicit about specifying the path to the file, just as we discussed in Section @ref(navigation). Suppose, however, I have several variables in my workspace, and I only want to save some of them. For instance, I might have this as my workspace:\n\nwho()\n##   -- Name --   -- Class --   -- Size --\n##   data         data.frame    3 x 2     \n##   handy        character     1         \n##   junk         numeric       1        \n\nI want to save data and handy, but not junk. But I don’t want to delete junk right now, because I want to use it for something else later on. This is where the save() function is useful, since it lets me indicate exactly which variables I want to save. Here is one way I can use the save function to solve my problem:\n\nsave(data, handy, file = \"myfile.Rdata\")\n\nImportantly, you must specify the name of the file argument. The reason is that if you don’t do so, R will think that \"myfile.Rdata\" is actually a variable that you want to save, and you’ll get an error message. Finally, I should mention a second way to specify which variables the save() function should save, which is to use the list argument. You do so like this:\n\nsave.me &lt;- c(\"data\", \"handy\")   # the variables to be saved\nsave( file = \"booksales2.Rdata\", list = save.me )   # the command to save them"
  },
  {
    "objectID": "chapters/reading-data.html#save1",
    "href": "chapters/reading-data.html#save1",
    "title": "9  Loading and saving data",
    "section": "9.6 Saving a workspace file using RStudio",
    "text": "9.6 Saving a workspace file using RStudio\nRStudio allows you to save the workspace pretty easily. In the environment panel (Figures @ref(fig:workspace) and @ref(fig:workspace2)) you can see the “save” button. There’s no text, but it’s the same icon that gets used on every computer everywhere: it’s the one that looks like a floppy disk. You know, those things that haven’t been used in about 20 years. Alternatively, go to the “Session” menu and click on the “Save Workspace As…” option.4 This will bring up the standard “save” dialog box for your operating system (e.g., on a Mac it’ll look a little bit like the loading dialog box in Figure @ref(fig:fileopen)). Type in the name of the file that you want to save it to, and all the variables in your workspace will be saved to disk. You’ll see an R command like this one\n\nsave.image(\"~/Desktop/Untitled.RData\")\n\nPretty straightforward, really."
  },
  {
    "objectID": "chapters/reading-data.html#other-things-you-might-want-to-save",
    "href": "chapters/reading-data.html#other-things-you-might-want-to-save",
    "title": "9  Loading and saving data",
    "section": "9.7 Other things you might want to save",
    "text": "9.7 Other things you might want to save\nUntil now, we’ve talked mostly about loading and saving data. Other things you might want to save include:\n\nThe output. Sometimes you might also want to keep a copy of all your interactions with R, including everything that you typed in and everything that R did in response. There are some functions that you can use to get R to write its output to a file rather than to print onscreen (e.g., sink()), but to be honest, if you do want to save the R output, the easiest thing to do is to use the mouse to select the relevant text in the R console, go to the “Edit” menu in RStudio and select “Copy”. The output has now been copied to the clipboard. Now open up your favourite text editor or word processing software, and paste it. And you’re done. However, this will only save the contents of the console, not the plots you’ve drawn (assuming you’ve drawn some). We’ll talk about saving images later on.\nA script. While it is possible – and sometimes handy – to save the R output as a method for keeping a copy of your statistical analyses, another option that people use a lot (especially when you move beyond simple “toy” analyses) is to write scripts. A script is a text file in which you write out all the commands that you want R to run. You can write your script using whatever software you like. In real world data analysis writing scripts is a key skill – and as you become familiar with R you’ll probably find that most of what you do involves scripting rather than typing commands at the R prompt. However, you won’t need to do much scripting initially, so we’ll leave that until Chapter @ref(scripting)."
  },
  {
    "objectID": "chapters/reading-data.html#summary",
    "href": "chapters/reading-data.html#summary",
    "title": "9  Loading and saving data",
    "section": "9.8 Summary",
    "text": "9.8 Summary"
  },
  {
    "objectID": "chapters/reading-data.html#footnotes",
    "href": "chapters/reading-data.html#footnotes",
    "title": "9  Loading and saving data",
    "section": "",
    "text": "Notably those with .rda, .Rd, .Rhistory, .rdb and .rdx extensions↩︎\nIn a lot of books you’ll see the read.table() function used for this purpose instead of read.csv(). They’re more or less identical functions, with the same arguments and everything. They differ only in the default values.↩︎\nNote that I didn’t to this in my earlier example when loading the .Rdata↩︎\nA word of warning: what you don’t want to do is use the “File” menu. If you look in the “File” menu you will see “Save” and “Save As…” options, but they don’t save the workspace. Those options are used for dealing with scripts, and so they’ll produce .R files. We won’t get to those until Chapter @ref(scripting).↩︎"
  },
  {
    "objectID": "chapters/descriptive-statistics.html#centraltendency",
    "href": "chapters/descriptive-statistics.html#centraltendency",
    "title": "10  Descriptive statistics",
    "section": "10.1 Measures of central tendency",
    "text": "10.1 Measures of central tendency\nDrawing pictures of the data is an excellent way to convey the “gist” of what the data is trying to tell you. Another approach that can be helpful is to condense the data into a few simple “summary” statistics. In most situations, the first thing that you’ll want to calculate is a measure of central tendency. That is, you’d like to know something about the “average” or “middle” of your data lies. The two most commonly used measures are the mean, median and mode; occasionally people will also report a trimmed mean. I’ll explain each of these in turn, and then discuss when each of them is useful.\n\n10.1.1 The mean\nThe mean of a set of observations is just a normal, old-fashioned average: add all of the values up, and then divide by the total number of values. The first five winning margins in the southern_slam data are 196, 51, 23, 106 and 219, so the mean of these observations is just: \\[\n\\frac{196 + 51 + 23 + 106 + 219}{5} = \\frac{595}{5} = 119\n\\] Of course, this definition of the mean isn’t news to anyone: averages (i.e., means) are used so often in everyday life that this is pretty familiar stuff. However, since the concept of a mean is something that everyone already understands, I’ll use this as an excuse to start introducing some of the mathematical notation that statisticians use to describe this calculation, and talk about how the calculations would be done in R.\nThe first piece of notation to introduce is \\(N\\), which we’ll use to refer to the number of observations that we’re averaging (in this case \\(N = 5\\)). Next, we need to attach a label to the observations themselves. It’s traditional to use \\(X\\) for this, and to use subscripts to indicate which observation we’re actually talking about. That is, we’ll use \\(X_1\\) to refer to the first observation, \\(X_2\\) to refer to the second observation, and so on, all the way up to \\(X_N\\) for the last one. Or, to say the same thing in a slightly more abstract way, we use \\(X_i\\) to refer to the \\(i\\)-th observation. Just to make sure we’re clear on the notation, the following table lists the 5 observations in the southern_slam$margins variable, along with the mathematical symbol used to refer to it, and the actual value that the observation corresponds to:\n\n\n\nThe observation\nIts symbol\nThe observed value\n\n\n\n\nWinning margin, game 1\n\\(X_1\\)\n196 points\n\n\nWinning margin, game 2\n\\(X_2\\)\n51 points\n\n\nWinning margin, game 3\n\\(X_3\\)\n23 points\n\n\nWinning margin, game 4\n\\(X_4\\)\n106 points\n\n\nWinning margin, game 5\n\\(X_5\\)\n219 points\n\n\n\nOkay, now let’s try to write a formula for the mean. By tradition, we use \\(\\bar{X}\\) as the notation for the mean. So the calculation for the mean could be expressed using the following formula: \\[\n\\bar{X} = \\frac{X_1 + X_2 + ... + X_{N-1} + X_N}{N}\n\\] This formula is entirely correct, but it’s terribly long, so we use a summation symbol – written as \\(sum\\) – to shorten it.1 If I want to add up the first five observations, I could write out the sum the long way, \\(X_1 + X_2 + X_3 + X_4 +X_5\\) or I could use the summation symbol to shorten it to this: \\[\n\\sum_{i=1}^5 X_i\n\\] Taken literally, this could be read as “the sum, taken over all \\(i\\) values from 1 to 5, of the value \\(X_i\\)”. But basically, what it means is “add up the first five observations”. In any case, we can use this notation to write out the formula for the mean, which looks like this: \\[\n\\bar{X} = \\frac{1}{N} \\sum_{i=1}^N X_i\n\\]\nIn all honesty, I can’t imagine that all this mathematical notation helps clarify the concept of the mean at all. In fact, it’s really just a fancy way of writing out the same thing I said in words: add all the values up, and then divide by the total number of items. However, that’s not really the reason I went into all that detail. My goal was to try to make sure that everyone reading this book is clear on the notation that we’ll be using throughout the book: \\(\\bar{X}\\) for the mean, \\(\\scriptstyle\\sum\\) for the idea of summation, \\(X_i\\) for the \\(i\\)th observation, and \\(N\\) for the total number of observations. We’re going to be re-using these symbols a fair bit, so it’s important that you understand them well enough to be able to “read” the equations, and to be able to see that it’s just saying “add up lots of things and then divide by another thing”.\n\n\n10.1.2 Calculating the mean in R\nOkay that’s the maths, how do we get the magic computing box to do the work for us? If you really wanted to, you could do this calculation directly in R. For the first southern_slam games, do this just by typing it in as if R were a calculator…\n\n(196 + 51 + 23 + 106 + 219) / 5\n\n[1] 119\n\n\n… in which case R outputs the answer 595, just as if it were a calculator. However, that’s not the only way to do the calculations, and when the number of observations starts to become large, it’s easily the most tedious. Besides, in almost every real world scenario, you’ve already got the actual numbers stored in a variable of some kind, just like we have with the afl.margins variable. Under those circumstances, what you want is a function that will just add up all the values stored in a numeric vector. That’s what the sum() function does. If we want to add up all 43 winning margins in the data set, we can do so using the following command:2\n\nsum(southern_slam$margin)\n\n[1] 5825\n\n\nIf we only want the sum of the first five observations, then we can use square brackets to pull out only the first five elements of the vector. So the command would now be:\n\nsum(southern_slam$margin[1:5])\n\n[1] 595\n\n\nTo calculate the mean, we now tell R to divide the output of this summation by five, so the command that we need to type now becomes the following:\n\nsum(southern_slam$margin[1:5]) / 5\n\n[1] 119\n\n\nAlthough it’s pretty easy to calculate the mean using the sum() function, we can do it in an even easier way, since R also provides us with the mean() function. To calculate the mean for all 176 games, we would use the following command:\n\nmean(southern_slam$margin[1:5])\n\n[1] 119\n\n\nAs you can see, this gives exactly the same answers as the previous calculations.\n\n\n10.1.3 The median\nThe second measure of central tendency that people use a lot is the median, and it’s even easier to describe than the mean. The median of a set of observations is just the middle value. As before let’s imagine we were interested only in the first five winning margins: 196, 51, 23, 106, and 219. To figure out the median, we sort these numbers into ascending order:\n\\[\n23, 51, \\mathbf{106}, 196, 219\n\\]\nFrom inspection, it’s obvious that the median value of these five observations is 106, since that’s the middle one in the sorted list (I’ve put it in bold to make it even more obvious). Easy stuff. But what should we do if we were interested in the first six games rather than the first five? The sixth game in the tournament had a winning margin of 60 points, so our sorted list is now \\[\n23, 51, \\mathbf{60}, \\mathbf{106}, 196, 219\n\\]\nand there are two middle numbers, 60 and 106. The median is defined as the average of those two numbers, which in this case is 83. As before, it’s very tedious to do this by hand when you’ve got lots of numbers. To illustrate this, here’s what happens when you use R to sort all 43 winning margins. First, I’ll use the sort() function (discussed in Chapter @ref(datahandling)) to display the winning margins in increasing numerical order:\n\nsort(southern_slam$margin)\n\n [1]   0   2   4  11  19  21  22  23  45  48  51  60  69  71  72  75  81  82  95\n[20]  99 106 108 110 120 126 143 159 164 173 178 180 196 201 204 219 225 235 239\n[39] 266 286 348 397 492\n\n\nAs we have 43 observations in our data, the median value corresponds to item 22 in the sorted list of numbers. When we look up that observation in the list, we find that the median winning was 108. In real life, of course, we don’t actually calculate the median by sorting the data and then looking for the middle value by searching it manually. In real life, we use the median() command:\n\nmedian(southern_slam$margin)\n\n[1] 108\n\n\nMuch nicer.\n\n\n10.1.4 Mean or median? What’s the difference?\nKnowing how to calculate means and medians is only a part of the story. You also need to understand what each one is saying about the data, and what that implies for when you should use each one. The basic idea is illustrated in the figure below. The mean is basically the \"centre of gravity\" of the data set: if you imagine that the histogram of the data is a solid object, then the point on which you could balance it (as if on a see-saw) is the mean. In contrast, the median is the middle observation. Half of the observations are smaller, and half of the observations are larger.\n\n\n\n\n\nWhat this implies, as far as which one you should use, depends a little on what type of data you’ve got and what you’re trying to achieve. As a rough guide:\n\nIf your data are nominal scale, you probably shouldn’t be using either the mean or the median. Both the mean and the median rely on the idea that the numbers assigned to values are meaningful. If the numbering scheme is arbitrary, then it’s probably best to use the mode (Section @ref(mode)) instead.\nIf your data are ordinal scale, you’re more likely to want to use the median than the mean. The median only makes use of the order information in your data (i.e., which numbers are bigger), but doesn’t depend on the precise numbers involved. That’s exactly the situation that applies when your data are ordinal scale. The mean, on the other hand, makes use of the precise numeric values assigned to the observations, so it’s not really appropriate for ordinal data.\nFor interval and ratio scale data, either one is generally acceptable. Which one you pick depends a bit on what you’re trying to achieve. The mean has the advantage that it uses all the information in the data (which is useful when you don’t have a lot of data), but it’s very sensitive to extreme values, as we’ll see in Section @ref(trimmedmean).\n\nLet’s expand on that last part a little. One consequence is that there’s systematic differences between the mean and the median when the histogram is asymmetric (skewed; see Section @ref(skewandkurtosis)). This is illustrated in Figure @ref(fig:meanmedian) notice that the median (right hand side) is located closer to the “body” of the histogram, whereas the mean (left hand side) gets dragged towards the “tail” (where the extreme values are).\nTo give a concrete example, suppose Bob (income $50,000), Kate (income $60,000) and Jane (income $65,000) are sitting at a table: the average income at the table is $58,333 and the median income is $60,000. Then Bill sits down with them (income $100,000,000). The average income has now jumped to $25,043,750 but the median rises only to $62,500. If you’re interested in looking at the overall income at the table, the mean might be the right answer; but if you’re interested in what counts as a typical income at the table, the median would be a better choice here.\n\n\n10.1.5 Trimmed mean\nOne of the fundamental rules of applied statistics is that the data are messy. Real life is never simple, and so the data sets that you obtain are never as straightforward as the statistical theory says.3 This can have awkward consequences. To illustrate, consider this rather strange looking data set:\n\\[\n-100, 2, 3, 4, 5, 6, 7, 8, 9, 10\n\\]\nIf you were to observe this in a real life data set, you’d probably suspect that something funny was going on with the \\(-100\\) value. It’s probably an outlier, a value that doesn’t really belong with the others. You might consider removing it from the data set entirely, and in this particular case I’d probably agree with that course of action. In real life, however, you don’t always get such cut-and-dried examples. For instance, you might get this instead:\n\\[\n-15, 2, 3, 4, 5, 6, 7, 8, 9, 12\n\\]\nThe \\(-15\\) looks a bit suspicious, but not anywhere near as much as that \\(-100\\) did. In this case, it’s a little trickier. It might be a legitimate observation, it might not.\nWhen faced with a situation where some of the most extreme-valued observations might not be quite trustworthy, the mean is not necessarily a good measure of central tendency. It is highly sensitive to one or two extreme values, and is thus not considered to be a robust measure. One remedy that we’ve seen is to use the median. A more general solution is to use a “trimmed mean”. To calculate a trimmed mean, what you do is “discard” the most extreme examples on both ends (i.e., the largest and the smallest), and then take the mean of everything else. The goal is to preserve the best characteristics of the mean and the median: just like a median, you aren’t highly influenced by extreme outliers, but like the mean, you “use” more than one of the observations. Generally, we describe a trimmed mean in terms of the percentage of observation on either side that are discarded. So, for instance, a 10% trimmed mean discards the largest 10% of the observations and the smallest 10% of the observations, and then takes the mean of the remaining 80% of the observations. Not surprisingly, the 0% trimmed mean is just the regular mean, and the 50% trimmed mean is the median. In that sense, trimmed means provide a whole family of central tendency measures that span the range from the mean to the median.\nFor our toy example above, we have 10 observations, and so a 10% trimmed mean is calculated by ignoring the largest value (i.e., 12) and the smallest value (i.e., -15) and taking the mean of the remaining values. First, let’s enter the data:\n\ndataset &lt;- c(-15, 2, 3, 4, 5, 6, 7, 8, 9, 12)\n\nNext, let’s calculate means and medians:\n\nmean(dataset)\n\n[1] 4.1\n\nmedian(dataset)\n\n[1] 5.5\n\n\nThat’s a fairly substantial difference, but I’m tempted to think that the mean is being influenced a bit too much by the extreme values at either end of the data set, especially the -15 one. So let’s just try trimming the mean a bit. If I take a 10% trimmed mean, we’ll drop the extreme values on either side, and take the mean of the rest:\n\nmean(dataset, trim = .1)\n\n[1] 5.5\n\n\nwhich in this case gives exactly the same answer as the median. Note that, to get a 10% trimmed mean you write trim = .1, not trim = 10. In any case, let’s finish up by calculating the 5% trimmed mean for the southern_slam$margin data,\n\nmean(southern_slam$margin, trim = .05)  \n\n[1] 126.5128"
  },
  {
    "objectID": "chapters/descriptive-statistics.html#footnotes",
    "href": "chapters/descriptive-statistics.html#footnotes",
    "title": "10  Descriptive statistics",
    "section": "",
    "text": "The choice to use \\(\\sum\\) to denote summation isn’t entirely arbitrary. It’s essentially identical the Greek upper case letter sigma, which is the analogue of the letter S. I do realise that “S is for sum” is a bit silly, but life is like that I’m afraid. Mathematical fonts will usually have some subtle differences between the summation symbol \\(\\sum\\) and the upper case sigma \\(\\displaystyle\\Sigma\\), but as you can see those differences are minor. Along similar lines, there’s a “product” symbol \\(\\prod\\) used to denote the multiplication of lots of numbers, and it very closely resembles the upper case Greek letter pi (the Greek analog of P). Again, there are usually minor differences in how they look in a font: \\(\\prod\\) is a product symbol, whereas \\(\\displaystyle\\Pi\\) is the upper case pi… and oh my god this footnote is boring.↩︎\nNote that, just as we saw with the combine function c() and the remove function rm(), the sum() function has unnamed arguments. I’ll talk about unnamed arguments later in Section @ref(dotsargument), but for now let’s just ignore this detail.↩︎\nOr at least, the basic statistical theory – these days there is a whole subfield of statistics called robust statistics that tries to grapple with the messiness of real data and develop theory that can cope with it.↩︎"
  },
  {
    "objectID": "chapters/references.html",
    "href": "chapters/references.html",
    "title": "References",
    "section": "",
    "text": "Bickel, P. J., E. A. Hammel, and J. W. O’Connell. 1975. “Sex Bias\nin Graduate Admissions: Data from Berkeley.”\nScience 187: 398–404.\n\n\nEvans, J. St. B. T., J. L. Barston, and P. Pollard. 1983. “On the\nConflict Between Logic and Belief in Syllogistic Reasoning.”\nMemory and Cognition 11: 295–306.\n\n\nFox, J., and S. Weisberg. 2011. An R Companion to\nApplied Regression. 2nd ed. Los Angeles: Sage."
  }
]