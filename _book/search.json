[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Statistics with R",
    "section": "",
    "text": "Welcome!\nYou’ve discovered the work-in-progress revision for “Learning Statistics with R”.\nI’m so sorry.\nPerhaps I should explain. Back in the grimdark pre-Snapchat era of humanity (i.e. early 2011), I started teaching an introductory statistics class for psychology students offered at the University of Adelaide, using the R statistical package as the primary tool. I wrote my own lecture notes for the class, which have now expanded to the point of effectively being a book. The book is freely available, and released under a creative commons licence (CC BY-SA 4.0). Somehow the book turned out to be rather popular and there are now several variations of the original LSR book:\n\nMy original book was written in LaTeX, which makes it a little inaccessible. Emily Kothe kindly created a bookdown adaptation of LSR, which I’m now reworking in quarto\nMatt Crump has incorporated some LSR content in Answering Questions with Data\nMy own R programming notes R for Psychological Science adapt some LSR content\nDavid Foxcroft has adapted LSR to create Learning Statistics with Jamovi\nTom Faulkenberry has adapted David Foxcroft’s version to create Learning Statistics with JASP\nJean-Marc Meunier has translated Learning Statistics with Jamovi into French\nEthan Weed has started work on a Learning Statistics with Python adaptation (this is a work in progress!)\nRóbert Fodor is working on Learning Statistics with Cogstat\n\nI have suggested that someone write a Learning Statistics with an Abacus adaptation but so far there has been little interest."
  },
  {
    "objectID": "installation.html#windows-installation",
    "href": "installation.html#windows-installation",
    "title": "2  Installing R",
    "section": "2.1 Windows installation",
    "text": "2.1 Windows installation\nThe CRAN homepage changes from time to time, and it’s not particularly pretty. But it’s not difficult to find what you’re after. Assuming it doesn’t change, it’s a three-step process:\n\nYou’ll find a link at the top of the page with the text “Download R for Windows”. Click on that.\nThis will take you to a page that offers you a few options. At the very top of the page you’ll see a link for folks installing R for the first time. Click on that.\nThis will take you to a page that has a prominent link at the top called “Download R 4.2.2 for Windows”. Click on that and your browser should start downloading a file called R-4.2.2-win.exe.\n\nThe file may take some time depending on how fast your internet connection is. Once you’ve downloaded the file, double click to install it. As with any software you download online, Windows will ask you some questions about whether you trust the file and so on. After you click through those, it’ll ask you where you want to install it, and what components you want to install. The default values should be fine for most people, so again, just click through. Once all that is done, you should have R installed on your system. You can access it from the Start menu, or from the desktop if you asked it to add a shortcut there. You can now open up R in the usual way if you want to, but what I’m going to suggest is that instead of doing that you should now install RStudio (Section 2.4)."
  },
  {
    "objectID": "installation.html#mac-os-installation",
    "href": "installation.html#mac-os-installation",
    "title": "2  Installing R",
    "section": "2.2 Mac OS installation",
    "text": "2.2 Mac OS installation\nWhen you click on the Mac OS link, you should find yourself on a page with the title “R for Mac OS”. Here you’ll see several different options. The exact option that you want depends on what kind of Mac you have, and what version of the operating system you’re running. Most likely, however, what you’ll want is one of the first two options:\n\nIf you’re using an M1 Mac or higher, select the R-4.2.2-arm64.pkg option\nIf you’re using an Intel Mac, select the R-4.2.2.pkg option.\n\nEither way, your browser will start downloading the package file. Once it’s completed, all you need to do is open it by double clicking on the package file. The installation should go smoothly from there: just follow all the instructions just like you usually do when you install something.\nOnce it’s finished, you’ll find a file called R.app in the Applications folder. You can now open up R in the usual way if you want to, but what I’m going to suggest is that instead of doing that you should now install RStudio (Section 2.4)."
  },
  {
    "objectID": "installation.html#linux-installation",
    "href": "installation.html#linux-installation",
    "title": "2  Installing R",
    "section": "2.3 Linux installation",
    "text": "2.3 Linux installation\nIf you’re successfully managing to run a Linux box, regardless of what distribution, then you should find the instructions on the website easy enough. You can compile R from source yourself if you want, or install it through your package management system, which will probably have R in it. Alternatively, the CRAN site has precompiled binaries for Debian, Red Hat, Suse and Ubuntu and has separate instructions for each. Once you’ve got R installed, you can run it from the command line just by typing R. However, if you’re feeling envious of Windows and Mac users for their fancy GUIs, you can download RStudio too (Section 2.4)."
  },
  {
    "objectID": "installation.html#sec-installingrstudio",
    "href": "installation.html#sec-installingrstudio",
    "title": "2  Installing R",
    "section": "2.4 Installing RStudio",
    "text": "2.4 Installing RStudio\nOkay, so regardless of what operating system you’re using, the last thing that I told you to do is to download RStudio. To understand why I’ve suggested this, you need to understand a little bit more about R itself. The term R doesn’t really refer to a specific application on your computer. Rather, it refers to the underlying statistical language. You can use this language through lots of different applications. When you install R initially, it comes with one application that lets you do this: it’s the R.exe application on a Windows machine, and the R.app application on a Mac. But that’s not the only way to do it. There are lots of different applications that you can use that will let you interact with R. One of those is called RStudio, and it’s the one I’m going to suggest that you use. RStudio provides a clean, professional interface to R that I find much nicer to work with than either the Windows or Mac defaults. Like R itself, RStudio is free software: you can find all the details on their webpage. In the meantime, you can download it here:\nhttps://posit.co/download/rstudio-desktop/\nThis link should take you to a page with several possible downloads: there’s a different one for each operating system. Click on the appropriate link, and the RStudio installer file will start downloading. Once it’s finished downloading, open the installer file in the usual way to install RStudio. After it’s finished installing, you can start R by opening RStudio. You don’t need to open R.app or R.exe in order to access R. RStudio will take care of that for you. To illustrate what RStudio looks like, the figure below shows a screenshot of an R session in progress. In this screenshot it happens to be running on linux, but it looks almost identical no matter what operating system you have.\n\n\n\n\n\nAn R session in progress running inside RStudio."
  },
  {
    "objectID": "installation.html#sec-startingR",
    "href": "installation.html#sec-startingR",
    "title": "2  Installing R",
    "section": "2.5 Starting R",
    "text": "2.5 Starting R\nOne way or another, regardless of what operating system you’re using and regardless of whether you’re using RStudio, or the default GUI, or even the command line, it’s time to open R and get started. When you do that, the first thing you’ll see (assuming that you’re looking at the R console, that is) is a whole lot of text that doesn’t make much sense. It should look something like this:\nR version 4.2.2 Patched (2022-11-10 r83330) -- \"Innocent and Trusting\"\nCopyright (C) 2022 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu (64-bit)\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\n\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\n> \nMost of this text is pretty uninteresting, and when doing real data analysis you’ll never really pay much attention to it. The important part of it is this…\n>\n… which has a flashing cursor next to it. That’s the command prompt. When you see this, it means that R is waiting patiently for you to do something!"
  },
  {
    "objectID": "installation.html#quitting-r",
    "href": "installation.html#quitting-r",
    "title": "2  Installing R",
    "section": "2.6 Quitting R",
    "text": "2.6 Quitting R\nThere’s one last thing I should cover in this chapter: how to quit R. When I say this, I’m not trying to imply that R is some kind of pathological addition and that you need to call the R QuitLine or wear patches to control the cravings.1 I just mean how to exit the program. Assuming you’re running R in the usual way (i.e., through RStudio or the default GUI on a Windows or Mac computer), then you can just shut down the application in the normal way. However, R also has a function, called q() that you can use to quit, which is pretty handy if you’re running R in a terminal window.\nRegardless of what method you use to quit R, when you do so for the first time R will probably ask you if you want to save the “workspace image”. We’ll talk a lot more about loading and saving data in ?sec-load, but I figured we’d better quickly cover this now otherwise you’re going to get annoyed when you close R at the end of the chapter. If you’re using RStudio, you’ll see a dialog box with buttons to click. If you’re using a text based interface you’ll see this:\n\nq()\n\nSave workspace image? [y/n/c]: \nThe y/n/c part here is short for “yes / no / cancel”. Type y if you want to save, n if you don’t, and c if you’ve changed your mind and you don’t want to quit after all.\nWhat does this actually mean? What’s going on is that R wants to know if you want to save all those variables that you’ve been creating, so that you can use them later. This sounds like a great idea, so it’s really tempting to type y or click the “Save” button. To be honest though, I never do this, and it kind of annoys me a little bit… what R is really asking is if you want it to store these variables in a “default” data file, which it will automatically reload for you next time you open R. And quite frankly, if I’d wanted to save the variables, then I’d have already saved them before trying to quit. Not only that, I’d have saved them to a location of my choice, so that I can find it again later. So I personally never bother with this.\nIn fact, every time I install R on a new machine one of the first things I do is change the settings so that it never asks me again. You can do this in RStudio really easily: use the menu system to find the RStudio option. The window that comes up will give you an option to tell R never to whine about this again, as shown below:\n\n\n\n\n\nThe options window in RStudio. The highlighted settings are used to control the exit options\n\n\n\n\nOn a Mac, you can open this window by going to the “RStudio” menu and selecting “Preferences”. On a Windows machine you go to the “Tools” menu and select “Global Options”. Under the “General” tab you’ll see an option that reads “Save workspace to .Rdata on exit”. By default this is set to “ask”. If you want R to stop asking, change it to “never”."
  },
  {
    "objectID": "introduction.html#sec-whywhywhy",
    "href": "introduction.html#sec-whywhywhy",
    "title": "1  Why statistics? Why R?",
    "section": "1.1 On the psychology of statistics",
    "text": "1.1 On the psychology of statistics\nIn fact, come to think of it, this sounds a lot like a psychological question. And since I used to work in a psychology department, it seems like a good idea to dig a little deeper here. Is it really plausible to think that this “common sense” approach is very trustworthy? Verbal arguments have to be constructed in language, and all languages have biases – some things are harder to say than others, and not necessarily because they’re false (e.g., quantum electrodynamics is a good theory, but hard to explain in words). Human intuitions aren’t built to solve scientific problems, they’re built to handle day to day inferences. Most fundamentally, reasoning sensibly requires people to engage in “induction”, making wise guesses and going beyond the immediate evidence of the senses to make generalisations about the world. It’s more or less impossible to do this without being influenced by other sources. Heck, as the next section shows, we can’t even solve “deductive” problems (ones where no guessing is required) without being influenced by our pre-existing biases.\n\n1.1.1 The curse of belief bias\nPeople are pretty smart. Our minds are quite amazing things, and we seem to be capable of the most incredible feats of thought and reason. That doesn’t make us perfect though. And among the many things that psychologists have shown over the years is that we really do find it hard to be neutral, to evaluate evidence impartially and without being swayed by pre-existing biases. A good example of this is the “belief bias” effect in logical reasoning: if you ask people to decide whether a particular argument is logically valid (i.e., conclusion would be true if the premises were true), we tend to be influenced by the believability of the conclusion, even when we shouldn’t. For instance, here’s a valid argument where the conclusion is believable:\n\nNo cigarettes are inexpensive (Premise 1)\nSome addictive things are inexpensive (Premise 2)\nTherefore, some addictive things are not cigarettes (Conclusion)\n\nAnd here’s a valid argument where the conclusion is not believable:\n\nNo addictive things are inexpensive (Premise 1)\nSome cigarettes are inexpensive (Premise 2)\nTherefore, some cigarettes are not addictive (Conclusion)\n\nThe logical structure of argument #2 is identical to the structure of argument #1, and they’re both valid. However, in the second argument, there are good reasons to think that premise 1 is incorrect, and as a result it’s probably the case that the conclusion is also incorrect. But that’s entirely irrelevant to the topic at hand: an argument is deductively valid if the conclusion is a logical consequence of the premises. That is, a valid argument doesn’t have to involve true statements.\nOn the other hand, here’s an invalid argument that has a believable conclusion:\n\nNo addictive things are inexpensive (Premise 1)\nSome cigarettes are inexpensive (Premise 2)\nTherefore, some addictive things are not cigarettes (Conclusion)\n\nAnd finally, an invalid argument with an unbelievable conclusion:\n\nNo cigarettes are inexpensive (Premise 1)\nSome addictive things are inexpensive (Premise 2)\nTherefore, some cigarettes are not addictive (Conclusion)\n\nNow, suppose that people really are perfectly able to set aside their pre-existing biases about what is true and what isn’t, and purely evaluate an argument on its logical merits. We’d expect 100% of people to say that the valid arguments are valid, and 0% of people to say that the invalid arguments are valid. So if you ran an experiment looking at this, you’d expect to see data like this:\n\n\n\n\nConclusion feels true\nConclusion feels false\n\n\n\n\nArgument is valid\n100% say “valid”\n100% say “valid”\n\n\nArgument is invalid\n0% say “valid”\n0% say “valid”\n\n\n\nIf the psychological data looked like this – or even a good approximation to this – we might feel safe in just trusting our gut instincts. That is, it’d be perfectly okay just to let scientists evaluate data based on their common sense, and not bother with all this murky statistics stuff. However, you guys have taken psych classes, and by now you probably know where this is going…\nIn a classic study, Evans, Barston, and Pollard (1983) ran an experiment looking at exactly this. What they found is that when pre-existing biases (i.e., beliefs) were in agreement with the structure of the data, everything went the way you’d hope:\n\n\n\n\nConclusion feels true\nConclusion feels false\n\n\n\n\nArgument is valid\n92% say “valid”\n\n\n\nArgument is invalid\n\n8% say “valid”\n\n\n\nNot perfect, but that’s pretty good. But look what happens when our intuitive feelings about the truth of the conclusion run against the logical structure of the argument:\n\n\n\n\nConclusion feels true\nConclusion feels false\n\n\n\n\nArgument is valid\n92% say “valid”\n46% say “valid”\n\n\nArgument is invalid\n92% say “valid”\n8% say “valid”\n\n\n\nOh dear, that’s not as good. Apparently, when people are presented with a strong argument that contradicts our pre-existing beliefs, we find it pretty hard to even perceive it to be a strong argument (people only did so 46% of the time). Even worse, when people are presented with a weak argument that agrees with our pre-existing biases, almost no-one can see that the argument is weak (people got that one wrong 92% of the time!)2\nData like these suggest that we ought to be cautious about trusting our intuitions too much. If you were a professional evaluator of evidence, and someone came along and offered you a magic tool that improves your chances of making the right decision, you’d probably jump at it, right? Of course you would. Thankfully, we actually do have a tool that can do this. But it’s not magic, it’s statistics. So that’s the first reason why scientists love statistics. It’s just too easy for us to believe what we want to believe; so if we want to follow the data instead, we’re going to need a bit of help to keep our personal biases under control. That’s what statistics does: when done properly, it helps keep us honest."
  },
  {
    "objectID": "introduction.html#the-cautionary-tale-of-simpsons-paradox",
    "href": "introduction.html#the-cautionary-tale-of-simpsons-paradox",
    "title": "1  Why statistics? Why R?",
    "section": "1.2 The cautionary tale of Simpson’s paradox",
    "text": "1.2 The cautionary tale of Simpson’s paradox\nThe following is a true story (I think…). In 1973, the University of California, Berkeley had some worries about the admissions of students into their postgraduate courses. Specifically, the thing that caused the problem was that the gender breakdown of their admissions, which looked like this…\n\n\n\n\nNumber of applicants\nPercent admitted\n\n\n\n\nMales\n8442\n46%\n\n\nFemales\n4321\n35%\n\n\n\n…and they were worried about being sued.3 Given that there were nearly 13,000 applicants, a difference of 9% in admission rates between males and females is just way too big to be a coincidence.4 Pretty compelling data, right?\nWell, maybe. Maybe not.\nWhen people started looking more carefully at the admissions data (Bickel, Hammel, and O’Connell 1975) they told a rather different story. Specifically, when they looked at it on a department by department basis, it turned out that most of the departments actually had a slightly higher success rate for female applicants than for male applicants. The table below shows the admission figures for the six largest departments:\n\n\n\nAdmission figures for the six largest departments by gender\n\n\n\n\n\n\n\n\n\nDepartment\nMale Applicants\nMale Percent Admitted\nFemale Applicants\nFemale Percent admitted\n\n\n\n\nA\n825\n62%\n108\n82%\n\n\nB\n560\n63%\n25\n68%\n\n\nC\n325\n37%\n593\n34%\n\n\nD\n417\n33%\n375\n35%\n\n\nE\n191\n28%\n393\n24%\n\n\nF\n272\n6%\n341\n7%\n\n\n\n\n\nRemarkably, most departments had a higher rate of admissions for females than for males! Yet the overall rate of admission across the university for females was lower than for males. How can this be? How can both of these statements be true at the same time?\nHere’s what’s going on. Firstly, notice that the departments are not equal to one another in terms of their admission percentages: some departments (e.g., engineering, chemistry) tended to admit a high percentage of the qualified applicants, whereas others (e.g., English) tended to reject most of the candidates, even if they were high quality. So, among the six departments shown above, notice that department A is the most generous, followed by B, C, D, E and F in that order. Next, notice that males and females tended to apply to different departments. If we rank the departments in terms of the total number of male applicants, we get A>B>D>C>F>E (the “easy” departments are in bold). On the whole, males tended to apply to the departments that had high admission rates. Now compare this to how the female applicants distributed themselves. Ranking the departments in terms of the total number of female applicants produces a quite different ordering C>E>D>F>A>B. In other words, what these data seem to be suggesting is that the female applicants tended to apply to “harder” departments. And in fact, if we look at all Figure @ref(fig:berkeley) we see that this trend is systematic, and quite striking. This effect is known as Simpson’s paradox. It’s not common, but it does happen in real life, and most people are very surprised by it when they first encounter it, and many people refuse to even believe that it’s real. It is very real. And while there are lots of very subtle statistical lessons buried in there, I want to use it to make a much more important point …doing research is hard, and there are lots of subtle, counterintuitive traps lying in wait for the unwary. That’s reason #2 why scientists love statistics, and why we teach research methods. Because science is hard, and the truth is sometimes cunningly hidden in the nooks and crannies of complicated data.\n\n\n\n\n\nThe Berkeley 1973 college admissions data. This figure plots the admission rate for the 85 departments that had at least one female applicant, as a function of the percentage of applicants that were female. The plot is a redrawing of Figure 1 from Bickel, Hammel, and O’Connell (1975). Circles plot departments with more than 40 applicants; the area of the circle is proportional to the total number of applicants. The crosses plot department with fewer than 40 applicants.\n\n\n\n\nBefore leaving this topic entirely, I want to point out something else really critical that is often overlooked in a research methods class. Statistics only solves part of the problem. Remember that we started all this with the concern that Berkeley’s admissions processes might be unfairly biased against female applicants. When we looked at the “aggregated” data, it did seem like the university was discriminating against women, but when we “disaggregate” and looked at the individual behaviour of all the departments it doesn’t seem like any such bias existed. The gender bias in total admissions was caused by the fact that women tended to apply to departments with stricter admission standards.\nFrom a legal perspective, that would probably put the university in the clear. Postgraduate admissions are determined at the level of the individual department, and at the level of individual departments, the decisions are more or less unbiased. Since the university can’t dictate which departments people choose to apply to, and the decision making takes place at the level of the department it can hardly be held accountable for any biases that those choices produce.\nHowever that’s not the whole story, is it?\nAfter all, if we’re interested in this from a more sociological and psychological perspective, we might want to ask why there are such strong gender differences in applications. Why do males tend to apply to engineering more often than females, and why is this reversed for the English department? And why is it it the case that the departments that tend to have a female-application bias tend to have lower overall admission rates than those departments that have a male-application bias? Might this not still reflect a gender bias, even though every single department is itself unbiased? It might. Suppose, hypothetically, that males preferred to apply to “hard sciences” and females prefer “humanities”. And suppose further that the reason for why the humanities departments have low admission rates is because the government doesn’t want to fund the humanities (Ph.D. places, for instance, are often tied to government funded research projects). Does that constitute a gender bias? Or just an unenlightened view of the value of the humanities? What if someone at a high level in the government cut the humanities funds because they felt that the humanities are ’too feminine”. That seems pretty blatantly gender biased.\nNone of this falls within the purview of the statistical analysis, but it matters to the research project. If you’re interested in the overall structural effects of subtle gender biases, then you probably want to look at both the aggregated and disaggregated data. If you’re interested in the decision making process at Berkeley itself then you’re probably only interested in the disaggregated data.\nIn short there are a lot of critical questions that you can’t answer with statistics, but the answers to those questions will have a huge impact on how you analyse and interpret data. And this is the reason why you should always think of statistics as a tool to help you learn about your data, no more and no less. It’s a powerful tool to that end, but there’s no substitute for careful thought."
  },
  {
    "objectID": "introduction.html#statistics-in-psychology",
    "href": "introduction.html#statistics-in-psychology",
    "title": "1  Why statistics? Why R?",
    "section": "1.3 Statistics in psychology",
    "text": "1.3 Statistics in psychology\nI hope that the discussion above helped explain why science in general is so focused on statistics. But I’m guessing that you have a lot more questions about what role statistics plays in psychology, and specifically why psychology classes always devote so many lectures to stats. So here’s my attempt to answer a few of them…\n\n1.3.1 Why does psychology have so much statistics?\nTo be perfectly honest, there’s a few different reasons, some of which are better than others. The most important reason is that psychology is a statistical science. What I mean by that is that the “things” that we study are people. Real, complicated, gloriously messy, infuriatingly perverse people. The “things” of physics include object like electrons, and while there are all sorts of complexities that arise in physics, electrons don’t have minds of their own. They don’t have opinions, they don’t differ from each other in weird and arbitrary ways, they don’t get bored in the middle of an experiment, and they don’t get angry at the experimenter and then deliberately try to sabotage the data set (not that I’ve ever done that…). At a fundamental level psychology is harder than physics.5\nBasically, we teach statistics to you as psychologists because you need to be better at stats than physicists. There’s actually a saying used sometimes in physics, to the effect that “if your experiment needs statistics, you should have done a better experiment”. They have the luxury of being able to say that because their objects of study are pathetically simple in comparison to the vast mess that confronts social scientists. It’s not just psychology, really: most social sciences are desperately reliant on statistics. Not because we’re bad experimenters, but because we’ve picked a harder problem to solve. We teach you stats because you really, really need it.\n\n\n1.3.2 Can’t someone else do the statistics?\nTo some extent, but not completely. It’s true that you don’t need to become a fully trained statistician just to do psychology, but you do need to reach a certain level of statistical competence. In my view, there’s three reasons that every psychological researcher ought to be able to do basic statistics:\n\nFirstly, there’s the fundamental reason: statistics is deeply intertwined with research design. If you want to be good at designing psychological studies, you need to at least understand the basics of stats.\nSecondly, if you want to be good at the psychological side of the research, then you need to be able to understand the psychological literature, right? But almost every paper in the psychological literature reports the results of statistical analyses. So if you really want to understand the psychology, you need to be able to understand what other people did with their data. And that means understanding a certain amount of statistics.\nThirdly, there’s a big practical problem with being dependent on other people to do all your statistics: statistical analysis is expensive. You may not be in a financial position to be able to afford a statistician. That’s not at all uncommon!\n\nNote that a lot of these reasons generalise beyond researchers. If you want to be a practicing psychologist and stay on top of the field, it helps to be able to read the scientific literature, which relies pretty heavily on statistics.\n\n\n1.3.3 I don’t care about jobs, research, or clinical work. Do I need statistics?\nOkay, now you’re just messing with me. Still, I think it should matter to you too. Statistics should matter to you in the same way that statistics should matter to everyone: we live in the 21st century, and data are everywhere. Frankly, given the world in which we live these days, a basic knowledge of statistics is pretty damn close to a survival tool! Which is the topic of the next section…"
  },
  {
    "objectID": "introduction.html#statistics-in-everyday-life",
    "href": "introduction.html#statistics-in-everyday-life",
    "title": "1  Why statistics? Why R?",
    "section": "1.4 Statistics in everyday life",
    "text": "1.4 Statistics in everyday life\nWhen I started writing up my lecture notes I took the 20 most recent news articles posted to the ABC news website. Of those 20 articles, it turned out that 8 of them involved a discussion of something that I would call a statistical topic; 6 of those made a mistake. The most common error, if you’re curious, was failing to report baseline data (e.g., the article mentions that 5% of people in situation X have some characteristic Y, but doesn’t say how common the characteristic is for everyone else!) The point I’m trying to make here isn’t that journalists are bad at statistics (though they almost always are), it’s that a basic knowledge of statistics is very helpful for trying to figure out when someone else is either making a mistake or even lying to you. In fact, one of the biggest things that a knowledge of statistics does to you is cause you to get angry at the newspaper or the internet on a far more frequent basis."
  },
  {
    "objectID": "introduction.html#theres-more-to-research-methods-than-statistics",
    "href": "introduction.html#theres-more-to-research-methods-than-statistics",
    "title": "1  Why statistics? Why R?",
    "section": "1.5 There’s more to research methods than statistics",
    "text": "1.5 There’s more to research methods than statistics\nSo far, most of what I’ve talked about is statistics, and so you’d be forgiven for thinking that statistics is all I care about in life. To be fair, you wouldn’t be far wrong, but research methodology is a broader concept than statistics. So most research methods courses will cover a lot of topics that relate much more to the pragmatics of research design, and in particular the issues that you encounter when trying to do research with humans. However, about 99% of student fears relate to the statistics part of the course, so I’ve focused on the stats in this discussion, and hopefully I’ve convinced you that statistics matters, and more importantly, that it’s not to be feared.\nThat being said, it’s pretty typical for introductory research methods classes to be very stats-heavy. This is not (usually) because the lecturers are evil people. Quite the contrary, in fact. Introductory classes focus a lot on the statistics because you almost always find yourself needing statistics before you need the other research methods training. Why? Because almost all of your assignments in other classes will rely on statistical training, to a much greater extent than they rely on other methodological tools. It’s not common for undergraduate assignments to require you to design your own study from the ground up (in which case you would need to know a lot about research design), but it is common for assignments to ask you to analyse and interpret data that were collected in a study that someone else designed (in which case you need statistics). In that sense, from the perspective of allowing you to do well in all your other classes, the statistics is more urgent.\nBut note that “urgent” is different from “important” – they both matter. I really do want to stress that research design is just as important as data analysis, and this book does spend a fair amount of time on it. However, while statistics has a kind of universality, and provides a set of core tools that are useful for most types of psychological research, the research methods side isn’t quite so universal. There are some general principles that everyone should think about, but a lot of research design is very idiosyncratic, and is specific to the area of research that you want to engage in. To the extent that it’s the details that matter, those details don’t usually show up in an introductory stats and research methods class."
  },
  {
    "objectID": "introduction.html#why-use-r",
    "href": "introduction.html#why-use-r",
    "title": "1  Why statistics? Why R?",
    "section": "1.6 Why use R?",
    "text": "1.6 Why use R?\n\nR, the mysterious and powerful language of the statisticians, holds secrets beyond the realm of mortal understanding. As a data scientist, I delve into its dark depths, unearthing hidden truths buried deep within the data.\nBut be warned, for R is not for the faint of heart. Its community is vast and ancient, with thousands of packages available for use, each holding its own eldritch power. These packages, written in a language known only to the initiated, can save one from certain doom by providing pre-written code for common tasks. But beware, for to gaze upon the ggplot2 package is to behold true terror, as it unveils the horrors of the data in a manner both beautiful and terrifying.\nIn the end, R is a tool to be respected and feared, for it holds the power to unveil the hidden mysteries of the data, but at what cost? Only the bravest of souls should dare to tread its path.\n– The ChatGPT model, when I asked it to write about R in a gothic horror style\n\nBefore starting any discussion of how R works, I ought to talk a bit about why you might want to want to use R at all. If you’re approaching R as a complete novice, your mental model of R might look quite similar to the output of ChatGPT in the quote above. So let’s take a moment to reassure you that a dive into R is not in face a descent into a Lovecraftian nightmare.\nWhy use R? Given that you’re reading this, you’ve probably got your own reasons. However, if those reasons are “because that’s what my stats class uses”, it might be worth explaining a little why your lecturer has chosen to use R for the class. Of course, I don’t really know why other people choose R, so I’m really talking about why I use it.\n\nIt’s sort of obvious, but worth saying anyway: doing your statistics on a computer is faster, easier and more powerful than doing statistics by hand. Computers excel at mindless repetitive tasks, and a lot of statistical calculations are both mindless and repetitive. For most people, the only reason to ever do statistical calculations with pencil and paper is for learning purposes. In my class I do occasionally suggest doing some calculations that way, but the only real value to it is pedagogical. It does help you to get a “feel” for statistics to do some calculations yourself, so it’s worth doing it once. But only once!\nDoing statistics in a spreadsheet (e.g., Microsoft Excel) is generally a bad idea in the long run. Although many people are likely feel more familiar with them, spreadsheets are very limited in terms of what analyses they allow you do. If you get into the habit of trying to do your real life data analysis using spreadsheets, then you’ve dug yourself into a very deep hole.\nAvoiding proprietary software is a very good idea. There are a lot of commercial packages out there that you can buy, some of which I like and some of which I don’t. They’re usually very glossy in their appearance, and generally very powerful (much more powerful than spreadsheets). However, they’re also very expensive: usually, the company sells “student versions” (crippled versions of the real thing) very cheaply; they sell full powered “educational versions” at a price that makes me wince; and they sell commercial licences with a staggeringly high price tag. The business model here is to suck you in during your student days, and then leave you dependent on their tools when you go out into the real world. It’s hard to blame them for trying, but personally I’m not in favour of shelling out thousands of dollars if I can avoid it. And you can avoid it: if you make use of packages like R that are open source and free, you never get trapped having to pay exorbitant licensing fees.\nSomething that you might not appreciate now, but will love later on if you do anything involving data analysis, is the fact that R is highly extensible. When you download and install R, you get all the basic “packages”, and those are very powerful on their own. However, because R is so open and so widely used, it’s become something of a standard tool in statistics, and so lots of people write their own packages that extend the system. And these are freely available too. One of the consequences of this, I’ve noticed, is that if you open up an advanced textbook rather than introductory textbooks, is that a lot of them use R. In other words, if you learn how to do your basic statistics in R, then you’re a lot closer to being able to use the state of the art methods than you would be if you’d started out with a “simpler” system: so if you want to become a genuine expert in psychological data analysis, learning R is a very good use of your time.\nRelated to the previous point: R is a real programming language. As you get better at using R for data analysis, you’re also learning to program. To some people this might seem like a bad thing, but in truth, programming is a core research skill across a lot of the social and behavioural sciences. Think about how many surveys and experiments are done online, or presented on computers. Think about all those online social environments which you might be interested in studying; and maybe collecting data from in an automated fashion. Think about artificial intelligence systems, computer vision and speech recognition. If any of these are things that you think you might want to be involved in – as someone “doing research in psychology”, that is – you’ll need to know a bit of programming. And if you don’t already know how to program, then learning how to do statistics using R is a nice way to start.\n\nThose are the main reasons I use R. It’s not without its flaws: it’s not easy to learn, and it has a few very annoying quirks to it that we’re all pretty much stuck with, but on the whole I think the strengths outweigh the weakness.\n\n\n\n\nBickel, P. J., E. A. Hammel, and J. W. O’Connell. 1975. “Sex Bias in Graduate Admissions: Data from Berkeley.” Science 187: 398–404.\n\n\nEvans, J. St. B. T., J. L. Barston, and P. Pollard. 1983. “On the Conflict Between Logic and Belief in Syllogistic Reasoning.” Memory and Cognition 11: 295–306."
  }
]